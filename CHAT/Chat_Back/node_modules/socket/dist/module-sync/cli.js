#!/usr/bin/env node
'use strict';

function _socketInterop(e) {
  let c = 0
  for (const k in e ?? {}) {
    c = c === 0 && k === 'default' ? 1 : 0
    if (!c && k !== '__esModule') break
  }
  return c ? e.default : e
}

var process$1 = require('node:process');
var node_url = require('node:url');
var ponyCause = _socketInterop(require('pony-cause'));
var updateNotifier = _socketInterop(require('tiny-updater'));
var colors = _socketInterop(require('yoctocolors-cjs'));
var logger = require('@socketsecurity/registry/lib/logger');
var commonTags = _socketInterop(require('common-tags'));
var fs = require('node:fs/promises');
var ScreenWidget = _socketInterop(require('blessed/lib/widgets/screen'));
var contrib = _socketInterop(require('blessed-contrib'));
var strings = require('@socketsecurity/registry/lib/strings');
var shadowNpmInject = require('./shadow-npm-inject.js');
var constants = require('./constants.js');
var path$1 = require('node:path');
var meow = _socketInterop(require('meow'));
var objects = require('@socketsecurity/registry/lib/objects');
var path = require('@socketsecurity/registry/lib/path');
var regexps = require('@socketsecurity/registry/lib/regexps');
var prompts = require('@socketsecurity/registry/lib/prompts');
var yargsParse = _socketInterop(require('yargs-parser'));
var words = require('@socketsecurity/registry/lib/words');
var fs$1 = require('node:fs');
var shadowBin = require('./shadow-bin.js');
var chalkTable = _socketInterop(require('chalk-table'));
var util = require('node:util');
var registry = require('@socketsecurity/registry');
var npm = require('@socketsecurity/registry/lib/npm');
var packages = require('@socketsecurity/registry/lib/packages');
var lockfileFile = _socketInterop(require('@pnpm/lockfile-file'));
var lockfile_detectDepTypes = _socketInterop(require('@pnpm/lockfile.detect-dep-types'));
var debug = require('@socketsecurity/registry/lib/debug');
var spawn = require('@socketsecurity/registry/lib/spawn');
var shadowNpmPaths = require('./shadow-npm-paths.js');
var browserslist = _socketInterop(require('browserslist'));
var semver = _socketInterop(require('semver'));
var which = _socketInterop(require('which'));
var index_cjs = require('@socketregistry/hyrious__bun.lockb/index.cjs');
var sorts = require('@socketsecurity/registry/lib/sorts');
var registryConstants = require('@socketsecurity/registry/lib/constants');
var isInteractive = require('@socketregistry/is-interactive/index.cjs');
var terminalLink = _socketInterop(require('terminal-link'));
var npa = _socketInterop(require('npm-package-arg'));
var tinyglobby = _socketInterop(require('tinyglobby'));
var promises = require('@socketsecurity/registry/lib/promises');
var yaml = _socketInterop(require('yaml'));
var betterAjvErrors = _socketInterop(require('@apideck/better-ajv-errors'));
var config$D = require('@socketsecurity/config');
var assert = require('node:assert');
var readline = require('node:readline/promises');
var open = _socketInterop(require('open'));
var BoxWidget = _socketInterop(require('blessed/lib/widgets/box'));
var TableWidget = _socketInterop(require('blessed-contrib/lib/widget/table'));
var readline$1 = require('node:readline');

function handleUnsuccessfulApiResponse(_name, result) {
  // SocketSdkErrorType['error'] is not typed.
  const resultErrorMessage = result.error?.message;
  const message = typeof resultErrorMessage === 'string' ? resultErrorMessage : 'No error message returned';
  if (result.status === 401 || result.status === 403) {
    // Lazily access constants.spinner.
    const {
      spinner
    } = constants;
    spinner.stop();
    throw new shadowNpmInject.AuthError(message);
  }
  logger.logger.fail(`${colors.bgRed(colors.white('API returned an error:'))} ${message}`);
  process$1.exit(1);
}
async function handleApiCall(value, description) {
  let result;
  try {
    result = await value;
  } catch (cause) {
    throw new Error(`Failed ${description}`, {
      cause
    });
  }
  return result;
}
async function handleAPIError(code) {
  if (code === 400) {
    return 'One of the options passed might be incorrect.';
  } else if (code === 403) {
    return 'You might be trying to access an organization that is not linked to the API key you are logged in with.';
  } else ;
}
function getLastFiveOfApiToken(token) {
  // Get the last 5 characters of the API token before the trailing "_api".
  return token.slice(-9, -4);
}

// The API server that should be used for operations.
function getDefaultApiBaseUrl() {
  const baseUrl = process$1.env['SOCKET_SECURITY_API_BASE_URL'] || shadowNpmInject.getSetting('apiBaseUrl');
  return strings.isNonEmptyString(baseUrl) ? baseUrl : undefined;
}
async function queryAPI(path, apiToken) {
  const API_V0_URL = getDefaultApiBaseUrl();
  return await fetch(`${API_V0_URL}/${path}`, {
    method: 'GET',
    headers: {
      Authorization: `Basic ${btoa(`${apiToken}:${apiToken}`)}`
    }
  });
}

async function fetchOrgAnalyticsData(time, spinner, apiToken) {
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const result = await handleApiCall(socketSdk.getOrgAnalytics(time.toString()), 'fetching analytics data');
  if (result.success === false) {
    handleUnsuccessfulApiResponse('getOrgAnalytics', result);
    return undefined;
  }
  spinner.stop();
  if (!result.data.length) {
    logger.logger.log('No analytics data is available for this organization yet.');
    return undefined;
  }
  return result.data;
}

async function fetchRepoAnalyticsData(repo, time, spinner, apiToken) {
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const result = await handleApiCall(socketSdk.getRepoAnalytics(repo, time.toString()), 'fetching analytics data');
  if (result.success === false) {
    handleUnsuccessfulApiResponse('getRepoAnalytics', result);
    return undefined;
  }
  spinner.stop();
  if (!result.data.length) {
    logger.logger.log('No analytics data is available for this organization yet.');
    return undefined;
  }
  return result.data;
}

function mdTableStringNumber(title1, title2, obj) {
  // | Date        | Counts |
  // | ----------- | ------ |
  // | Header      | 201464 |
  // | Paragraph   |     18 |
  let mw1 = title1.length;
  let mw2 = title2.length;
  for (const [key, value] of Object.entries(obj)) {
    mw1 = Math.max(mw1, key.length);
    mw2 = Math.max(mw2, String(value ?? '').length);
  }
  const lines = [];
  lines.push(`| ${title1.padEnd(mw1, ' ')} | ${title2.padEnd(mw2)} |`);
  lines.push(`| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} |`);
  for (const [key, value] of Object.entries(obj)) {
    lines.push(`| ${key.padEnd(mw1, ' ')} | ${String(value ?? '').padStart(mw2, ' ')} |`);
  }
  lines.push(`| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} |`);
  return lines.join('\n');
}
function mdTable(logs,
// This is saying "an array of strings and the strings are a valid key of elements of T"
// In turn, T is defined above as the audit log event type from our OpenAPI docs.
cols) {
  // Max col width required to fit all data in that column
  const cws = cols.map(col => col.length);
  for (const log of logs) {
    for (let i = 0; i < cols.length; ++i) {
      // @ts-ignore
      const val = log[cols[i] ?? ''] ?? '';
      cws[i] = Math.max(cws[i] ?? 0, String(val).length);
    }
  }
  let div = '|';
  for (const cw of cws) div += ' ' + '-'.repeat(cw) + ' |';
  let header = '|';
  for (let i = 0; i < cols.length; ++i) header += ' ' + String(cols[i]).padEnd(cws[i] ?? 0, ' ') + ' |';
  let body = '';
  for (const log of logs) {
    body += '|';
    for (let i = 0; i < cols.length; ++i) {
      // @ts-ignore
      const val = log[cols[i] ?? ''] ?? '';
      body += ' ' + String(val).padEnd(cws[i] ?? 0, ' ') + ' |';
    }
    body += '\n';
  }
  return [div, header, div, body.trim(), div].filter(s => !!s.trim()).join('\n');
}
function mdTableOfPairs(arr,
// This is saying "an array of strings and the strings are a valid key of elements of T"
// In turn, T is defined above as the audit log event type from our OpenAPI docs.
cols) {
  // Max col width required to fit all data in that column
  const cws = cols.map(col => col.length);
  for (const [key, val] of arr) {
    cws[0] = Math.max(cws[0] ?? 0, String(key).length);
    cws[1] = Math.max(cws[1] ?? 0, String(val ?? '').length);
  }
  let div = '|';
  for (const cw of cws) div += ' ' + '-'.repeat(cw) + ' |';
  let header = '|';
  for (let i = 0; i < cols.length; ++i) {
    header += ' ' + String(cols[i]).padEnd(cws[i] ?? 0, ' ') + ' |';
  }
  let body = '';
  for (const [key, val] of arr) {
    body += '|';
    body += ' ' + String(key).padEnd(cws[0] ?? 0, ' ') + ' |';
    body += ' ' + String(val ?? '').padEnd(cws[1] ?? 0, ' ') + ' |';
    body += '\n';
  }
  return [div, header, div, body.trim(), div].filter(s => !!s.trim()).join('\n');
}

// Note: Widgets does not seem to actually work as code :'(

const METRICS = ['total_critical_alerts', 'total_high_alerts', 'total_medium_alerts', 'total_low_alerts', 'total_critical_added', 'total_medium_added', 'total_low_added', 'total_high_added', 'total_critical_prevented', 'total_high_prevented', 'total_medium_prevented', 'total_low_prevented'];

// Note: This maps `new Date(date).getMonth()` to English three letters
const Months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'];
async function displayAnalytics({
  filePath,
  outputKind,
  repo,
  scope,
  time
}) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API token.');
  }
  await outputAnalyticsWithToken({
    apiToken,
    filePath,
    outputKind,
    repo,
    scope,
    time
  });
}
async function outputAnalyticsWithToken({
  apiToken,
  filePath,
  outputKind,
  repo,
  scope,
  time
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Fetching analytics data');
  let data;
  if (scope === 'org') {
    data = await fetchOrgAnalyticsData(time, spinner, apiToken);
  } else if (repo) {
    data = await fetchRepoAnalyticsData(repo, time, spinner, apiToken);
  }

  // A message should already have been printed if we have no data here
  if (!data) return;
  if (outputKind === 'json') {
    const serialized = renderJson(data);
    if (!serialized) return;
    if (filePath && filePath !== '-') {
      try {
        await fs.writeFile(filePath, serialized, 'utf8');
        logger.logger.log(`Data successfully written to ${filePath}`);
      } catch (e) {
        process.exitCode = 1;
        logger.logger.fail('There was an error trying to write the json to disk');
        logger.logger.error(e);
      }
    } else {
      logger.logger.log(serialized);
    }
  } else {
    const fdata = scope === 'org' ? formatDataOrg(data) : formatDataRepo(data);
    if (outputKind === 'markdown') {
      const serialized = renderMarkdown(fdata, time, repo);
      if (filePath && filePath !== '-') {
        try {
          await fs.writeFile(filePath, serialized, 'utf8');
          logger.logger.log(`Data successfully written to ${filePath}`);
        } catch (e) {
          logger.logger.error(e);
        }
      } else {
        logger.logger.log(serialized);
      }
    } else {
      displayAnalyticsScreen(fdata);
    }
  }
}
function renderJson(data) {
  try {
    return JSON.stringify(data, null, 2);
  } catch (e) {
    process.exitCode = 1;
    // This could be caused by circular references, which is an "us" problem
    logger.logger.fail('There was a problem converting the data set to JSON. Please try without --json or with --markdown');
    return;
  }
}
function renderMarkdown(data, days, repoSlug) {
  return commonTags.stripIndents`
# Socket Alert Analytics

These are the Socket.dev stats are analytics for the ${repoSlug ? `${repoSlug} repo` : 'org'} of the past ${days} days

${[['Total critical alerts', mdTableStringNumber('Date', 'Counts', data['total_critical_alerts'])], ['Total high alerts', mdTableStringNumber('Date', 'Counts', data['total_high_alerts'])], ['Total critical alerts added to the main branch', mdTableStringNumber('Date', 'Counts', data['total_critical_added'])], ['Total high alerts added to the main branch', mdTableStringNumber('Date', 'Counts', data['total_high_added'])], ['Total critical alerts prevented from the main branch', mdTableStringNumber('Date', 'Counts', data['total_critical_prevented'])], ['Total high alerts prevented from the main branch', mdTableStringNumber('Date', 'Counts', data['total_high_prevented'])], ['Total medium alerts prevented from the main branch', mdTableStringNumber('Date', 'Counts', data['total_medium_prevented'])], ['Total low alerts prevented from the main branch', mdTableStringNumber('Date', 'Counts', data['total_low_prevented'])]].map(([title, table]) => commonTags.stripIndents`
## ${title}

${table}
`).join('\n\n')}

## Top 5 alert types

${mdTableStringNumber('Name', 'Counts', data['top_five_alert_types'])}
`;
}
function displayAnalyticsScreen(data) {
  const screen = new ScreenWidget({});
  const grid = new contrib.grid({
    rows: 5,
    cols: 4,
    screen
  });
  renderLineCharts(grid, screen, 'Total critical alerts', [0, 0, 1, 2], data['total_critical_alerts']);
  renderLineCharts(grid, screen, 'Total high alerts', [0, 2, 1, 2], data['total_high_alerts']);
  renderLineCharts(grid, screen, 'Total critical alerts added to the main branch', [1, 0, 1, 2], data['total_critical_added']);
  renderLineCharts(grid, screen, 'Total high alerts added to the main branch', [1, 2, 1, 2], data['total_high_added']);
  renderLineCharts(grid, screen, 'Total critical alerts prevented from the main branch', [2, 0, 1, 2], data['total_critical_prevented']);
  renderLineCharts(grid, screen, 'Total high alerts prevented from the main branch', [2, 2, 1, 2], data['total_high_prevented']);
  renderLineCharts(grid, screen, 'Total medium alerts prevented from the main branch', [3, 0, 1, 2], data['total_medium_prevented']);
  renderLineCharts(grid, screen, 'Total low alerts prevented from the main branch', [3, 2, 1, 2], data['total_low_prevented']);
  const bar = grid.set(4, 0, 1, 2, contrib.bar, {
    label: 'Top 5 alert types',
    barWidth: 10,
    barSpacing: 17,
    xOffset: 0,
    maxHeight: 9,
    barBgColor: 'magenta'
  });
  screen.append(bar); //must append before setting data

  bar.setData({
    titles: Object.keys(data.top_five_alert_types),
    data: Object.values(data.top_five_alert_types)
  });
  screen.render();
  screen.key(['escape', 'q', 'C-c'], () => process.exit(0));
}
function formatDataRepo(data) {
  const sortedTopFiveAlerts = {};
  const totalTopAlerts = {};
  const formattedData = {};
  for (const metric of METRICS) {
    formattedData[metric] = {};
  }
  for (const entry of data) {
    const topFiveAlertTypes = entry['top_five_alert_types'];
    for (const type of Object.keys(topFiveAlertTypes)) {
      const count = topFiveAlertTypes[type] ?? 0;
      if (!totalTopAlerts[type]) {
        totalTopAlerts[type] = count;
      } else if (count > (totalTopAlerts[type] ?? 0)) {
        totalTopAlerts[type] = count;
      }
    }
  }
  for (const entry of data) {
    for (const metric of METRICS) {
      formattedData[metric][formatDate(entry['created_at'])] = entry[metric];
    }
  }
  const topFiveAlertEntries = Object.entries(totalTopAlerts).sort(([_keya, a], [_keyb, b]) => b - a).slice(0, 5);
  for (const [key, value] of topFiveAlertEntries) {
    sortedTopFiveAlerts[key] = value;
  }
  return {
    ...formattedData,
    top_five_alert_types: sortedTopFiveAlerts
  };
}
function formatDataOrg(data) {
  const sortedTopFiveAlerts = {};
  const totalTopAlerts = {};
  const formattedData = {};
  for (const metric of METRICS) {
    formattedData[metric] = {};
  }
  for (const entry of data) {
    const topFiveAlertTypes = entry['top_five_alert_types'];
    for (const type of Object.keys(topFiveAlertTypes)) {
      const count = topFiveAlertTypes[type] ?? 0;
      if (!totalTopAlerts[type]) {
        totalTopAlerts[type] = count;
      } else {
        totalTopAlerts[type] += count;
      }
    }
  }
  for (const metric of METRICS) {
    const formatted = formattedData[metric];
    for (const entry of data) {
      const date = formatDate(entry['created_at']);
      if (!formatted[date]) {
        formatted[date] = entry[metric];
      } else {
        formatted[date] += entry[metric];
      }
    }
  }
  const topFiveAlertEntries = Object.entries(totalTopAlerts).sort(([_keya, a], [_keyb, b]) => b - a).slice(0, 5);
  for (const [key, value] of topFiveAlertEntries) {
    sortedTopFiveAlerts[key] = value;
  }
  return {
    ...formattedData,
    top_five_alert_types: sortedTopFiveAlerts
  };
}
function formatDate(date) {
  return `${Months[new Date(date).getMonth()]} ${new Date(date).getDate()}`;
}
function renderLineCharts(grid, screen, title, coords, data) {
  const line = grid.set(...coords, contrib.line, {
    style: {
      line: 'cyan',
      text: 'cyan',
      baseline: 'black'
    },
    xLabelPadding: 0,
    xPadding: 0,
    xOffset: 0,
    wholeNumbersOnly: true,
    legend: {
      width: 1
    },
    label: title
  });
  screen.append(line);
  const lineData = {
    x: Object.keys(data),
    y: Object.values(data)
  };
  line.setData([lineData]);
}

// TODO: not sure if I'm missing something but meow doesn't seem to expose this?

// Note: we use this description in getFlagListOutput, meow doesn't care

const commonFlags = {
  help: {
    type: 'boolean',
    default: false,
    shortFlag: 'h',
    description: 'Print this help.'
  },
  dryRun: {
    type: 'boolean',
    default: false,
    description: 'Do input validation for a command and exit 0 when input is ok'
  }
};
const outputFlags = {
  json: {
    type: 'boolean',
    shortFlag: 'j',
    default: false,
    description: 'Output result as json'
  },
  markdown: {
    type: 'boolean',
    shortFlag: 'm',
    default: false,
    description: 'Output result as markdown'
  }
};
const validationFlags = {
  all: {
    type: 'boolean',
    default: false,
    description: 'Include all issues'
  },
  strict: {
    type: 'boolean',
    default: false,
    description: 'Exits with an error code if any matching issues are found'
  }
};

function getFlagListOutput(list, indent, {
  keyPrefix = '--',
  padName
} = {}) {
  return getHelpListOutput({
    ...list
  }, indent, {
    keyPrefix,
    padName
  });
}
function getHelpListOutput(list, indent, {
  keyPrefix = '',
  padName = 18
} = {}) {
  let result = '';
  const names = Object.keys(list).sort();
  for (const name of names) {
    const rawDescription = list[name];
    const description = (typeof rawDescription === 'object' ? rawDescription.description : rawDescription) || '';
    result += ''.padEnd(indent) + (keyPrefix + name).padEnd(padName) + description + '\n';
  }
  return result.trim();
}

const {
  DRY_RUN_LABEL: DRY_RUN_LABEL$1,
  REDACTED
} = constants;
async function meowWithSubcommands(subcommands, options) {
  const {
    aliases = {},
    argv,
    defaultSub,
    importMeta,
    name,
    ...additionalOptions
  } = {
    __proto__: null,
    ...options
  };
  const [commandOrAliasNamex, ...rawCommandArgv] = argv;
  let commandOrAliasName = commandOrAliasNamex;
  if (!commandOrAliasName && defaultSub) {
    commandOrAliasName = defaultSub;
  }
  // If we got at least some args, then lets find out if we can find a command.
  if (commandOrAliasName) {
    const alias = aliases[commandOrAliasName];
    // First: Resolve argv data from alias if its an alias that's been given.
    const [commandName, ...commandArgv] = alias ? [...alias.argv, ...rawCommandArgv] : [commandOrAliasName, ...rawCommandArgv];
    // Second: Find a command definition using that data.
    const commandDefinition = commandName ? subcommands[commandName] : undefined;
    // Third: If a valid command has been found, then we run it...
    if (commandDefinition) {
      return await commandDefinition.run(commandArgv, importMeta, {
        parentName: name
      });
    }
  }
  const flags = {
    ...commonFlags,
    ...additionalOptions.flags
  };
  // ...else we provide basic instructions and help.

  emitBanner(name);
  const cli = meow(`
    Usage
      $ ${name} <command>

    Commands
      ${getHelpListOutput({
    ...objects.toSortedObject(Object.fromEntries(Object.entries(subcommands).filter(({
      1: subcommand
    }) => !subcommand.hidden))),
    ...objects.toSortedObject(Object.fromEntries(Object.entries(aliases).filter(({
      1: alias
    }) => {
      const {
        hidden
      } = alias;
      const cmdName = hidden ? '' : alias.argv[0];
      const subcommand = cmdName ? subcommands[cmdName] : undefined;
      return subcommand && !subcommand.hidden;
    })))
  }, 6)}

    Options
      ${getFlagListOutput(flags, 6)}

    Examples
      $ ${name} --help
  `, {
    argv,
    importMeta,
    ...additionalOptions,
    flags,
    autoHelp: false // otherwise we can't exit(0)
  });
  if (!cli.flags['help'] && cli.flags['dryRun']) {
    process.exitCode = 0;
    logger.logger.log(`${DRY_RUN_LABEL$1}: No-op, call a sub-command; ok`);
  } else {
    cli.showHelp();
  }
}

/**
 * Note: meow will exit immediately if it calls its .showHelp()
 */
function meowOrExit({
  allowUnknownFlags,
  // commands that pass-through args need to allow this
  argv,
  config,
  importMeta,
  parentName
}) {
  const command = `${parentName} ${config.commandName}`;
  emitBanner(command);

  // This exits if .printHelp() is called either by meow itself or by us.
  const cli = meow({
    argv,
    description: config.description,
    help: config.help(command, config),
    importMeta,
    flags: config.flags,
    allowUnknownFlags: Boolean(allowUnknownFlags),
    autoHelp: false // otherwise we can't exit(0)
  });
  if (cli.flags['help']) {
    cli.showHelp();
  }
  return cli;
}
function emitBanner(name) {
  // Print a banner at the top of each command.
  // This helps with brand recognition and marketing.
  // It also helps with debugging since it contains version and command details.
  // Note: print over stderr to preserve stdout for flags like --json and
  //       --markdown. If we don't do this, you can't use --json in particular
  //       and pipe the result to other tools. By emitting the banner over stderr
  //       you can do something like `socket scan view xyz | jq | process`.
  //       The spinner also emits over stderr for example.
  logger.logger.error(getAsciiHeader(name));
}
function getAsciiHeader(command) {
  const cliVersion = // The '@rollup/plugin-replace' will replace "process.env['INLINED_SOCKET_CLI_VERSION_HASH']".
  "0.14.65:ace6cae:00eaf610:pub";
  const nodeVersion = process.version;
  const apiToken = shadowNpmInject.getSetting('apiToken');
  const shownToken = apiToken ? getLastFiveOfApiToken(apiToken) : 'no';
  const relCwd = path.normalizePath(process.cwd().replace(new RegExp(`^${regexps.escapeRegExp(constants.homePath)}(?:${path$1.sep}|$)`, 'i'), '~/'));
  const body = `
   _____         _       _        /---------------
  |   __|___ ___| |_ ___| |_      | Socket.dev CLI ver ${cliVersion}
  |__   | . |  _| '_| -_|  _|     | Node: ${nodeVersion}, API token set: ${shownToken}
  |_____|___|___|_,_|___|_|.dev   | Command: \`${command}\`, cwd: ${relCwd}`.trimStart();
  return `   ${body}\n`;
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$B
} = constants;
const config$C = {
  commandName: 'analytics',
  description: `Look up analytics data`,
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags,
    file: {
      type: 'string',
      shortFlag: 'f',
      default: '-',
      description: 'Path to a local file to save the output. Only valid with --json/--markdown. Defaults to stdout.'
    },
    repo: {
      type: 'string',
      shortFlag: 'r',
      default: '',
      description: 'Name of the repository. Only valid when scope=repo'
    },
    scope: {
      type: 'string',
      shortFlag: 's',
      default: 'org',
      description: "Scope of the analytics data - either 'org' or 'repo', default: org"
    },
    time: {
      type: 'number',
      shortFlag: 't',
      default: 7,
      description: 'Time filter - either 7, 30 or 90, default: 7'
    }
  },
  help: (command, {
    flags
  }) => `
    Usage
      $ ${command} --scope=<scope> --time=<time filter>

    Default parameters are set to show the organization-level analytics over the
    last 7 days.

    Options
      ${getFlagListOutput(flags, 6)}

    Examples
      $ ${command} --scope=org --time=7
      $ ${command} --scope=org --time=30
      $ ${command} --scope=repo --repo=test-repo --time=30
  `
};
const cmdAnalytics = {
  description: config$C.description,
  hidden: config$C.hidden,
  run: run$C
};
async function run$C(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$C,
    importMeta,
    parentName
  });
  const {
    file,
    json,
    markdown,
    repo,
    scope,
    time
  } = cli.flags;
  const badScope = scope !== 'org' && scope !== 'repo';
  const badTime = time !== 7 && time !== 30 && time !== 90;
  const badRepo = scope === 'repo' && !repo;
  const badFile = file !== '-' && !json && !markdown;
  const badFlags = json && markdown;
  if (badScope || badTime || badRepo || badFile || badFlags) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Scope must be "repo" or "org" ${badScope ? colors.red('(bad!)') : colors.green('(ok)')}

      - The time filter must either be 7, 30 or 90 ${badTime ? colors.red('(bad!)') : colors.green('(ok)')}

      ${scope === 'repo' ? `- Repository name using --repo when scope is "repo" ${badRepo ? colors.red('(bad!)') : colors.green('(ok)')}` : ''}

      ${badFlags ? `- The \`--json\` and \`--markdown\` flags can not be used at the same time ${badFlags ? colors.red('(bad!)') : colors.green('(ok)')}` : ''}

      ${badFile ? `- The \`--file\` flag is only valid when using \`--json\` or \`--markdown\` ${badFile ? colors.red('(bad!)') : colors.green('(ok)')}` : ''}
    `.split('\n').filter(s => !!s.trim()).join('\n'));
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$B);
    return;
  }
  return await displayAnalytics({
    scope,
    time,
    repo: String(repo || ''),
    outputKind: json ? 'json' : markdown ? 'markdown' : 'print',
    filePath: String(file || '')
  });
}

async function fetchAuditLog({
  logType,
  orgSlug,
  outputKind,
  page,
  perPage
}) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchAuditLogWithToken(apiToken, {
    logType,
    orgSlug,
    outputKind,
    page,
    perPage
  });
}
async function fetchAuditLogWithToken(apiToken, {
  logType,
  orgSlug,
  outputKind,
  page,
  perPage
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start(`Looking up audit log for ${orgSlug}`);
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const result = await handleApiCall(socketSdk.getAuditLogEvents(orgSlug, {
    // I'm not sure this is used at all.
    outputJson: String(outputKind === 'json'),
    // I'm not sure this is used at all.
    outputMarkdown: String(outputKind === 'markdown'),
    orgSlug,
    type: logType,
    page: String(page),
    per_page: String(perPage)
  }), `Looking up audit log for ${orgSlug}\n`);
  if (!result.success) {
    handleUnsuccessfulApiResponse('getAuditLogEvents', result);
    return;
  }
  spinner.stop();
  return result.data;
}

async function outputAuditLog(auditLogs, {
  logType,
  orgSlug,
  outputKind,
  page,
  perPage
}) {
  if (outputKind === 'json') {
    await outputAsJson(auditLogs.results, orgSlug, logType, page, perPage);
  } else if (outputKind === 'markdown') {
    await outputAsMarkdown(auditLogs.results, orgSlug, logType, page, perPage);
  } else {
    await outputAsPrint(auditLogs.results, orgSlug, logType);
  }
}
async function outputAsJson(auditLogs, orgSlug, logType, page, perPage) {
  let json;
  try {
    json = JSON.stringify({
      desc: 'Audit logs for given query',
      generated: new Date().toISOString(),
      org: orgSlug,
      logType,
      page,
      perPage,
      logs: auditLogs.map(log => {
        // Note: The subset is pretty arbitrary
        const {
          created_at,
          event_id,
          ip_address,
          type,
          user_agent,
          user_email
        } = log;
        return {
          event_id,
          created_at,
          ip_address,
          type,
          user_agent,
          user_email
        };
      })
    }, null, 2);
  } catch (e) {
    process.exitCode = 1;
    logger.logger.fail('There was a problem converting the logs to JSON, please try without the `--json` flag');
    return;
  }
  logger.logger.log(json);
}
async function outputAsMarkdown(auditLogs, orgSlug, logType, page, perPage) {
  try {
    const table = mdTable(auditLogs, ['event_id', 'created_at', 'type', 'user_email', 'ip_address', 'user_agent']);
    logger.logger.log(commonTags.stripIndents`
# Socket Audit Logs

These are the Socket.dev audit logs as per requested query.
- org: ${orgSlug}
- type filter: ${logType || '(none)'}
- page: ${page}
- per page: ${perPage}
- generated: ${new Date().toISOString()}

${table}
`);
  } catch (e) {
    process.exitCode = 1;
    logger.logger.fail('There was a problem converting the logs to JSON, please try without the `--json` flag');
    logger.logger.error(e);
    return;
  }
}
async function outputAsPrint(auditLogs, orgSlug, logType) {
  const data = [];
  const logDetails = {};
  for (const d of auditLogs) {
    const {
      created_at
    } = d;
    if (created_at) {
      const name = `${new Date(created_at).toLocaleDateString('en-us', {
        year: 'numeric',
        month: 'numeric',
        day: 'numeric'
      })} - ${d.user_email} - ${d.type} - ${d.ip_address} - ${d.user_agent}`;
      data.push({
        name
      }, new prompts.Separator());
      logDetails[name] = JSON.stringify(d.payload);
    }
  }
  logger.logger.log(logDetails[await prompts.select({
    message: logType ? `\n Audit log for: ${orgSlug} with type: ${logType}\n` : `\n Audit log for: ${orgSlug}\n`,
    choices: data,
    pageSize: 30
  })]);
}

async function handleAuditLog({
  logType,
  orgSlug,
  outputKind,
  page,
  perPage
}) {
  const auditLogs = await fetchAuditLog({
    orgSlug,
    outputKind,
    page,
    perPage,
    logType
  });
  if (!auditLogs) return;
  await outputAuditLog(auditLogs, {
    logType,
    orgSlug,
    outputKind,
    page,
    perPage
  });
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$A
} = constants;
const config$B = {
  commandName: 'audit-log',
  description: 'Look up the audit log for an organization',
  hidden: false,
  flags: {
    type: {
      type: 'string',
      shortFlag: 't',
      default: '',
      description: 'Type of log event'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Results per page - default is 30'
    },
    page: {
      type: 'number',
      shortFlag: 'p',
      default: 1,
      description: 'Page number - default is 1'
    },
    ...commonFlags,
    ...outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    This feature requires an Enterprise Plan. To learn more about getting access
    to this feature and many more, please visit https://socket.dev/pricing

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg
  `
};
const cmdAuditLog = {
  description: config$B.description,
  hidden: config$B.hidden,
  run: run$B
};
async function run$B(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$B,
    importMeta,
    parentName
  });
  const {
    json,
    markdown,
    page,
    perPage,
    type
  } = cli.flags;
  const logType = String(type || '');
  const [orgSlug = ''] = cli.input;
  if (!orgSlug) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
      ${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:\n
      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}
    `);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$A);
    return;
  }
  await handleAuditLog({
    orgSlug,
    outputKind: json ? 'json' : markdown ? 'markdown' : 'print',
    page: Number(page || 0),
    perPage: Number(perPage || 0),
    logType: logType.charAt(0).toUpperCase() + logType.slice(1)
  });
}

const {
  NPM: NPM$f,
  NPX: NPX$3,
  PACKAGE_LOCK_JSON,
  PNPM: PNPM$a,
  YARN: YARN$1,
  YARN_LOCK
} = constants;
const nodejsPlatformTypes = new Set(['javascript', 'js', 'nodejs', NPM$f, PNPM$a, 'ts', 'tsx', 'typescript']);
async function runCycloneDX(yargvWithYes) {
  let cleanupPackageLock = false;
  const {
    yes,
    ...yargv
  } = {
    __proto__: null,
    ...yargvWithYes
  };
  const yesArgs = yes ? ['--yes'] : [];
  if (yargv.type !== YARN$1 && nodejsPlatformTypes.has(yargv.type) && fs$1.existsSync(`./${YARN_LOCK}`)) {
    if (fs$1.existsSync(`./${PACKAGE_LOCK_JSON}`)) {
      yargv.type = NPM$f;
    } else {
      // Use synp to create a package-lock.json from the yarn.lock,
      // based on the node_modules folder, for a more accurate SBOM.
      try {
        await shadowBin(NPX$3, [...yesArgs,
        // The '@rollup/plugin-replace' will replace "process.env['INLINED_SYNP_VERSION']".
        `synp@${"^1.9.14"}`, '--source-file', `./${YARN_LOCK}`]);
        yargv.type = NPM$f;
        cleanupPackageLock = true;
      } catch {}
    }
  }
  await shadowBin(NPX$3, [...yesArgs,
  // The '@rollup/plugin-replace' will replace "process.env['INLINED_CYCLONEDX_CDXGEN_VERSION']".
  `@cyclonedx/cdxgen@${"^11.2.2"}`, ...argvToArray(yargv)]);
  if (cleanupPackageLock) {
    try {
      await fs$1.promises.rm(`./${PACKAGE_LOCK_JSON}`);
    } catch {}
  }
  const fullOutputPath = path$1.join(process$1.cwd(), yargv.output);
  if (fs$1.existsSync(fullOutputPath)) {
    logger.logger.log(colors.cyanBright(`${yargv.output} created!`));
  }
}
function argvToArray(argv) {
  if (argv['help']) {
    return ['--help'];
  }
  const result = [];
  for (const {
    0: key,
    1: value
  } of Object.entries(argv)) {
    if (key === '_' || key === '--') {
      continue;
    }
    if (key === 'babel' || key === 'install-deps' || key === 'validate') {
      // cdxgen documents no-babel, no-install-deps, and no-validate flags so
      // use them when relevant.
      result.push(`--${value ? key : `no-${key}`}`);
    } else if (value === true) {
      result.push(`--${key}`);
    } else if (typeof value === 'string') {
      result.push(`--${key}`, String(value));
    } else if (Array.isArray(value)) {
      result.push(`--${key}`, ...value.map(String));
    }
  }
  if (argv['--']) {
    result.push('--', ...argv['--']);
  }
  return result;
}

const helpFlags = new Set(['--help', '-h']);
function cmdFlagsToString(args) {
  const result = [];
  for (let i = 0, {
      length
    } = args; i < length; i += 1) {
    if (args[i].startsWith('--')) {
      // Check if the next item exists and is NOT another flag.
      if (i + 1 < length && !args[i + 1].startsWith('--')) {
        result.push(`${args[i]}=${args[i + 1]}`);
        i += 1;
      } else {
        result.push(args[i]);
      }
    }
  }
  return result.join(' ');
}
function cmdPrefixMessage(cmdName, text) {
  const cmdPrefix = cmdName ? `${cmdName}: ` : '';
  return `${cmdPrefix}${text}`;
}
function isHelpFlag(cmdArg) {
  return helpFlags.has(cmdArg);
}

// import { meowOrExit } from '../../utils/meow-with-subcommands'
const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$z
} = constants;

// TODO: convert yargs to meow. Or convert all the other things to yargs.
const toLower = arg => arg.toLowerCase();
const arrayToLower = arg => arg.map(toLower);
const yargsConfig = {
  configuration: {
    'camel-case-expansion': false,
    'strip-aliased': true,
    'parse-numbers': false,
    'populate--': true,
    'unknown-options-as-args': true
  },
  coerce: {
    author: arrayToLower,
    filter: arrayToLower,
    only: arrayToLower,
    profile: toLower,
    standard: arrayToLower,
    type: toLower
  },
  default: {
    //author: ['OWASP Foundation'],
    //'auto-compositions': true,
    //babel: true,
    //evidence: false,
    //'include-crypto': false,
    //'include-formulation': false,

    // Default 'install-deps' to `false` and 'lifecycle' to 'pre-build' to
    // sidestep arbitrary code execution during a cdxgen scan.
    // https://github.com/CycloneDX/cdxgen/issues/1328
    'install-deps': false,
    lifecycle: 'pre-build',
    //output: 'bom.json',
    //profile: 'generic',
    //'project-version': '',
    //recurse: true,
    //'server-host': '127.0.0.1',
    //'server-port': '9090',
    //'spec-version': '1.5',
    type: 'js'
    //validate: true,
  },
  alias: {
    help: ['h'],
    output: ['o'],
    print: ['p'],
    recurse: ['r'],
    'resolve-class': ['c'],
    type: ['t'],
    version: ['v'],
    yes: ['y']
  },
  array: [{
    key: 'author',
    type: 'string'
  }, {
    key: 'exclude',
    type: 'string'
  }, {
    key: 'filter',
    type: 'string'
  }, {
    key: 'only',
    type: 'string'
  }, {
    key: 'standard',
    type: 'string'
  }],
  boolean: ['auto-compositions', 'babel', 'deep', 'evidence', 'fail-on-error', 'generate-key-and-sign', 'help', 'include-formulation', 'include-crypto', 'install-deps', 'print', 'required-only', 'server', 'validate', 'version',
  // The --yes flag and -y alias map to the corresponding flag and alias of npx.
  // https://docs.npmjs.com/cli/v7/commands/npx#compatibility-with-older-npx-versions
  'yes'],
  string: ['api-key', 'lifecycle', 'output', 'parent-project-id', 'profile', 'project-group', 'project-name', 'project-version', 'project-id', 'server-host', 'server-port', 'server-url', 'spec-version']
};
const config$A = {
  commandName: 'cdxgen',
  description: 'Create an SBOM with CycloneDX generator (cdxgen)',
  hidden: false,
  flags: {
    // TODO: convert from yargsConfig
  },
  help: (command, config) => `
    Usage
      $ ${command} [options]

    Options
      ${getFlagListOutput(config.flags, 6)}
  `
};
const cmdCdxgen = {
  description: config$A.description,
  hidden: config$A.hidden,
  run: run$A
};
async function run$A(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    allowUnknownFlags: true,
    // Don't let meow take over --help.
    argv: argv.filter(a => !isHelpFlag(a)),
    config: config$A,
    importMeta,
    parentName
  });
  // if (cli.input.length)
  //   logger.fail(
  //     stripIndents`
  //       ${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:
  //
  //       - Unexpected arguments
  //   `)
  //   config.help(parentName, config)
  //   return
  // }

  // TODO: Convert to meow.
  const yargv = {
    ...yargsParse(argv, yargsConfig)
  };
  const unknown = yargv._;
  const {
    length: unknownLength
  } = unknown;
  if (unknownLength) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process$1.exitCode = 2;
    logger.logger.fail(`Unknown ${words.pluralize('argument', unknownLength)}: ${yargv._.join(', ')}`);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$z);
    return;
  }
  if (yargv.output === undefined) {
    yargv.output = 'socket-cdx.json';
  }
  await runCycloneDX(yargv);
}

async function fetchDependencies({
  limit,
  offset
}) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchDependenciesWithToken(apiToken, {
    limit,
    offset
  });
}
async function fetchDependenciesWithToken(apiToken, {
  limit,
  offset
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Fetching organization dependencies...');
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const result = await handleApiCall(socketSdk.searchDependencies({
    limit,
    offset
  }), 'Searching dependencies');
  spinner?.successAndStop('Received organization dependencies response.');
  if (!result.success) {
    handleUnsuccessfulApiResponse('searchDependencies', result);
    return;
  }
  return result.data;
}

// @ts-ignore
async function outputDependencies(data, {
  limit,
  offset,
  outputKind
}) {
  if (outputKind === 'json') {
    let json;
    try {
      json = JSON.stringify(data, null, 2);
    } catch (e) {
      process.exitCode = 1;
      logger.logger.fail('There was a problem converting the data to JSON, please try without the `--json` flag');
      return;
    }
    logger.logger.log(json);
    return;
  }
  logger.logger.log('Request details: Offset:', offset, ', limit:', limit, ', is there more data after this?', data.end ? 'no' : 'yes');
  const options = {
    columns: [{
      field: 'namespace',
      name: colors.cyan('Namespace')
    }, {
      field: 'name',
      name: colors.cyan('Name')
    }, {
      field: 'version',
      name: colors.cyan('Version')
    }, {
      field: 'repository',
      name: colors.cyan('Repository')
    }, {
      field: 'branch',
      name: colors.cyan('Branch')
    }, {
      field: 'type',
      name: colors.cyan('Type')
    }, {
      field: 'direct',
      name: colors.cyan('Direct')
    }]
  };
  logger.logger.log(chalkTable(options, data.rows));
}

async function handleDependencies({
  limit,
  offset,
  outputKind
}) {
  const data = await fetchDependencies({
    limit,
    offset
  });
  if (!data) return;
  await outputDependencies(data, {
    limit,
    offset,
    outputKind
  });
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$y
} = constants;
const config$z = {
  commandName: 'dependencies',
  description: 'Search for any dependency that is being used in your organization',
  hidden: false,
  flags: {
    ...commonFlags,
    limit: {
      type: 'number',
      shortFlag: 'l',
      default: 50,
      description: 'Maximum number of dependencies returned'
    },
    offset: {
      type: 'number',
      shortFlag: 'o',
      default: 0,
      description: 'Page number'
    },
    ...outputFlags
  },
  help: (command, config) => `
    Usage
      ${command}

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      ${command} --limit 20 --offset 10
  `
};
const cmdScanCreate$1 = {
  description: config$z.description,
  hidden: config$z.hidden,
  run: run$z
};
async function run$z(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$z,
    importMeta,
    parentName
  });
  const {
    json,
    limit,
    markdown,
    offset
  } = cli.flags;
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$y);
    return;
  }
  await handleDependencies({
    limit: Number(limit || 0) || 0,
    offset: Number(offset || 0) || 0,
    outputKind: json ? 'json' : markdown ? 'markdown' : 'text'
  });
}

async function fetchDiffScan({
  after,
  before,
  orgSlug
}) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchDiffScanWithToken(apiToken, {
    after,
    before,
    orgSlug
  });
}
async function fetchDiffScanWithToken(apiToken, {
  after,
  before,
  orgSlug
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Fetching diff-scan...');
  const response = await queryAPI(`orgs/${orgSlug}/full-scans/diff?before=${encodeURIComponent(before)}&after=${encodeURIComponent(after)}`, apiToken);
  spinner?.successAndStop('Received diff-scan response');
  if (!response.ok) {
    const err = await handleAPIError(response.status);
    spinner.errorAndStop(`${colors.bgRed(colors.white(response.statusText))}: ${err}`);
    return;
  }
  const result = await handleApiCall(await response.json(), 'Deserializing json');
  return result;
}

async function outputDiffScan(result, {
  depth,
  file,
  outputKind
}) {
  const dashboardUrl = result.diff_report_url;
  const dashboardMessage = dashboardUrl ? `\n View this diff scan in the Socket dashboard: ${colors.cyan(dashboardUrl)}` : '';

  // When forcing json, or dumping to file, serialize to string such that it
  // won't get truncated. The only way to dump the full raw JSON to stdout is
  // to use `--json --file -` (the dash is a standard notation for stdout)
  if (outputKind === 'json' || file) {
    let json;
    try {
      json = JSON.stringify(result, null, 2);
    } catch (e) {
      process.exitCode = 1;
      // Most likely caused by a circular reference (or OOM)
      logger.logger.fail('There was a problem converting the data to JSON');
      logger.logger.error(e);
      return;
    }
    if (file && file !== '-') {
      logger.logger.log(`Writing json to \`${file}\``);
      fs$1.writeFile(file, JSON.stringify(result, null, 2), err => {
        if (err) {
          logger.logger.fail(`Writing to \`${file}\` failed...`);
          logger.logger.error(err);
        } else {
          logger.logger.log(`Data successfully written to \`${file}\``);
        }
        logger.logger.error(dashboardMessage);
      });
    } else {
      // TODO: expose different method for writing to stderr when simply dodging stdout
      logger.logger.error(`\n Diff scan result: \n`);
      logger.logger.log(json);
      logger.logger.error(dashboardMessage);
    }
    return;
  }

  // In this case neither the --json nor the --file flag was passed
  // Dump the JSON to CLI and let NodeJS deal with truncation

  logger.logger.log('Diff scan result:');
  logger.logger.log(util.inspect(result, {
    showHidden: false,
    depth: depth > 0 ? depth : null,
    colors: true,
    maxArrayLength: null
  }));
  logger.logger.log(`\n ðŸ“ To display the detailed report in the terminal, use the --json flag \n`);
  logger.logger.log(dashboardMessage);
}

async function handleDiffScan({
  after,
  before,
  depth,
  file,
  orgSlug,
  outputKind
}) {
  const data = await fetchDiffScan({
    after,
    before,
    orgSlug
  });
  if (!data) return;
  await outputDiffScan(data, {
    depth,
    file,
    outputKind
  });
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$x
} = constants;
const config$y = {
  commandName: 'get',
  description: 'Get a diff scan for an organization',
  hidden: false,
  flags: {
    ...commonFlags,
    after: {
      type: 'string',
      shortFlag: 'a',
      default: '',
      description: 'The full scan ID of the head scan'
    },
    before: {
      type: 'string',
      shortFlag: 'b',
      default: '',
      description: 'The full scan ID of the base scan'
    },
    depth: {
      type: 'number',
      default: 2,
      description: 'Max depth of JSON to display before truncating, use zero for no limit (without --json/--file)'
    },
    json: {
      type: 'boolean',
      shortFlag: 'j',
      default: false,
      description: 'Output result as json. This can be big. Use --file to store it to disk without truncation.'
    },
    file: {
      type: 'string',
      shortFlag: 'f',
      default: '',
      description: 'Path to a local file where the output should be saved. Use `-` to force stdout.'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug> --before=<before> --after=<after>

    This command displays the package changes between two scans. The full output
    can be pretty large depending on the size of your repo and time range. It is
    best stored to disk to be further analyzed by other tools.

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeCorp --before=aaa0aa0a-aaaa-0000-0a0a-0000000a00a0 --after=aaa1aa1a-aaaa-1111-1a1a-1111111a11a1
  `
};
const cmdDiffScanGet = {
  description: config$y.description,
  hidden: config$y.hidden,
  run: run$y
};
async function run$y(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$y,
    importMeta,
    parentName
  });
  const {
    after,
    before,
    depth,
    file,
    json,
    markdown
  } = cli.flags;
  const [orgSlug = ''] = cli.input;
  if (!before || !after || cli.input.length < 1) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:\n
      - Specify a before and after full scan ID ${!before && !after ? colors.red('(missing before and after!)') : !before ? colors.red('(missing before!)') : !after ? colors.red('(missing after!)') : colors.green('(ok)')}\n
          - To get full scans IDs, you can run the command "socket scan list <your org slug>".
            The args are expecting a full \`aaa0aa0a-aaaa-0000-0a0a-0000000a00a0\` ID.\n
      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}\n`);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$x);
    return;
  }
  await handleDiffScan({
    before: String(before || ''),
    after: String(after || ''),
    depth: Number(depth),
    orgSlug,
    outputKind: json ? 'json' : markdown ? 'markdown' : 'text',
    file: String(file || '')
  });
}

const description$6 = 'Diff scans related commands';
const cmdDiffScan = {
  description: description$6,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: true,
  async run(argv, importMeta, {
    parentName
  }) {
    await meowWithSubcommands({
      get: cmdDiffScanGet
    }, {
      argv,
      description: description$6,
      importMeta,
      name: parentName + ' diff-scan'
    });
  }
};

const {
  NPM: NPM$e
} = constants;
function isTopLevel(tree, node) {
  return tree.children.get(node.name) === node;
}
async function npmFix(_pkgEnvDetails, cwd, options) {
  const {
    spinner
  } = {
    __proto__: null,
    ...options
  };
  spinner?.start();
  const arb = new shadowNpmInject.SafeArborist({
    path: cwd,
    ...shadowNpmInject.SAFE_ARBORIST_REIFY_OPTIONS_OVERRIDES
  });
  await arb.reify();
  const alertsMap = await shadowNpmInject.getAlertsMapFromArborist(arb, {
    consolidate: true,
    include: {
      existing: true,
      unfixable: false,
      upgrade: false
    }
  });
  const infoByPkg = shadowNpmInject.getCveInfoByAlertsMap(alertsMap);
  if (!infoByPkg) {
    spinner?.stop();
    return;
  }
  await arb.buildIdealTree();
  const editablePkgJson = await packages.readPackageJson(cwd, {
    editable: true
  });
  for (const {
    0: name,
    1: infos
  } of infoByPkg) {
    const revertToIdealTree = arb.idealTree;
    arb.idealTree = null;
    // eslint-disable-next-line no-await-in-loop
    await arb.buildIdealTree();
    const tree = arb.idealTree;
    const hasUpgrade = !!registry.getManifestData(NPM$e, name);
    if (hasUpgrade) {
      spinner?.info(`Skipping ${name}. Socket Optimize package exists.`);
      continue;
    }
    const nodes = shadowNpmInject.findPackageNodes(tree, name);
    const packument = nodes.length && infos.length ?
    // eslint-disable-next-line no-await-in-loop
    await packages.fetchPackagePackument(name) : null;
    if (!packument) {
      continue;
    }
    for (let i = 0, {
        length: nodesLength
      } = nodes; i < nodesLength; i += 1) {
      const node = nodes[i];
      for (let j = 0, {
          length: infosLength
        } = infos; j < infosLength; j += 1) {
        const {
          firstPatchedVersionIdentifier,
          vulnerableVersionRange
        } = infos[j];
        const {
          version: oldVersion
        } = node;
        if (shadowNpmInject.updateNode(node, packument, vulnerableVersionRange)) {
          try {
            // eslint-disable-next-line no-await-in-loop
            await npm.runScript('test', [], {
              spinner,
              stdio: 'ignore'
            });
            spinner?.info(`Patched ${name} ${oldVersion} -> ${node.version}`);
            if (isTopLevel(tree, node)) {
              for (const depField of ['dependencies', 'optionalDependencies', 'peerDependencies']) {
                const {
                  content: pkgJson
                } = editablePkgJson;
                const oldVersion = pkgJson[depField]?.[name];
                if (oldVersion) {
                  const decorator = /^[~^]/.exec(oldVersion)?.[0] ?? '';
                  pkgJson[depField][name] = `${decorator}${node.version}`;
                }
              }
            }
            // eslint-disable-next-line no-await-in-loop
            await editablePkgJson.save();
          } catch {
            spinner?.error(`Reverting ${name} to ${oldVersion}`);
            arb.idealTree = revertToIdealTree;
          }
        } else {
          spinner?.error(`Could not patch ${name} ${oldVersion}`);
        }
      }
    }
  }
  const arb2 = new shadowNpmInject.Arborist({
    path: cwd
  });
  arb2.idealTree = arb.idealTree;
  await arb2.reify();
  spinner?.stop();
}

async function getAlertsMapFromPnpmLockfile(lockfile, options) {
  const {
    include: _include,
    spinner
  } = {
    __proto__: null,
    ...options
  };
  const include = {
    __proto__: null,
    unfixable: true,
    ..._include
  };
  const depTypes = lockfile_detectDepTypes.detectDepTypes(lockfile);
  const pkgIds = Object.keys(depTypes);
  let {
    length: remaining
  } = pkgIds;
  const alertsByPkgId = new Map();
  if (!remaining) {
    return alertsByPkgId;
  }
  const getText = () => `Looking up data for ${remaining} packages`;
  spinner?.start(getText());
  const socketSdk = await shadowNpmInject.setupSdk(shadowNpmInject.getPublicToken());
  const toAlertsMapOptions = {
    overrides: lockfile.overrides,
    ...options
  };
  for await (const batchPackageFetchResult of socketSdk.batchPackageStream({
    alerts: 'true',
    compact: 'true',
    fixable: include.unfixable ? 'false' : 'true'
  }, {
    components: pkgIds.map(id => ({
      purl: `pkg:npm/${id}`
    }))
  })) {
    if (batchPackageFetchResult.success) {
      await shadowNpmInject.addArtifactToAlertsMap(batchPackageFetchResult.data, alertsByPkgId, toAlertsMapOptions);
    }
    remaining -= 1;
    if (spinner && remaining > 0) {
      spinner.start();
      spinner.setText(getText());
    }
  }
  spinner?.stop();
  return alertsByPkgId;
}

const {
  SOCKET_IPC_HANDSHAKE
} = constants;
function safeNpmInstall(options) {
  const {
    agentExecPath = shadowNpmPaths.getNpmBinPath(),
    args = [],
    ipc,
    spinner,
    ...spawnOptions
  } = {
    __proto__: null,
    ...options
  };
  const useIpc = objects.isObject(ipc);
  const useDebug = debug.isDebug();
  const terminatorPos = args.indexOf('--');
  const binArgs = (terminatorPos === -1 ? args : args.slice(0, terminatorPos)).filter(a => !npm.isAuditFlag(a) && !npm.isFundFlag(a) && !npm.isProgressFlag(a));
  const otherArgs = terminatorPos === -1 ? [] : args.slice(terminatorPos);
  const isSilent = !useDebug && !binArgs.some(npm.isLoglevelFlag);
  const logLevelArgs = isSilent ? ['--loglevel', 'silent'] : [];
  const spawnPromise = spawn.spawn(
  // Lazily access constants.execPath.
  constants.execPath, [
  // Lazily access constants.nodeHardenFlags.
  ...constants.nodeHardenFlags,
  // Lazily access constants.nodeNoWarningsFlags.
  ...constants.nodeNoWarningsFlags,
  // Lazily access false.
  ...([]), '--require',
  // Lazily access constants.distShadowNpmInjectPath.
  constants.distShadowNpmInjectPath, agentExecPath, 'install',
  // Avoid code paths for 'audit' and 'fund'.
  '--no-audit', '--no-fund',
  // Add '--no-progress' to fix input being swallowed by the npm spinner.
  '--no-progress',
  // Add '--loglevel=silent' if a loglevel flag is not provided and the
  // SOCKET_CLI_DEBUG environment variable is not truthy.
  ...logLevelArgs, ...binArgs, ...otherArgs], {
    spinner,
    // Set stdio to include 'ipc'.
    // See https://github.com/nodejs/node/blob/v23.6.0/lib/child_process.js#L161-L166
    // and https://github.com/nodejs/node/blob/v23.6.0/lib/internal/child_process.js#L238.
    stdio: useIpc ? [0, 1, 2, 'ipc'] : 'inherit',
    ...spawnOptions,
    env: {
      ...process$1.env,
      ...spawnOptions.env
    }
  });
  if (useIpc) {
    spawnPromise.process.send({
      [SOCKET_IPC_HANDSHAKE]: ipc
    });
  }
  return spawnPromise;
}

const {
  NPM: NPM$d
} = constants;
function runAgentInstall(pkgEnvDetails, options) {
  const {
    agent,
    agentExecPath
  } = pkgEnvDetails;
  // All package managers support the "install" command.
  if (agent === NPM$d) {
    return safeNpmInstall({
      agentExecPath,
      ...options
    });
  }
  const {
    args = [],
    spinner,
    ...spawnOptions
  } = {
    __proto__: null,
    ...options
  };
  return spawn.spawn(agentExecPath, ['install', ...args], {
    spinner,
    stdio: debug.isDebug() ? 'inherit' : 'ignore',
    ...spawnOptions,
    env: {
      ...process.env,
      NODE_OPTIONS: cmdFlagsToString([
      // Lazily access constants.nodeHardenFlags.
      ...constants.nodeHardenFlags,
      // Lazily access constants.nodeNoWarningsFlags.
      ...constants.nodeNoWarningsFlags]),
      ...spawnOptions.env
    }
  });
}

const {
  NPM: NPM$c,
  OVERRIDES: OVERRIDES$2,
  PNPM: PNPM$9
} = constants;
async function pnpmFix(pkgEnvDetails, cwd, options) {
  const {
    spinner
  } = {
    __proto__: null,
    ...options
  };
  spinner?.start();
  const lockfile = await lockfileFile.readWantedLockfile(cwd, {
    ignoreIncompatible: false
  });
  if (!lockfile) {
    spinner?.stop();
    return;
  }
  const alertsMap = await getAlertsMapFromPnpmLockfile(lockfile, {
    consolidate: true,
    include: {
      existing: true,
      unfixable: false,
      upgrade: false
    }
  });
  const infoByPkg = shadowNpmInject.getCveInfoByAlertsMap(alertsMap);
  if (!infoByPkg) {
    spinner?.stop();
    return;
  }
  const arb = new shadowNpmInject.SafeArborist({
    path: cwd,
    ...shadowNpmInject.SAFE_ARBORIST_REIFY_OPTIONS_OVERRIDES
  });
  await arb.loadActual();
  const editablePkgJson = await packages.readPackageJson(cwd, {
    editable: true
  });
  const {
    content: pkgJson
  } = editablePkgJson;
  for (const {
    0: name,
    1: infos
  } of infoByPkg) {
    const tree = arb.actualTree;
    const hasUpgrade = !!registry.getManifestData(NPM$c, name);
    if (hasUpgrade) {
      spinner?.info(`Skipping ${name}. Socket Optimize package exists.`);
      continue;
    }
    const nodes = shadowNpmInject.findPackageNodes(tree, name);
    const packument = nodes.length && infos.length ?
    // eslint-disable-next-line no-await-in-loop
    await packages.fetchPackagePackument(name) : null;
    if (!packument) {
      continue;
    }
    for (let i = 0, {
        length: nodesLength
      } = nodes; i < nodesLength; i += 1) {
      const node = nodes[i];
      for (let j = 0, {
          length: infosLength
        } = infos; j < infosLength; j += 1) {
        const {
          firstPatchedVersionIdentifier,
          vulnerableVersionRange
        } = infos[j];
        const {
          version: oldVersion
        } = node;
        const availableVersions = Object.keys(packument.versions);
        // Find the highest non-vulnerable version within the same major range
        const targetVersion = shadowNpmInject.findBestPatchVersion(node, availableVersions, vulnerableVersionRange);
        const targetPackument = targetVersion ? packument.versions[targetVersion] : undefined;
        if (targetPackument) {
          const oldPnpm = pkgJson[PNPM$9];
          const oldOverrides = oldPnpm?.[OVERRIDES$2];
          try {
            editablePkgJson.update({
              [PNPM$9]: {
                ...oldPnpm,
                [OVERRIDES$2]: {
                  [`${node.name}@${vulnerableVersionRange}`]: `^${targetVersion}`,
                  ...oldOverrides
                }
              }
            });
            spinner?.info(`Patched ${name} ${oldVersion} -> ${node.version}`);

            // eslint-disable-next-line no-await-in-loop
            await editablePkgJson.save();
            // eslint-disable-next-line no-await-in-loop
            await runAgentInstall(pkgEnvDetails, {
              spinner
            });
          } catch {
            spinner?.error(`Reverting ${name} to ${oldVersion}`);
          }
        } else {
          spinner?.error(`Could not patch ${name} ${oldVersion}`);
        }
      }
    }
  }
  spinner?.stop();
}

const {
  BINARY_LOCK_EXT,
  BUN: BUN$5,
  HIDDEN_PACKAGE_LOCK_JSON,
  LOCK_EXT: LOCK_EXT$1,
  NPM: NPM$b,
  NPM_BUGGY_OVERRIDES_PATCHED_VERSION: NPM_BUGGY_OVERRIDES_PATCHED_VERSION$1,
  PACKAGE_JSON,
  PNPM: PNPM$8,
  VLT: VLT$5,
  YARN,
  YARN_BERRY: YARN_BERRY$5,
  YARN_CLASSIC: YARN_CLASSIC$6
} = constants;
const AGENTS = [BUN$5, NPM$b, PNPM$8, YARN_BERRY$5, YARN_CLASSIC$6, VLT$5];
const binByAgent = new Map([[BUN$5, BUN$5], [NPM$b, NPM$b], [PNPM$8, PNPM$8], [YARN_BERRY$5, YARN], [YARN_CLASSIC$6, YARN], [VLT$5, VLT$5]]);
async function getAgentExecPath(agent) {
  const binName = binByAgent.get(agent);
  return (await which(binName, {
    nothrow: true
  })) ?? binName;
}
async function getAgentVersion(agentExecPath, cwd) {
  let result;
  try {
    result =
    // Coerce version output into a valid semver version by passing it through
    // semver.coerce which strips leading v's, carets (^), comparators (<,<=,>,>=,=),
    // and tildes (~).
    semver.coerce(
    // All package managers support the "--version" flag.
    (await spawn.spawn(agentExecPath, ['--version'], {
      cwd
    })).stdout) ?? undefined;
  } catch {}
  return result;
}

// The order of LOCKS properties IS significant as it affects iteration order.
const LOCKS = {
  [`bun${LOCK_EXT$1}`]: BUN$5,
  [`bun${BINARY_LOCK_EXT}`]: BUN$5,
  // If both package-lock.json and npm-shrinkwrap.json are present in the root
  // of a project, npm-shrinkwrap.json will take precedence and package-lock.json
  // will be ignored.
  // https://docs.npmjs.com/cli/v10/configuring-npm/package-lock-json#package-lockjson-vs-npm-shrinkwrapjson
  'npm-shrinkwrap.json': NPM$b,
  'package-lock.json': NPM$b,
  'pnpm-lock.yaml': PNPM$8,
  'pnpm-lock.yml': PNPM$8,
  [`yarn${LOCK_EXT$1}`]: YARN_CLASSIC$6,
  'vlt-lock.json': VLT$5,
  // Lastly, look for a hidden lock file which is present if .npmrc has package-lock=false:
  // https://docs.npmjs.com/cli/v10/configuring-npm/package-lock-json#hidden-lockfiles
  //
  // Unlike the other LOCKS keys this key contains a directory AND filename so
  // it has to be handled differently.
  'node_modules/.package-lock.json': NPM$b
};
const readLockFileByAgent = (() => {
  function wrapReader(reader) {
    return async (...args) => {
      try {
        return await reader(...args);
      } catch {}
      return undefined;
    };
  }
  const binaryReader = wrapReader(shadowNpmInject.readFileBinary);
  const defaultReader = wrapReader(async lockPath => await shadowNpmInject.readFileUtf8(lockPath));
  return new Map([[BUN$5, wrapReader(async (lockPath, agentExecPath) => {
    const ext = path$1.extname(lockPath);
    if (ext === LOCK_EXT$1) {
      return await defaultReader(lockPath);
    }
    if (ext === BINARY_LOCK_EXT) {
      const lockBuffer = await binaryReader(lockPath);
      if (lockBuffer) {
        try {
          return index_cjs.parse(lockBuffer);
        } catch {}
      }
      // To print a Yarn lockfile to your console without writing it to disk
      // use `bun bun.lockb`.
      // https://bun.sh/guides/install/yarnlock
      return (await spawn.spawn(agentExecPath, [lockPath])).stdout.trim();
    }
    return undefined;
  })], [NPM$b, defaultReader], [PNPM$8, defaultReader], [VLT$5, defaultReader], [YARN_BERRY$5, defaultReader], [YARN_CLASSIC$6, defaultReader]]);
})();
async function detectPackageEnvironment({
  cwd = process$1.cwd(),
  onUnknown
} = {}) {
  let lockPath = await shadowNpmInject.findUp(Object.keys(LOCKS), {
    cwd
  });
  let lockName = lockPath ? path$1.basename(lockPath) : undefined;
  const isHiddenLockFile = lockName === HIDDEN_PACKAGE_LOCK_JSON;
  const pkgJsonPath = lockPath ? path$1.resolve(lockPath, `${isHiddenLockFile ? '../' : ''}../${PACKAGE_JSON}`) : await shadowNpmInject.findUp(PACKAGE_JSON, {
    cwd
  });
  const pkgPath = pkgJsonPath && fs$1.existsSync(pkgJsonPath) ? path$1.dirname(pkgJsonPath) : undefined;
  const editablePkgJson = pkgPath ? await packages.readPackageJson(pkgPath, {
    editable: true
  }) : undefined;
  const pkgJson = editablePkgJson?.content;
  // Read Corepack `packageManager` field in package.json:
  // https://nodejs.org/api/packages.html#packagemanager
  const pkgManager = strings.isNonEmptyString(pkgJson?.packageManager) ? pkgJson.packageManager : undefined;
  let agent;
  let agentVersion;
  if (pkgManager) {
    // A valid "packageManager" field value is "<package manager name>@<version>".
    // https://nodejs.org/api/packages.html#packagemanager
    const atSignIndex = pkgManager.lastIndexOf('@');
    if (atSignIndex !== -1) {
      const name = pkgManager.slice(0, atSignIndex);
      const version = pkgManager.slice(atSignIndex + 1);
      if (version && AGENTS.includes(name)) {
        agent = name;
      }
    }
  }
  if (agent === undefined && !isHiddenLockFile && typeof pkgJsonPath === 'string' && typeof lockName === 'string') {
    agent = LOCKS[lockName];
  }
  if (agent === undefined) {
    agent = NPM$b;
    onUnknown?.(pkgManager);
  }
  const agentExecPath = await getAgentExecPath(agent);
  const npmExecPath = agent === NPM$b ? agentExecPath : await getAgentExecPath(NPM$b);
  if (agentVersion === undefined) {
    agentVersion = await getAgentVersion(agentExecPath, cwd);
  }
  if (agent === YARN_CLASSIC$6 && (agentVersion?.major ?? 0) > 1) {
    agent = YARN_BERRY$5;
  }
  // Lazily access constants.maintainedNodeVersions.
  const {
    maintainedNodeVersions
  } = constants;
  // Lazily access constants.minimumVersionByAgent.
  const minSupportedAgentVersion = constants.minimumVersionByAgent.get(agent);
  const minSupportedNodeVersion = maintainedNodeVersions.last;
  const nodeVersion = semver.coerce(process$1.version);
  let lockSrc;
  let pkgAgentRange;
  let pkgNodeRange;
  let pkgMinAgentVersion = minSupportedAgentVersion;
  let pkgMinNodeVersion = minSupportedNodeVersion;
  if (pkgJson) {
    const {
      engines
    } = pkgJson;
    const engineAgentRange = engines?.[agent];
    const engineNodeRange = engines?.['node'];
    if (strings.isNonEmptyString(engineAgentRange)) {
      pkgAgentRange = engineAgentRange;
      // Roughly check agent range as semver.coerce will strip leading
      // v's, carets (^), comparators (<,<=,>,>=,=), and tildes (~).
      const coerced = semver.coerce(pkgAgentRange);
      if (coerced && semver.lt(coerced, pkgMinAgentVersion)) {
        pkgMinAgentVersion = coerced.version;
      }
    }
    if (strings.isNonEmptyString(engineNodeRange)) {
      pkgNodeRange = engineNodeRange;
      // Roughly check Node range as semver.coerce will strip leading
      // v's, carets (^), comparators (<,<=,>,>=,=), and tildes (~).
      const coerced = semver.coerce(pkgNodeRange);
      if (coerced && semver.lt(coerced, pkgMinNodeVersion)) {
        pkgMinNodeVersion = coerced.version;
      }
    }
    const browserslistQuery = pkgJson['browserslist'];
    if (Array.isArray(browserslistQuery)) {
      // List Node targets in ascending version order.
      const browserslistNodeTargets = browserslist(browserslistQuery).filter(v => /^node /i.test(v)).map(v => v.slice(5 /*'node '.length*/)).sort(sorts.naturalCompare);
      if (browserslistNodeTargets.length) {
        // browserslistNodeTargets[0] is the lowest Node target version.
        const coerced = semver.coerce(browserslistNodeTargets[0]);
        if (coerced && semver.lt(coerced, pkgMinNodeVersion)) {
          pkgMinNodeVersion = coerced.version;
        }
      }
    }
    lockSrc = typeof lockPath === 'string' ? await readLockFileByAgent.get(agent)(lockPath, agentExecPath) : undefined;
  } else {
    lockName = undefined;
    lockPath = undefined;
  }
  // Does the system agent version meet our minimum supported agent version?
  const agentSupported = !!agentVersion && semver.satisfies(agentVersion, `>=${minSupportedAgentVersion}`);

  // Does the system Node version meet our minimum supported Node version?
  const nodeSupported = semver.satisfies(nodeVersion, `>=${minSupportedNodeVersion}`);
  const npmBuggyOverrides = agent === NPM$b && !!agentVersion && semver.lt(agentVersion, NPM_BUGGY_OVERRIDES_PATCHED_VERSION$1);
  return {
    agent,
    agentExecPath,
    agentSupported,
    agentVersion,
    features: {
      npmBuggyOverrides
    },
    lockName,
    lockPath,
    lockSrc,
    nodeSupported,
    nodeVersion,
    npmExecPath,
    pkgJson: editablePkgJson,
    pkgPath,
    pkgRequirements: {
      agent: pkgAgentRange ?? `>=${pkgMinAgentVersion}`,
      node: pkgNodeRange ?? `>=${pkgMinNodeVersion}`
    },
    pkgSupports: {
      // Does our minimum supported agent version meet the package's requirements?
      agent: semver.satisfies(minSupportedAgentVersion, `>=${pkgMinAgentVersion}`),
      // Does our supported Node versions meet the package's requirements?
      node: maintainedNodeVersions.some(v => semver.satisfies(v, `>=${pkgMinNodeVersion}`))
    }
  };
}
async function detectAndValidatePackageEnvironment(cwd, options) {
  const {
    cmdName = '',
    logger,
    prod
  } = {
    __proto__: null,
    ...options
  };
  const details = await detectPackageEnvironment({
    cwd,
    onUnknown(pkgManager) {
      logger?.warn(cmdPrefixMessage(cmdName, `Unknown package manager${pkgManager ? ` ${pkgManager}` : ''}, defaulting to npm`));
    }
  });
  const {
    agent,
    nodeVersion,
    pkgRequirements
  } = details;
  const agentVersion = details.agentVersion ?? 'unknown';
  if (!details.agentSupported) {
    const minVersion = constants.minimumVersionByAgent.get(agent);
    logger?.fail(cmdPrefixMessage(cmdName, `Requires ${agent} >=${minVersion}. Current version: ${agentVersion}.`));
    return;
  }
  if (!details.nodeSupported) {
    const minVersion = constants.maintainedNodeVersions.last;
    logger?.fail(cmdPrefixMessage(cmdName, `Requires Node >=${minVersion}. Current version: ${nodeVersion}.`));
    return;
  }
  if (!details.pkgSupports.agent) {
    logger?.fail(cmdPrefixMessage(cmdName, `Package engine "${agent}" requires ${pkgRequirements.agent}. Current version: ${agentVersion}`));
    return;
  }
  if (!details.pkgSupports.node) {
    logger?.fail(cmdPrefixMessage(cmdName, `Package engine "node" requires ${pkgRequirements.node}. Current version: ${nodeVersion}`));
    return;
  }
  if (agent === VLT$5) {
    logger?.fail(cmdPrefixMessage(cmdName, `${agent} does not support overrides. Soon, though âš¡`));
    return;
  }
  const lockName = details.lockName ?? 'lock file';
  if (details.lockName === undefined || details.lockSrc === undefined) {
    logger?.fail(cmdPrefixMessage(cmdName, `No ${lockName} found`));
    return;
  }
  if (details.lockSrc.trim() === '') {
    logger?.fail(cmdPrefixMessage(cmdName, `${lockName} is empty`));
    return;
  }
  if (details.pkgPath === undefined) {
    logger?.fail(cmdPrefixMessage(cmdName, `No ${PACKAGE_JSON} found`));
    return;
  }
  if (prod && (agent === BUN$5 || agent === YARN_BERRY$5)) {
    logger?.fail(cmdPrefixMessage(cmdName, `--prod not supported for ${agent}${agentVersion ? `@${agentVersion}` : ''}`));
    return;
  }
  if (details.lockPath && path$1.relative(cwd, details.lockPath).startsWith('.')) {
    logger?.warn(cmdPrefixMessage(cmdName, `Package ${lockName} found at ${details.lockPath}`));
  }
  return details;
}

const {
  NPM: NPM$a,
  PNPM: PNPM$7
} = constants;
const CMD_NAME$2 = 'socket fix';
async function runFix() {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start();
  const cwd = process.cwd();
  const pkgEnvDetails = await detectAndValidatePackageEnvironment(cwd, {
    cmdName: CMD_NAME$2,
    logger: logger.logger
  });
  if (!pkgEnvDetails) {
    spinner.stop();
    return;
  }
  switch (pkgEnvDetails.agent) {
    case NPM$a:
      {
        await npmFix(pkgEnvDetails, cwd);
        break;
      }
    case PNPM$7:
      {
        await pnpmFix(pkgEnvDetails, cwd);
        break;
      }
  }
  spinner.successAndStop('Socket.dev fix successful');
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$w
} = constants;
const config$x = {
  commandName: 'fix',
  description: 'Fix "fixable" Socket alerts',
  hidden: true,
  flags: {
    ...commonFlags
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Options
      ${getFlagListOutput(config.flags, 6)}
  `
};
const cmdFix = {
  description: config$x.description,
  hidden: config$x.hidden,
  run: run$x
};
async function run$x(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$x,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$w);
    return;
  }
  await runFix();
}

async function fetchPackageInfo(pkgName, pkgVersion, includeAllIssues) {
  const socketSdk = await shadowNpmInject.setupSdk(shadowNpmInject.getPublicToken());

  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start(pkgVersion === 'latest' ? `Looking up data for the latest version of ${pkgName}` : `Looking up data for version ${pkgVersion} of ${pkgName}`);
  const result = await handleApiCall(socketSdk.getIssuesByNPMPackage(pkgName, pkgVersion), 'looking up package');
  const scoreResult = await handleApiCall(socketSdk.getScoreByNPMPackage(pkgName, pkgVersion), 'looking up package score');
  spinner.successAndStop('Data fetched');
  if (result.success === false) {
    return handleUnsuccessfulApiResponse('getIssuesByNPMPackage', result);
  }
  if (scoreResult.success === false) {
    return handleUnsuccessfulApiResponse('getScoreByNPMPackage', scoreResult);
  }
  const severityCount = shadowNpmInject.getSeverityCount(result.data, includeAllIssues ? undefined : 'high');
  return {
    data: result.data,
    severityCount,
    score: scoreResult.data
  };
}

const {
  NPM: NPM$9
} = registryConstants;
function formatScore$1(score) {
  if (score > 80) {
    return colors.green(`${score}`);
  } else if (score < 80 && score > 60) {
    return colors.yellow(`${score}`);
  }
  return colors.red(`${score}`);
}
function outputPackageIssuesDetails(packageData, outputMarkdown) {
  const issueDetails = packageData.filter(d => d.value?.severity === shadowNpmInject.SEVERITY.critical || d.value?.severity === shadowNpmInject.SEVERITY.high);
  const uniqueIssueDetails = issueDetails.reduce((acc, issue) => {
    const {
      type
    } = issue;
    if (type) {
      const details = acc.get(type);
      if (details) {
        details.count += 1;
      } else {
        acc.set(type, {
          label: issue.value?.label ?? '',
          count: 1
        });
      }
    }
    return acc;
  }, new Map());
  const format = new shadowNpmInject.ColorOrMarkdown(outputMarkdown);
  for (const [type, details] of uniqueIssueDetails.entries()) {
    const issueWithLink = format.hyperlink(details.label, shadowNpmInject.getSocketDevAlertUrl(type), {
      fallbackToUrl: true
    });
    if (details.count === 1) {
      logger.logger.log(`- ${issueWithLink}`);
    } else {
      logger.logger.log(`- ${issueWithLink}: ${details.count}`);
    }
  }
}
function outputPackageInfo({
  data,
  score,
  severityCount
}, {
  name,
  outputKind,
  pkgName,
  pkgVersion
}) {
  if (outputKind === 'json') {
    logger.logger.log(JSON.stringify(data, undefined, 2));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log(commonTags.stripIndents`
      # Package report for ${pkgName}

      Package report card:
    `);
  } else {
    logger.logger.log(`Package report card for ${pkgName}:`);
  }
  const scoreResult = {
    'Supply Chain Risk': Math.floor(score.supplyChainRisk.score * 100),
    Maintenance: Math.floor(score.maintenance.score * 100),
    Quality: Math.floor(score.quality.score * 100),
    Vulnerabilities: Math.floor(score.vulnerability.score * 100),
    License: Math.floor(score.license.score * 100)
  };
  logger.logger.log('\n');
  Object.entries(scoreResult).map(score => logger.logger.log(`- ${score[0]}: ${formatScore$1(score[1])}`));
  logger.logger.log('\n');
  if (objects.hasKeys(severityCount)) {
    if (outputKind === 'markdown') {
      logger.logger.log('# Issues\n');
    }
    logger.logger.log(`Package has these issues: ${shadowNpmInject.formatSeverityCount(severityCount)}\n`);
    outputPackageIssuesDetails(data, outputKind === 'markdown');
  } else {
    logger.logger.log('Package has no issues');
  }
  const format = new shadowNpmInject.ColorOrMarkdown(outputKind === 'markdown');
  const url = shadowNpmInject.getSocketDevPackageOverviewUrl(NPM$9, pkgName, pkgVersion);
  logger.logger.log('\n');
  if (pkgVersion === 'latest') {
    logger.logger.log(`Detailed info on socket.dev: ${format.hyperlink(`${pkgName}`, url, {
      fallbackToUrl: true
    })}`);
  } else {
    logger.logger.log(`Detailed info on socket.dev: ${format.hyperlink(`${pkgName} v${pkgVersion}`, url, {
      fallbackToUrl: true
    })}`);
  }
  if (outputKind !== 'markdown') {
    logger.logger.log(colors.dim(`\nOr rerun ${colors.italic(name)} using the ${colors.italic('--json')} flag to get full JSON output`));
  } else {
    logger.logger.log('');
  }
}

async function handlePackageInfo({
  commandName,
  includeAllIssues,
  outputKind,
  pkgName,
  pkgVersion,
  strict
}) {
  const packageData = await fetchPackageInfo(pkgName, pkgVersion, includeAllIssues);
  if (packageData) {
    outputPackageInfo(packageData, {
      name: commandName,
      outputKind,
      pkgName,
      pkgVersion
    });
    if (strict && objects.hasKeys(packageData.severityCount)) {
      // Let NodeJS exit gracefully but with exit(1)
      process$1.exitCode = 1;
    }
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$v
} = constants;
const config$w = {
  commandName: 'info',
  description: 'Look up info regarding a package',
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags,
    ...validationFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <name>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} webtorrent
      $ ${command} webtorrent@1.9.1
  `
};
const cmdInfo = {
  description: config$w.description,
  hidden: config$w.hidden,
  run: run$w
};
async function run$w(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$w,
    importMeta,
    parentName
  });
  const {
    all,
    json,
    markdown,
    strict
  } = cli.flags;
  const [rawPkgName = ''] = cli.input;
  if (!rawPkgName || cli.input.length > 1) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:\n
      - Expecting a package name ${!rawPkgName ? colors.red('(missing!)') : colors.green('(ok)')}\n
      - Can only accept one package at a time ${cli.input.length > 1 ? colors.red('(got ' + cli.input.length + '!)') : colors.green('(ok)')}\n`);
    return;
  }
  const versionSeparator = rawPkgName.lastIndexOf('@');
  const pkgName = versionSeparator < 1 ? rawPkgName : rawPkgName.slice(0, versionSeparator);
  const pkgVersion = versionSeparator < 1 ? 'latest' : rawPkgName.slice(versionSeparator + 1);
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$v);
    return;
  }
  await handlePackageInfo({
    commandName: `${parentName} ${config$w.commandName}`,
    includeAllIssues: Boolean(all),
    outputKind: json ? 'json' : markdown ? 'markdown' : 'print',
    pkgName,
    pkgVersion,
    strict: Boolean(strict)
  });
}

function applyLogin(apiToken, enforcedOrgs, apiBaseUrl, apiProxy) {
  shadowNpmInject.updateSetting('enforcedOrgs', enforcedOrgs);
  shadowNpmInject.updateSetting('apiToken', apiToken);
  shadowNpmInject.updateSetting('apiBaseUrl', apiBaseUrl);
  shadowNpmInject.updateSetting('apiProxy', apiProxy);
}

const {
  SOCKET_PUBLIC_API_TOKEN
} = constants;
async function attemptLogin(apiBaseUrl, apiProxy) {
  apiBaseUrl ??= shadowNpmInject.getSetting('apiBaseUrl') ?? undefined;
  apiProxy ??= shadowNpmInject.getSetting('apiProxy') ?? undefined;
  const apiToken = (await prompts.password({
    message: `Enter your ${terminalLink('Socket.dev API key', 'https://docs.socket.dev/docs/api-keys')} (leave blank for a public key)`
  })) || SOCKET_PUBLIC_API_TOKEN;
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Verifying API key...');
  let orgs;
  try {
    const sdk = await shadowNpmInject.setupSdk(apiToken, apiBaseUrl, apiProxy);
    const result = await sdk.getOrganizations();
    if (!result.success) {
      throw new shadowNpmInject.AuthError();
    }
    orgs = result.data;
    spinner.success('API key verified');
  } catch {
    spinner.errorAndStop('Invalid API key');
    return;
  }
  const enforcedChoices = Object.values(orgs.organizations).filter(org => org?.plan === 'enterprise').map(org => ({
    name: org.name,
    value: org.id
  }));
  let enforcedOrgs = [];
  if (enforcedChoices.length > 1) {
    const id = await prompts.select({
      message: "Which organization's policies should Socket enforce system-wide?",
      choices: enforcedChoices.concat({
        name: 'None',
        value: '',
        description: 'Pick "None" if this is a personal device'
      })
    }, {
      spinner
    });
    if (id) {
      enforcedOrgs = [id];
    }
  } else if (enforcedChoices.length) {
    const confirmOrg = await prompts.confirm({
      message: `Should Socket enforce ${enforcedChoices[0]?.name}'s security policies system-wide?`,
      default: true
    }, {
      spinner
    });
    if (confirmOrg) {
      const existing = enforcedChoices[0];
      if (existing) {
        enforcedOrgs = [existing.value];
      }
    }
  }
  spinner.stop();
  const oldToken = shadowNpmInject.getSetting('apiToken');
  try {
    applyLogin(apiToken, enforcedOrgs, apiBaseUrl, apiProxy);
    logger.logger.success(`API credentials ${oldToken ? 'updated' : 'set'}`);
  } catch {
    logger.logger.fail(`API login failed`);
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$u
} = constants;
const config$v = {
  commandName: 'login',
  description: 'Socket API login',
  hidden: false,
  flags: {
    ...commonFlags,
    apiBaseUrl: {
      type: 'string',
      description: 'API server to connect to for login'
    },
    apiProxy: {
      type: 'string',
      description: 'Proxy to use when making connection to API server'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Logs into the Socket API by prompting for an API key

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}
      $ ${command} --api-proxy=http://localhost:1234
  `
};
const cmdLogin = {
  description: config$v.description,
  hidden: config$v.hidden,
  run: run$v
};
async function run$v(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$v,
    importMeta,
    parentName
  });
  const apiBaseUrl = cli.flags['apiBaseUrl'];
  const apiProxy = cli.flags['apiProxy'];
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$u);
    return;
  }
  if (!isInteractive()) {
    throw new shadowNpmInject.InputError('Cannot prompt for credentials in a non-interactive shell');
  }
  await attemptLogin(apiBaseUrl, apiProxy);
}

function applyLogout() {
  shadowNpmInject.updateSetting('apiToken', null);
  shadowNpmInject.updateSetting('apiBaseUrl', null);
  shadowNpmInject.updateSetting('apiProxy', null);
  shadowNpmInject.updateSetting('enforcedOrgs', null);
}

function attemptLogout() {
  try {
    applyLogout();
    logger.logger.success('Successfully logged out');
  } catch {
    logger.logger.fail('Failed to complete logout steps');
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$t
} = constants;
const config$u = {
  commandName: 'logout',
  description: 'Socket API logout',
  hidden: false,
  flags: {
    ...commonFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}

    Logs out of the Socket API and clears all Socket credentials from disk
  `
};
const cmdLogout = {
  description: config$u.description,
  hidden: config$u.hidden,
  run: run$u
};
async function run$u(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$u,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$t);
    return;
  }
  attemptLogout();
}

async function convertGradleToMaven(target, bin, _out, verbose, gradleOpts) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const rbin = path$1.resolve(bin);
  const rtarget = path$1.resolve(target);
  if (verbose) {
    logger.logger.group('gradle2maven:');
    logger.logger.log(`[VERBOSE] - Absolute bin path: \`${rbin}\``);
    logger.logger.log(`[VERBOSE] - Absolute target path: \`${rtarget}\``);
    logger.logger.groupEnd();
  } else {
    logger.logger.group('gradle2maven:');
    logger.logger.log(`- executing: \`${bin}\``);
    logger.logger.log(`- src dir: \`${target}\``);
    logger.logger.groupEnd();
  }
  try {
    // Run sbt with the init script we provide which should yield zero or more
    // pom files. We have to figure out where to store those pom files such that
    // we can upload them and predict them through the GitHub API. We could do a
    // .socket folder. We could do a socket.pom.gz with all the poms, although
    // I'd prefer something plain-text if it is to be committed.

    // Note: init.gradle will be exported by .config/rollup.dist.config.mjs
    const initLocation = path$1.join(constants.rootDistPath, 'init.gradle');
    const commandArgs = ['--init-script', initLocation, ...gradleOpts, 'pom'];
    if (verbose) {
      logger.logger.log('[VERBOSE] Executing:', bin, commandArgs);
    }
    spinner.start(`Converting gradle to maven from \`${bin}\` on \`${target}\`...`);
    const output = await spawn.spawn(bin, commandArgs, {
      cwd: target || '.'
    });
    spinner.stop();
    if (verbose) {
      logger.logger.group('[VERBOSE] gradle stdout:');
      logger.logger.log(output);
      logger.logger.groupEnd();
    }
    if (output.stderr) {
      process.exitCode = 1;
      logger.logger.fail('There were errors while running gradle');
      // (In verbose mode, stderr was printed above, no need to repeat it)
      if (!verbose) {
        logger.logger.group('[VERBOSE] stderr:');
        logger.logger.error(output.stderr);
        logger.logger.groupEnd();
      }
      return;
    }
    logger.logger.success('Executed gradle successfully');
    logger.logger.log('Reported exports:');
    output.stdout.replace(/^POM file copied to: (.*)/gm, (_all, fn) => {
      logger.logger.log('- ', fn);
      return fn;
    });

    // const loc = output.stdout?.match(/Wrote (.*?.pom)\n/)?.[1]?.trim()
    // if (!loc) {
    //   logger.fail(
    //     'There were no errors from sbt but could not find the location of resulting .pom file either'
    //   )
    //   process.exit(1)
    // }
    //
    // // Move the pom file to ...? initial cwd? loc will be an absolute path, or dump to stdout
    // if (out === '-') {
    //   spinner.start('Result:\n```')
    //   spinner.log(await safeReadFile(loc))
    //   spinner.log('```')
    //   spinner.successAndStop(`OK`)
    // } else {
    //   spinner.start()
    //   if (verbose) {
    //     spinner.log(
    //       `Moving manifest file from \`${loc.replace(/^\/home\/[^/]*?\//, '~/')}\` to \`${out}\``
    //     )
    //   } else {
    //     spinner.log('Moving output pom file')
    //   }
    //   // TODO: do we prefer fs-extra? renaming can be gnarly on windows and fs-extra's version is better
    //   await renamep(loc, out)
    //   spinner.successAndStop(`OK. File should be available in \`${out}\``)
    // }
  } catch (e) {
    process.exitCode = 1;
    spinner.stop();
    logger.logger.fail('There was an unexpected error while running this' + (verbose ? '' : ' (use --verbose for details)'));
    if (verbose) {
      logger.logger.group('[VERBOSE] error:');
      logger.logger.log(e);
      logger.logger.groupEnd();
    }
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$s
} = constants;
const config$t = {
  commandName: 'gradle',
  description: '[beta] Use Gradle to generate a manifest file (`pom.xml`) for a Gradle/Java/Kotlin/etc project',
  hidden: false,
  flags: {
    ...commonFlags,
    bin: {
      type: 'string',
      description: 'Location of gradlew binary to use, default: CWD/gradlew'
    },
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    gradleOpts: {
      type: 'string',
      default: '',
      description: 'Additional options to pass on to ./gradlew, see `./gradlew --help`'
    },
    out: {
      type: 'string',
      default: './socket.pom.xml',
      description: 'Path of output file; where to store the resulting manifest, see also --stdout'
    },
    stdout: {
      type: 'boolean',
      description: 'Print resulting pom.xml to stdout (supersedes --out)'
    },
    task: {
      type: 'string',
      default: 'all',
      description: 'Task to target. By default targets all.'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [--gradle=path/to/gradle/binary] [--out=path/to/result] DIR

    Options
      ${getFlagListOutput(config.flags, 6)}

    Uses gradle, preferably through your local project \`gradlew\`, to generate a
    \`pom.xml\` file for each task. If you have no \`gradlew\` you can try the
    global \`gradle\` binary but that may not work (hard to predict).

    The \`pom.xml\` is a manifest file similar to \`package.json\` for npm or
    or requirements.txt for PyPi), but specifically for Maven, which is Java's
    dependency repository. Languages like Kotlin and Scala piggy back on it too.

    There are some caveats with the gradle to \`pom.xml\` conversion:

    - each task will generate its own xml file and by default it generates one xml
      for every task.

    - it's possible certain features don't translate well into the xml. If you
      think something is missing that could be supported please reach out.

    - it works with your \`gradlew\` from your repo and local settings and config

    Support is beta. Please report issues or give us feedback on what's missing.

    Examples

      $ ${command} .
      $ ${command} --gradlew=../gradlew .
  `
};
const cmdManifestGradle = {
  description: config$t.description,
  hidden: config$t.hidden,
  run: run$t
};
async function run$t(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$t,
    importMeta,
    parentName
  });
  const verbose = Boolean(cli.flags['verbose']);
  if (verbose) {
    logger.logger.group('- ', parentName, config$t.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.groupEnd();
  }
  const target = cli.input[0];

  // TODO: I'm not sure it's feasible to parse source file from stdin. We could
  // try, store contents in a file in some folder, target that folder... what
  // would the file name be?
  if (!target || target === '-' || cli.input.length > 1) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - The DIR arg is required ${!target ? colors.red('(missing!)') : target === '-' ? colors.red('(stdin is not supported)') : colors.green('(ok)')}

      - Can only accept one DIR (make sure to escape spaces!) ${cli.input.length > 1 ? colors.red(`(received ${cli.input.length}!)`) : colors.green('(ok)')}`);
    return;
  }
  let bin;
  if (cli.flags['bin']) {
    bin = cli.flags['bin'];
  } else {
    bin = path$1.join(target, 'gradlew');
  }
  let out = './socket.pom.xml';
  if (cli.flags['out']) {
    out = cli.flags['out'];
  }
  if (cli.flags['stdout']) {
    out = '-';
  }
  if (verbose) {
    logger.logger.group();
    logger.logger.log('- target:', target);
    logger.logger.log('- gradle bin:', bin);
    logger.logger.log('- out:', out);
    logger.logger.groupEnd();
  }
  let gradleOpts = [];
  if (cli.flags['gradleOpts']) {
    gradleOpts = cli.flags['gradleOpts'].split(' ').map(s => s.trim()).filter(Boolean);
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$s);
    return;
  }
  await convertGradleToMaven(target, bin, out, verbose, gradleOpts);
}

async function convertSbtToMaven(target, bin, out, verbose, sbtOpts) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const rbin = path$1.resolve(bin);
  const rtarget = path$1.resolve(target);
  if (verbose) {
    logger.logger.group('sbt2maven:');
    logger.logger.log(`[VERBOSE] - Absolute bin path: \`${rbin}\``);
    logger.logger.log(`[VERBOSE] - Absolute target path: \`${rtarget}\``);
    // logger.log(`[VERBOSE] - Absolute out path: \`${rout}\``)
    logger.logger.groupEnd();
  } else {
    logger.logger.group('sbt2maven:');
    logger.logger.log(`- executing: \`${bin}\``);
    logger.logger.log(`- src dir: \`${target}\``);
    // logger.log(`- dst dir: \`${out}\``)
    logger.logger.groupEnd();
  }
  try {
    spinner.start(`Converting sbt to maven from \`${bin}\` on \`${target}\`...`);

    // Run sbt with the init script we provide which should yield zero or more
    // pom files. We have to figure out where to store those pom files such that
    // we can upload them and predict them through the GitHub API. We could do a
    // .socket folder. We could do a socket.pom.gz with all the poms, although
    // I'd prefer something plain-text if it is to be committed.
    const output = await spawn.spawn(bin, ['makePom'].concat(sbtOpts), {
      cwd: target || '.'
    });
    spinner.stop();
    if (verbose) {
      logger.logger.group('[VERBOSE] sbt stdout:');
      logger.logger.log(output);
      logger.logger.groupEnd();
    }
    if (output.stderr) {
      process.exitCode = 1;
      logger.logger.fail('There were errors while running sbt');
      // (In verbose mode, stderr was printed above, no need to repeat it)
      if (!verbose) {
        logger.logger.group('[VERBOSE] stderr:');
        logger.logger.error(output.stderr);
        logger.logger.groupEnd();
      }
      return;
    }
    const poms = [];
    output.stdout.replace(/Wrote (.*?.pom)\n/g, (_all, fn) => {
      poms.push(fn);
      return fn;
    });
    if (!poms.length) {
      process.exitCode = 1;
      logger.logger.fail('There were no errors from sbt but it seems to not have generated any poms either');
      return;
    }
    // Move the pom file to ...? initial cwd? loc will be an absolute path, or dump to stdout
    // TODO: what to do with multiple output files? Do we want to dump them to stdout? Raw or with separators or ?
    // TODO: maybe we can add an option to target a specific file to dump to stdout
    if (out === '-' && poms.length === 1) {
      logger.logger.log('Result:\n```');
      logger.logger.log(await shadowNpmInject.safeReadFile(poms[0]));
      logger.logger.log('```');
      logger.logger.success(`OK`);
    } else if (out === '-') {
      process.exitCode = 1;
      logger.logger.fail('Requested out target was stdout but there are multiple generated files');
      poms.forEach(fn => logger.logger.error('-', fn));
      logger.logger.error('Exiting now...');
      return;
    } else {
      // if (verbose) {
      //   logger.log(
      //     `Moving manifest file from \`${loc.replace(/^\/home\/[^/]*?\//, '~/')}\` to \`${out}\``
      //   )
      // } else {
      //   logger.log('Moving output pom file')
      // }
      // TODO: do we prefer fs-extra? renaming can be gnarly on windows and fs-extra's version is better
      // await renamep(loc, out)
      logger.logger.success(`Generated ${poms.length} pom files`);
      poms.forEach(fn => logger.logger.log('-', fn));
      logger.logger.success(`OK`);
    }
  } catch (e) {
    process.exitCode = 1;
    spinner.stop();
    logger.logger.fail('There was an unexpected error while running this' + (verbose ? '' : ' (use --verbose for details)'));
    if (verbose) {
      logger.logger.group('[VERBOSE] error:');
      logger.logger.log(e);
      logger.logger.groupEnd();
    }
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$r
} = constants;
const config$s = {
  commandName: 'scala',
  description: "[beta] Generate a manifest file (`pom.xml`) from Scala's `build.sbt` file",
  hidden: false,
  flags: {
    ...commonFlags,
    bin: {
      type: 'string',
      default: 'sbt',
      description: 'Location of sbt binary to use'
    },
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    out: {
      type: 'string',
      default: './socket.pom.xml',
      description: 'Path of output file; where to store the resulting manifest, see also --stdout'
    },
    stdout: {
      type: 'boolean',
      description: 'Print resulting pom.xml to stdout (supersedes --out)'
    },
    sbtOpts: {
      type: 'string',
      default: '',
      description: 'Additional options to pass on to sbt, as per `sbt --help`'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [--sbt=path/to/sbt/binary] [--out=path/to/result] FILE|DIR

    Options
      ${getFlagListOutput(config.flags, 6)}

    Uses \`sbt makePom\` to generate a \`pom.xml\` from your \`build.sbt\` file.
    This xml file is the dependency manifest (like a package.json
    for Node.js or requirements.txt for PyPi), but specifically for Scala.

    There are some caveats with \`build.sbt\` to \`pom.xml\` conversion:

    - the xml is exported as socket.pom.xml as to not confuse existing build tools
      but it will first hit your /target/sbt<version> folder (as a different name)

    - the pom.xml format (standard by Scala) does not support certain sbt features
      - \`excludeAll()\`, \`dependencyOverrides\`, \`force()\`, \`relativePath\`
      - For details: https://www.scala-sbt.org/1.x/docs/Library-Management.html

    - it uses your sbt settings and local configuration verbatim

    - it can only export one target per run, so if you have multiple targets like
      development and production, you must run them separately.

    You can optionally configure the path to the \`sbt\` bin to invoke.

    Support is beta. Please report issues or give us feedback on what's missing.

    This is only for SBT. If your Scala setup uses gradle, please see the help
    sections for \`socket manifest gradle\` or \`socket cdxgen\`.

    Examples

      $ ${command} ./build.sbt
      $ ${command} --bin=/usr/bin/sbt ./build.sbt
  `
};
const cmdManifestScala = {
  description: config$s.description,
  hidden: config$s.hidden,
  run: run$s
};
async function run$s(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$s,
    importMeta,
    parentName
  });
  const verbose = Boolean(cli.flags['verbose']);
  if (verbose) {
    logger.logger.group('- ', parentName, config$s.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.groupEnd();
  }
  const target = cli.input[0];

  // TODO: I'm not sure it's feasible to parse source file from stdin. We could
  // try, store contents in a file in some folder, target that folder... what
  // would the file name be?
  if (!target || target === '-' || cli.input.length > 1) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - The DIR or FILE arg is required ${!target ? colors.red('(missing!)') : target === '-' ? colors.red('(stdin is not supported)') : colors.green('(ok)')}

      - Can only accept one DIR or FILE (make sure to escape spaces!) ${cli.input.length > 1 ? colors.red(`(received ${cli.input.length}!)`) : colors.green('(ok)')}`);
    return;
  }
  let bin = 'sbt';
  if (cli.flags['bin']) {
    bin = cli.flags['bin'];
  }
  let out = './socket.pom.xml';
  if (cli.flags['out']) {
    out = cli.flags['out'];
  }
  if (cli.flags['stdout']) {
    out = '-';
  }
  if (verbose) {
    logger.logger.group();
    logger.logger.log('- target:', target);
    logger.logger.log('- gradle bin:', bin);
    logger.logger.log('- out:', out);
    logger.logger.groupEnd();
  }
  let sbtOpts = [];
  if (cli.flags['sbtOpts']) {
    sbtOpts = cli.flags['sbtOpts'].split(' ').map(s => s.trim()).filter(Boolean);
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$r);
    return;
  }
  await convertSbtToMaven(target, bin, out, verbose, sbtOpts);
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$q
} = constants;
const config$r = {
  commandName: 'auto',
  description: 'Auto-detect build and attempt to generate manifest file',
  hidden: false,
  flags: {
    ...commonFlags,
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    verbose: {
      type: 'boolean',
      default: false,
      description: 'Enable debug output, may help when running into errors'
    }
    // TODO: support output flags
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Options
      ${getFlagListOutput(config.flags, 6)}

    Tries to figure out what language your current repo uses. If it finds a
    supported case then it will try to generate the manifest file for that
    language with the default or detected settings.
  `
};
const cmdManifestAuto = {
  description: config$r.description,
  hidden: config$r.hidden,
  run: run$r
};
async function run$r(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$r,
    importMeta,
    parentName
  });
  const verbose = !!cli.flags['verbose'];
  const cwd = cli.flags['cwd'] ?? process.cwd();
  if (verbose) {
    logger.logger.group('- ', parentName, config$r.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.log('- cwd:', cwd);
    logger.logger.groupEnd();
  }
  const subArgs = [];
  if (verbose) {
    subArgs.push('--verbose');
  }
  const dir = cwd;
  if (fs$1.existsSync(path$1.join(dir, 'build.sbt'))) {
    logger.logger.log('Detected a Scala sbt build, running default Scala generator...');
    if (cwd) {
      subArgs.push('--cwd', cwd);
    }
    subArgs.push(dir);
    if (cli.flags['dryRun']) {
      logger.logger.log(DRY_RUN_BAIL_TEXT$q);
      return;
    }
    await cmdManifestScala.run(subArgs, importMeta, {
      parentName
    });
    return;
  }
  if (fs$1.existsSync(path$1.join(dir, 'gradlew'))) {
    logger.logger.log('Detected a gradle build, running default gradle generator...');
    if (cwd) {
      // This command takes the cwd as first arg.
      subArgs.push(cwd);
    }
    if (cli.flags['dryRun']) {
      logger.logger.log(DRY_RUN_BAIL_TEXT$q);
      return;
    }
    await cmdManifestGradle.run(subArgs, importMeta, {
      parentName
    });
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$q);
    return;
  }

  // Show new help screen and exit.
  meow(`
    $ ${parentName} ${config$r.commandName}

    Unfortunately this script did not discover a supported language in the
    current folder.

    - Make sure this script would work with your target build
    - Make sure to run it from the correct folder
    - Make sure the necessary build tools are available (\`PATH\`)

    If that doesn't work, see \`${parentName} <lang> --help\` for config details for
    your target language.
  `, {
    argv: [],
    description: config$r.description,
    importMeta
  }).showHelp();
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$p
} = constants;

// TODO: we may want to dedupe some pieces for all gradle languages. I think it
//       makes sense to have separate commands for them and I think it makes
//       sense for the help panels to note the requested language, rather than
//       `socket manifest kotlin` to print help screens with `gradle` as the
//       command. Room for improvement.
const config$q = {
  commandName: 'kotlin',
  description: '[beta] Use Gradle to generate a manifest file (`pom.xml`) for a Kotlin project',
  hidden: false,
  flags: {
    ...commonFlags,
    bin: {
      type: 'string',
      description: 'Location of gradlew binary to use, default: CWD/gradlew'
    },
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    gradleOpts: {
      type: 'string',
      default: '',
      description: 'Additional options to pass on to ./gradlew, see `./gradlew --help`'
    },
    out: {
      type: 'string',
      default: './socket.pom.xml',
      description: 'Path of output file; where to store the resulting manifest, see also --stdout'
    },
    stdout: {
      type: 'boolean',
      description: 'Print resulting pom.xml to stdout (supersedes --out)'
    },
    task: {
      type: 'string',
      default: 'all',
      description: 'Task to target. By default targets all.'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [--gradle=path/to/gradle/binary] [--out=path/to/result] DIR

    Options
      ${getFlagListOutput(config.flags, 6)}

    Uses gradle, preferably through your local project \`gradlew\`, to generate a
    \`pom.xml\` file for each task. If you have no \`gradlew\` you can try the
    global \`gradle\` binary but that may not work (hard to predict).

    The \`pom.xml\` is a manifest file similar to \`package.json\` for npm or
    or requirements.txt for PyPi), but specifically for Maven, which is Java's
    dependency repository. Languages like Kotlin and Scala piggy back on it too.

    There are some caveats with the gradle to \`pom.xml\` conversion:

    - each task will generate its own xml file and by default it generates one xml
      for every task. (This may be a good thing!)

    - it's possible certain features don't translate well into the xml. If you
      think something is missing that could be supported please reach out.

    - it works with your \`gradlew\` from your repo and local settings and config

    Support is beta. Please report issues or give us feedback on what's missing.

    Examples

      $ ${command} .
      $ ${command} --gradlew=../gradlew .
  `
};
const cmdManifestKotlin = {
  description: config$q.description,
  hidden: config$q.hidden,
  run: run$q
};
async function run$q(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$q,
    importMeta,
    parentName
  });
  const verbose = Boolean(cli.flags['verbose']);
  if (verbose) {
    logger.logger.group('- ', parentName, config$q.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.groupEnd();
  }
  const target = cli.input[0];

  // TODO: I'm not sure it's feasible to parse source file from stdin. We could
  // try, store contents in a file in some folder, target that folder... what
  // would the file name be?
  if (!target || target === '-' || cli.input.length > 1) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - The DIR arg is required ${!target ? colors.red('(missing!)') : target === '-' ? colors.red('(stdin is not supported)') : colors.green('(ok)')}

      - Can only accept one DIR (make sure to escape spaces!) ${cli.input.length > 1 ? colors.red(`(received ${cli.input.length}!)`) : colors.green('(ok)')}`);
    return;
  }
  let bin;
  if (cli.flags['bin']) {
    bin = cli.flags['bin'];
  } else {
    bin = path$1.join(target, 'gradlew');
  }
  let out = './socket.pom.xml';
  if (cli.flags['out']) {
    out = cli.flags['out'];
  }
  if (cli.flags['stdout']) {
    out = '-';
  }
  if (verbose) {
    logger.logger.group();
    logger.logger.log('- target:', target);
    logger.logger.log('- gradle bin:', bin);
    logger.logger.log('- out:', out);
    logger.logger.groupEnd();
  }
  let gradleOpts = [];
  if (cli.flags['gradleOpts']) {
    gradleOpts = cli.flags['gradleOpts'].split(' ').map(s => s.trim()).filter(Boolean);
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$p);
    return;
  }
  await convertGradleToMaven(target, bin, out, verbose, gradleOpts);
}

const config$p = {
  commandName: 'manifest',
  description: 'Generate a dependency manifest for given file or dir',
  hidden: false,
  flags: {
    ...commonFlags
  }};
const cmdManifest = {
  description: config$p.description,
  hidden: config$p.hidden,
  run: run$p
};
async function run$p(argv, importMeta, {
  parentName
}) {
  await meowWithSubcommands({
    auto: cmdManifestAuto,
    scala: cmdManifestScala,
    gradle: cmdManifestGradle,
    kotlin: cmdManifestKotlin
  }, {
    argv,
    aliases: {
      yolo: {
        description: config$p.description,
        hidden: true,
        argv: ['auto']
      }
    },
    description: config$p.description,
    importMeta,
    flags: config$p.flags,
    name: `${parentName} ${config$p.commandName}`
  });
}

const {
  NPM: NPM$8
} = constants;
async function wrapNpm(argv) {
  // Lazily access constants.distShadowNpmBinPath.
  const shadowBin = require(constants.distShadowNpmBinPath);
  await shadowBin(NPM$8, argv);
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$o,
  NPM: NPM$7
} = constants;
const config$o = {
  commandName: 'npm',
  description: `${NPM$7} wrapper functionality`,
  hidden: false,
  flags: {},
  help: (command, _config) => `
    Usage
      $ ${command}
  `
};
const cmdNpm = {
  description: config$o.description,
  hidden: config$o.hidden,
  run: run$o
};
async function run$o(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$o,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$o);
    return;
  }
  await wrapNpm(argv);
}

const {
  NPX: NPX$2
} = constants;
async function wrapNpx(argv) {
  // Lazily access constants.distShadowNpmBinPath.
  const shadowBin = require(constants.distShadowNpmBinPath);
  await shadowBin(NPX$2, argv);
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$n,
  NPX: NPX$1
} = constants;
const config$n = {
  commandName: 'npx',
  description: `${NPX$1} wrapper functionality`,
  hidden: false,
  flags: {},
  help: (command, _config) => `
    Usage
      $ ${command}
  `
};
const cmdNpx = {
  description: config$n.description,
  hidden: config$n.hidden,
  run: run$n
};
async function run$n(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$n,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$n);
    return;
  }
  await wrapNpx(argv);
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$m
} = constants;
const config$m = {
  commandName: 'oops',
  description: 'Trigger an intentional error (for development)',
  hidden: true,
  flags: {
    ...commonFlags
  },
  help: (parentName, config) => `
    Usage
      $ ${parentName} ${config.commandName}

    Don't run me.
  `
};
const cmdOops = {
  description: config$m.description,
  hidden: config$m.hidden,
  run: run$m
};
async function run$m(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$m,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$m);
    return;
  }
  throw new Error('This error was intentionally left blank');
}

const {
  BUN: BUN$4,
  NPM: NPM$6,
  PNPM: PNPM$6,
  VLT: VLT$4,
  YARN_BERRY: YARN_BERRY$4,
  YARN_CLASSIC: YARN_CLASSIC$5
} = constants;
function matchLsCmdViewHumanStdout(stdout, name) {
  return stdout.includes(` ${name}@`);
}
function matchQueryCmdStdout(stdout, name) {
  return stdout.includes(`"${name}"`);
}
const depsIncludesByAgent = new Map([[BUN$4, matchLsCmdViewHumanStdout], [NPM$6, matchQueryCmdStdout], [PNPM$6, matchQueryCmdStdout], [VLT$4, matchQueryCmdStdout], [YARN_BERRY$4, matchLsCmdViewHumanStdout], [YARN_CLASSIC$5, matchLsCmdViewHumanStdout]]);

function getDependencyEntries(pkgJson) {
  const {
    dependencies,
    devDependencies,
    optionalDependencies,
    peerDependencies
  } = pkgJson;
  return [['dependencies', dependencies ? {
    __proto__: null,
    ...dependencies
  } : undefined], ['devDependencies', devDependencies ? {
    __proto__: null,
    ...devDependencies
  } : undefined], ['peerDependencies', peerDependencies ? {
    __proto__: null,
    ...peerDependencies
  } : undefined], ['optionalDependencies', optionalDependencies ? {
    __proto__: null,
    ...optionalDependencies
  } : undefined]].filter(({
    1: o
  }) => o);
}

const {
  BUN: BUN$3,
  NPM: NPM$5,
  OVERRIDES: OVERRIDES$1,
  PNPM: PNPM$5,
  RESOLUTIONS: RESOLUTIONS$1,
  VLT: VLT$3,
  YARN_BERRY: YARN_BERRY$3,
  YARN_CLASSIC: YARN_CLASSIC$4
} = constants;
function getOverridesDataBun(pkgJson) {
  const overrides = pkgJson?.[RESOLUTIONS$1] ?? {};
  return {
    type: YARN_BERRY$3,
    overrides
  };
}

// npm overrides documentation:
// https://docs.npmjs.com/cli/v10/configuring-npm/package-json#overrides
function getOverridesDataNpm(pkgJson) {
  const overrides = pkgJson?.[OVERRIDES$1] ?? {};
  return {
    type: NPM$5,
    overrides
  };
}

// pnpm overrides documentation:
// https://pnpm.io/package_json#pnpmoverrides
function getOverridesDataPnpm(pkgJson) {
  const overrides = pkgJson?.pnpm?.[OVERRIDES$1] ?? {};
  return {
    type: PNPM$5,
    overrides
  };
}
function getOverridesDataVlt(pkgJson) {
  const overrides = pkgJson?.[OVERRIDES$1] ?? {};
  return {
    type: VLT$3,
    overrides
  };
}

// Yarn resolutions documentation:
// https://yarnpkg.com/configuration/manifest#resolutions
function getOverridesDataYarn(pkgJson) {
  const overrides = pkgJson?.[RESOLUTIONS$1] ?? {};
  return {
    type: YARN_BERRY$3,
    overrides
  };
}

// Yarn resolutions documentation:
// https://classic.yarnpkg.com/en/docs/selective-version-resolutions
function getOverridesDataClassic(pkgJson) {
  const overrides = pkgJson?.[RESOLUTIONS$1] ?? {};
  return {
    type: YARN_CLASSIC$4,
    overrides
  };
}
const overridesDataByAgent = new Map([[BUN$3, getOverridesDataBun], [NPM$5, getOverridesDataNpm], [PNPM$5, getOverridesDataPnpm], [VLT$3, getOverridesDataVlt], [YARN_BERRY$3, getOverridesDataYarn], [YARN_CLASSIC$4, getOverridesDataClassic]]);

const {
  PNPM: PNPM$4
} = constants;
const PNPM_WORKSPACE = `${PNPM$4}-workspace`;
async function getWorkspaceGlobs(agent, pkgPath, pkgJson) {
  let workspacePatterns;
  if (agent === PNPM$4) {
    for (const workspacePath of [path$1.join(pkgPath, `${PNPM_WORKSPACE}.yaml`), path$1.join(pkgPath, `${PNPM_WORKSPACE}.yml`)]) {
      // eslint-disable-next-line no-await-in-loop
      const yml = await shadowNpmInject.safeReadFile(workspacePath);
      if (yml) {
        try {
          workspacePatterns = yaml.parse(yml)?.packages;
        } catch {}
        if (workspacePatterns) {
          break;
        }
      }
    }
  } else {
    workspacePatterns = pkgJson['workspaces'];
  }
  return Array.isArray(workspacePatterns) ? workspacePatterns.filter(strings.isNonEmptyString).map(workspacePatternToGlobPattern) : undefined;
}
function workspacePatternToGlobPattern(workspace) {
  const {
    length
  } = workspace;
  if (!length) {
    return '';
  }
  // If the workspace ends with "/"
  if (workspace.charCodeAt(length - 1) === 47 /*'/'*/) {
    return `${workspace}/*/package.json`;
  }
  // If the workspace ends with "/**"
  if (workspace.charCodeAt(length - 1) === 42 /*'*'*/ && workspace.charCodeAt(length - 2) === 42 /*'*'*/ && workspace.charCodeAt(length - 3) === 47 /*'/'*/) {
    return `${workspace}/*/**/package.json`;
  }
  // Things like "packages/a" or "packages/*"
  return `${workspace}/package.json`;
}

const {
  BUN: BUN$2,
  LOCK_EXT,
  NPM: NPM$4,
  PNPM: PNPM$3,
  VLT: VLT$2,
  YARN_BERRY: YARN_BERRY$2,
  YARN_CLASSIC: YARN_CLASSIC$3
} = constants;
function includesNpm(lockSrc, name) {
  // Detects the package name in the following cases:
  //   "name":
  return lockSrc.includes(`"${name}":`);
}
function includesBun(lockSrc, name, lockName) {
  // This is a bit counterintuitive. When lockName ends with a .lockb
  // we treat it as a yarn.lock. When lockName ends with a .lock we
  // treat it as a package-lock.json. The bun.lock format is not identical
  // package-lock.json, however it close enough for npmLockIncludes to work.
  const lockfileScanner = lockName?.endsWith(LOCK_EXT) ? includesNpm : includesYarn;
  return lockfileScanner(lockSrc, name);
}
function includesPnpm(lockSrc, name) {
  const escapedName = regexps.escapeRegExp(name);
  return new RegExp(
  // Detects the package name in the following cases:
  //   /name/
  //   'name'
  //   name:
  //   name@
  `(?<=^\\s*)(?:(['/])${escapedName}\\1|${escapedName}(?=[:@]))`, 'm').test(lockSrc);
}
function includesVlt(lockSrc, name) {
  // Detects the package name in the following cases:
  //   "name"
  return lockSrc.includes(`"${name}"`);
}
function includesYarn(lockSrc, name) {
  const escapedName = regexps.escapeRegExp(name);
  return new RegExp(
  // Detects the package name in the following cases:
  //   "name@
  //   , "name@
  //   name@
  //   , name@
  `(?<=(?:^\\s*|,\\s*)"?)${escapedName}(?=@)`, 'm').test(lockSrc);
}
const lockfileIncludesByAgent = new Map([[BUN$2, includesBun], [NPM$4, includesNpm], [PNPM$3, includesPnpm], [VLT$2, includesVlt], [YARN_BERRY$2, includesYarn], [YARN_CLASSIC$3, includesYarn]]);

const {
  BUN: BUN$1,
  NPM: NPM$3,
  PNPM: PNPM$2,
  VLT: VLT$1,
  YARN_BERRY: YARN_BERRY$1,
  YARN_CLASSIC: YARN_CLASSIC$2
} = constants;
function cleanupQueryStdout(stdout) {
  if (stdout === '') {
    return '';
  }
  let pkgs;
  try {
    pkgs = JSON.parse(stdout);
  } catch {}
  if (!Array.isArray(pkgs)) {
    return '';
  }
  const names = new Set();
  for (const {
    _id,
    name,
    pkgid
  } of pkgs) {
    // `npm query` results may not have a "name" property, in which case we
    // fallback to "_id" and then "pkgid".
    // `vlt ls --view json` results always have a "name" property.
    const fallback = _id ?? pkgid ?? '';
    const resolvedName = name ?? fallback.slice(0, fallback.indexOf('@', 1));
    // Add package names, except for those under the `@types` scope as those
    // are known to only be dev dependencies.
    if (resolvedName && !resolvedName.startsWith('@types/')) {
      names.add(resolvedName);
    }
  }
  return JSON.stringify([...names], null, 2);
}
function parsableToQueryStdout(stdout) {
  if (stdout === '') {
    return '';
  }
  // Convert the parsable stdout into a json array of unique names.
  // The matchAll regexp looks for a forward (posix) or backward (win32) slash
  // and matches one or more non-slashes until the newline.
  const names = new Set(stdout.matchAll(/(?<=[/\\])[^/\\]+(?=\n)/g));
  return JSON.stringify([...names], null, 2);
}
async function npmQuery(npmExecPath, cwd) {
  let stdout = '';
  try {
    stdout = (await spawn.spawn(npmExecPath, ['query', ':not(.dev)'], {
      cwd
    })).stdout;
  } catch {}
  return cleanupQueryStdout(stdout);
}
async function lsBun(agentExecPath, cwd) {
  try {
    // Bun does not support filtering by production packages yet.
    // https://github.com/oven-sh/bun/issues/8283
    return (await spawn.spawn(agentExecPath, ['pm', 'ls', '--all'], {
      cwd
    })).stdout;
  } catch {}
  return '';
}
async function lsNpm(agentExecPath, cwd) {
  return await npmQuery(agentExecPath, cwd);
}
async function lsPnpm(agentExecPath, cwd, options) {
  const npmExecPath = options?.npmExecPath;
  if (npmExecPath && npmExecPath !== NPM$3) {
    const result = await npmQuery(npmExecPath, cwd);
    if (result) {
      return result;
    }
  }
  let stdout = '';
  try {
    stdout = (await spawn.spawn(agentExecPath,
    // Pnpm uses the alternative spelling of parsable.
    // https://en.wiktionary.org/wiki/parsable
    ['ls', '--parseable', '--prod', '--depth', 'Infinity'], {
      cwd
    })).stdout;
  } catch {}
  return parsableToQueryStdout(stdout);
}
async function lsVlt(agentExecPath, cwd) {
  let stdout = '';
  try {
    // See https://docs.vlt.sh/cli/commands/list#options.
    stdout = (await spawn.spawn(agentExecPath, ['ls', '--view', 'human', ':not(.dev)'], {
      cwd
    })).stdout;
  } catch {}
  return cleanupQueryStdout(stdout);
}
async function lsYarnBerry(agentExecPath, cwd) {
  try {
    return (
      // Yarn Berry does not support filtering by production packages yet.
      // https://github.com/yarnpkg/berry/issues/5117
      (await spawn.spawn(agentExecPath, ['info', '--recursive', '--name-only'], {
        cwd
      })).stdout.trim()
    );
  } catch {}
  return '';
}
async function lsYarnClassic(agentExecPath, cwd) {
  try {
    // However, Yarn Classic does support it.
    // https://github.com/yarnpkg/yarn/releases/tag/v1.0.0
    // > Fix: Excludes dev dependencies from the yarn list output when the
    //   environment is production
    return (await spawn.spawn(agentExecPath, ['list', '--prod'], {
      cwd
    })).stdout.trim();
  } catch {}
  return '';
}
const lsByAgent = new Map([[BUN$1, lsBun], [NPM$3, lsNpm], [PNPM$2, lsPnpm], [VLT$1, lsVlt], [YARN_BERRY$1, lsYarnBerry], [YARN_CLASSIC$2, lsYarnClassic]]);

const {
  BUN,
  NPM: NPM$2,
  OVERRIDES,
  PNPM: PNPM$1,
  RESOLUTIONS,
  VLT,
  YARN_BERRY,
  YARN_CLASSIC: YARN_CLASSIC$1
} = constants;
const depFields = ['dependencies', 'devDependencies', 'peerDependencies', 'peerDependenciesMeta', 'optionalDependencies', 'bundleDependencies'];
function getEntryIndexes(entries, keys) {
  return keys.map(n => entries.findIndex(p => p[0] === n)).filter(n => n !== -1).sort((a, b) => a - b);
}
function getLowestEntryIndex(entries, keys) {
  return getEntryIndexes(entries, keys)?.[0] ?? -1;
}
function getHighestEntryIndex(entries, keys) {
  return getEntryIndexes(entries, keys).at(-1) ?? -1;
}
function updatePkgJsonField(editablePkgJson, field, value) {
  const {
    content: pkgJson
  } = editablePkgJson;
  const oldValue = pkgJson[field];
  if (oldValue) {
    // The field already exists so we simply update the field value.
    if (field === PNPM$1) {
      const isPnpmObj = objects.isObject(oldValue);
      if (objects.hasKeys(value)) {
        editablePkgJson.update({
          [field]: {
            ...(isPnpmObj ? oldValue : {}),
            overrides: {
              ...(isPnpmObj ? oldValue[OVERRIDES] : {}),
              ...value
            }
          }
        });
      } else {
        // Properties with undefined values are omitted when saved as JSON.
        editablePkgJson.update(objects.hasKeys(oldValue) ? {
          [field]: {
            ...(isPnpmObj ? oldValue : {}),
            overrides: undefined
          }
        } : {
          [field]: undefined
        });
      }
    } else if (field === OVERRIDES || field === RESOLUTIONS) {
      // Properties with undefined values are omitted when saved as JSON.
      editablePkgJson.update({
        [field]: objects.hasKeys(value) ? value : undefined
      });
    } else {
      editablePkgJson.update({
        [field]: value
      });
    }
    return;
  }
  if ((field === OVERRIDES || field === PNPM$1 || field === RESOLUTIONS) && !objects.hasKeys(value)) {
    return;
  }
  // Since the field doesn't exist we want to insert it into the package.json
  // in a place that makes sense, e.g. close to the "dependencies" field. If
  // we can't find a place to insert the field we'll add it to the bottom.
  const entries = Object.entries(pkgJson);
  let insertIndex = -1;
  let isPlacingHigher = false;
  if (field === OVERRIDES) {
    insertIndex = getLowestEntryIndex(entries, [RESOLUTIONS]);
    if (insertIndex === -1) {
      isPlacingHigher = true;
      insertIndex = getHighestEntryIndex(entries, [...depFields, PNPM$1]);
    }
  } else if (field === RESOLUTIONS) {
    isPlacingHigher = true;
    insertIndex = getHighestEntryIndex(entries, [...depFields, OVERRIDES, PNPM$1]);
  } else if (field === PNPM$1) {
    insertIndex = getLowestEntryIndex(entries, [OVERRIDES, RESOLUTIONS]);
    if (insertIndex === -1) {
      isPlacingHigher = true;
      insertIndex = getHighestEntryIndex(entries, depFields);
    }
  }
  if (insertIndex === -1) {
    insertIndex = getLowestEntryIndex(entries, ['engines', 'files']);
  }
  if (insertIndex === -1) {
    isPlacingHigher = true;
    insertIndex = getHighestEntryIndex(entries, ['exports', 'imports', 'main']);
  }
  if (insertIndex === -1) {
    insertIndex = entries.length;
  } else if (isPlacingHigher) {
    insertIndex += 1;
  }
  entries.splice(insertIndex, 0, [field, field === PNPM$1 ? {
    [OVERRIDES]: value
  } : value]);
  editablePkgJson.fromJSON(`${JSON.stringify(Object.fromEntries(entries), null, 2)}\n`);
}
function updateOverridesField(editablePkgJson, overrides) {
  updatePkgJsonField(editablePkgJson, OVERRIDES, overrides);
}
function updateResolutionsField(editablePkgJson, overrides) {
  updatePkgJsonField(editablePkgJson, RESOLUTIONS, overrides);
}
function updatePnpmField(editablePkgJson, overrides) {
  updatePkgJsonField(editablePkgJson, PNPM$1, overrides);
}
const updateManifestByAgent = new Map([[BUN, updateResolutionsField], [NPM$2, updateOverridesField], [PNPM$1, updatePnpmField], [VLT, updateOverridesField], [YARN_BERRY, updateResolutionsField], [YARN_CLASSIC$1, updateResolutionsField]]);

const {
  NPM: NPM$1,
  PNPM,
  YARN_CLASSIC
} = constants;
const CMD_NAME$1 = 'socket optimize';
const manifestNpmOverrides = registry.getManifestData(NPM$1);
async function addOverrides(pkgPath, pkgEnvDetails, options) {
  const {
    agent,
    agentExecPath,
    lockName,
    lockSrc,
    npmExecPath,
    pkgPath: rootPath
  } = pkgEnvDetails;
  const {
    logger,
    pin,
    prod,
    spinner,
    state = {
      added: new Set(),
      addedInWorkspaces: new Set(),
      updated: new Set(),
      updatedInWorkspaces: new Set(),
      warnedPnpmWorkspaceRequiresNpm: false
    }
  } = {
    __proto__: null,
    ...options
  };
  let {
    pkgJson: editablePkgJson
  } = pkgEnvDetails;
  if (editablePkgJson === undefined) {
    editablePkgJson = await packages.readPackageJson(pkgPath, {
      editable: true
    });
  }
  const {
    content: pkgJson
  } = editablePkgJson;
  const workspaceName = path$1.relative(rootPath, pkgPath);
  const workspaceGlobs = await getWorkspaceGlobs(agent, pkgPath, pkgJson);
  const isRoot = pkgPath === rootPath;
  const isLockScanned = isRoot && !prod;
  const isWorkspace = !!workspaceGlobs;
  if (isWorkspace && agent === PNPM &&
  // npmExecPath will === the agent name IF it CANNOT be resolved.
  npmExecPath === NPM$1 && !state.warnedPnpmWorkspaceRequiresNpm) {
    state.warnedPnpmWorkspaceRequiresNpm = true;
    logger?.warn(cmdPrefixMessage(CMD_NAME$1, `${agent} workspace support requires \`npm ls\`, falling back to \`${agent} list\``));
  }
  const overridesDataObjects = [];
  if (pkgJson['private'] || isWorkspace) {
    overridesDataObjects.push(overridesDataByAgent.get(agent)(pkgJson));
  } else {
    overridesDataObjects.push(overridesDataByAgent.get(NPM$1)(pkgJson), overridesDataByAgent.get(YARN_CLASSIC)(pkgJson));
  }
  spinner?.setText(`Adding overrides${workspaceName ? ` to ${workspaceName}` : ''}...`);
  const depAliasMap = new Map();
  const depEntries = getDependencyEntries(pkgJson);
  const manifestEntries = manifestNpmOverrides.filter(({
    1: data
  }) => semver.satisfies(
  // Roughly check Node range as semver.coerce will strip leading
  // v's, carets (^), comparators (<,<=,>,>=,=), and tildes (~).
  semver.coerce(data.engines.node), pkgEnvDetails.pkgRequirements.node));

  // Chunk package names to process them in parallel 3 at a time.
  await promises.pEach(manifestEntries, 3, async ({
    1: data
  }) => {
    const {
      name: sockRegPkgName,
      package: origPkgName,
      version
    } = data;
    const major = semver.major(version);
    const sockOverridePrefix = `${NPM$1}:${sockRegPkgName}@`;
    const sockOverrideSpec = `${sockOverridePrefix}${pin ? version : `^${major}`}`;
    for (const {
      1: depObj
    } of depEntries) {
      const sockSpec = objects.hasOwn(depObj, sockRegPkgName) ? depObj[sockRegPkgName] : undefined;
      if (sockSpec) {
        depAliasMap.set(sockRegPkgName, sockSpec);
      }
      const origSpec = objects.hasOwn(depObj, origPkgName) ? depObj[origPkgName] : undefined;
      if (origSpec) {
        let thisSpec = origSpec;
        // Add package aliases for direct dependencies to avoid npm EOVERRIDE
        // errors...
        // https://docs.npmjs.com/cli/v8/using-npm/package-spec#aliases
        if (
        // ...if the spec doesn't start with a valid Socket override.
        !(thisSpec.startsWith(sockOverridePrefix) &&
        // Check the validity of the spec by passing it through npa and
        // seeing if it will coerce to a version.
        semver.coerce(npa(thisSpec).rawSpec)?.version)) {
          thisSpec = sockOverrideSpec;
          depObj[origPkgName] = thisSpec;
          state.added.add(sockRegPkgName);
          if (workspaceName) {
            state.addedInWorkspaces.add(workspaceName);
          }
        }
        depAliasMap.set(origPkgName, thisSpec);
      }
    }
    if (isRoot) {
      // The AgentDepsIncludesFn and AgentLockIncludesFn types overlap in their
      // first two parameters. AgentLockIncludesFn accepts an optional third
      // parameter which AgentDepsIncludesFn will ignore so we cast thingScanner
      // as an AgentLockIncludesFn type.
      const thingScanner = isLockScanned ? lockfileIncludesByAgent.get(agent) : depsIncludesByAgent.get(agent);
      const thingToScan = isLockScanned ? lockSrc : await lsByAgent.get(agent)(agentExecPath, pkgPath, {
        npmExecPath
      });
      // Chunk package names to process them in parallel 3 at a time.
      await promises.pEach(overridesDataObjects, 3, async ({
        overrides,
        type
      }) => {
        const overrideExists = objects.hasOwn(overrides, origPkgName);
        if (overrideExists || thingScanner(thingToScan, origPkgName, lockName)) {
          const oldSpec = overrideExists ? overrides[origPkgName] : undefined;
          const origDepAlias = depAliasMap.get(origPkgName);
          const sockRegDepAlias = depAliasMap.get(sockRegPkgName);
          const depAlias = sockRegDepAlias ?? origDepAlias;
          let newSpec = sockOverrideSpec;
          if (type === NPM$1 && depAlias) {
            // With npm one may not set an override for a package that one directly
            // depends on unless both the dependency and the override itself share
            // the exact same spec. To make this limitation easier to deal with,
            // overrides may also be defined as a reference to a spec for a direct
            // dependency by prefixing the name of the package to match the version
            // of with a $.
            // https://docs.npmjs.com/cli/v8/configuring-npm/package-json#overrides
            newSpec = `$${sockRegDepAlias ? sockRegPkgName : origPkgName}`;
          } else if (typeof oldSpec === 'string') {
            const thisSpec = oldSpec.startsWith('$') ? depAlias || newSpec : oldSpec || newSpec;
            if (thisSpec.startsWith(sockOverridePrefix)) {
              if (pin && semver.major(
              // Check the validity of the spec by passing it through npa
              // and seeing if it will coerce to a version. semver.coerce
              // will strip leading v's, carets (^), comparators (<,<=,>,>=,=),
              // and tildes (~). If not coerced to a valid version then
              // default to the manifest entry version.
              semver.coerce(npa(thisSpec).rawSpec)?.version ?? version) !== major) {
                const otherVersion = (await packages.fetchPackageManifest(thisSpec))?.version;
                if (otherVersion && otherVersion !== version) {
                  newSpec = `${sockOverridePrefix}${pin ? otherVersion : `^${semver.major(otherVersion)}`}`;
                }
              }
            } else {
              newSpec = oldSpec;
            }
          }
          if (newSpec !== oldSpec) {
            overrides[origPkgName] = newSpec;
            const addedOrUpdated = overrideExists ? 'updated' : 'added';
            state[addedOrUpdated].add(sockRegPkgName);
          }
        }
      });
    }
  });
  if (workspaceGlobs) {
    const workspacePkgJsonPaths = await tinyglobby.glob(workspaceGlobs, {
      absolute: true,
      cwd: pkgPath,
      ignore: ['**/node_modules/**', '**/bower_components/**']
    });
    // Chunk package names to process them in parallel 3 at a time.
    await promises.pEach(workspacePkgJsonPaths, 3, async workspacePkgJsonPath => {
      const otherState = await addOverrides(path$1.dirname(workspacePkgJsonPath), pkgEnvDetails, {
        logger,
        pin,
        prod,
        spinner
      });
      for (const key of ['added', 'addedInWorkspaces', 'updated', 'updatedInWorkspaces']) {
        for (const value of otherState[key]) {
          state[key].add(value);
        }
      }
    });
  }
  if (state.added.size > 0 || state.updated.size > 0) {
    editablePkgJson.update(Object.fromEntries(depEntries));
    for (const {
      overrides,
      type
    } of overridesDataObjects) {
      updateManifestByAgent.get(type)(editablePkgJson, objects.toSortedObject(overrides));
    }
    await editablePkgJson.save();
  }
  return state;
}

const {
  NPM_BUGGY_OVERRIDES_PATCHED_VERSION
} = constants;
async function updateLockfile(pkgEnvDetails, options) {
  const {
    cmdName = '',
    logger,
    spinner
  } = {
    __proto__: null,
    ...options
  };
  const isSpinning = !!spinner?.['isSpinning'];
  if (!isSpinning) {
    spinner?.start();
  }
  spinner?.setText(`Updating ${pkgEnvDetails.lockName}...`);
  try {
    await runAgentInstall(pkgEnvDetails, {
      spinner
    });
    if (pkgEnvDetails.features.npmBuggyOverrides) {
      logger?.log(`ðŸ’¡ Re-run ${cmdName ? `${cmdName} ` : ''}whenever ${pkgEnvDetails.lockName} changes.\n   This can be skipped for ${pkgEnvDetails.agent} >=${NPM_BUGGY_OVERRIDES_PATCHED_VERSION}.`);
    }
  } catch (e) {
    spinner?.stop();
    logger?.fail(cmdPrefixMessage(cmdName, `${pkgEnvDetails.agent} install failed to update ${pkgEnvDetails.lockName}`));
    logger?.error(e);
  }
  if (isSpinning) {
    spinner?.start();
  } else {
    spinner?.stop();
  }
}

const CMD_NAME = 'socket optimize';
function createActionMessage(verb, overrideCount, workspaceCount) {
  return `${verb} ${overrideCount} Socket.dev optimized ${words.pluralize('override', overrideCount)}${workspaceCount ? ` in ${workspaceCount} ${words.pluralize('workspace', workspaceCount)}` : ''}`;
}
async function applyOptimization(cwd, pin, prod) {
  const pkgEnvDetails = await detectAndValidatePackageEnvironment(cwd, {
    cmdName: CMD_NAME,
    logger: logger.logger,
    prod
  });
  if (!pkgEnvDetails) {
    return;
  }
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Socket optimizing...');
  const state = await addOverrides(pkgEnvDetails.pkgPath, pkgEnvDetails, {
    logger: logger.logger,
    pin,
    prod,
    spinner
  });
  const addedCount = state.added.size;
  const updatedCount = state.updated.size;
  const pkgJsonChanged = addedCount > 0 || updatedCount > 0;
  if (pkgJsonChanged || pkgEnvDetails.features.npmBuggyOverrides) {
    await updateLockfile(pkgEnvDetails, {
      cmdName: CMD_NAME,
      logger: logger.logger,
      spinner
    });
  }
  spinner.stop();
  if (pkgJsonChanged) {
    if (updatedCount > 0) {
      logger.logger?.log(`${createActionMessage('Updated', updatedCount, state.updatedInWorkspaces.size)}${addedCount ? '.' : 'ðŸš€'}`);
    }
    if (addedCount > 0) {
      logger.logger?.log(`${createActionMessage('Added', addedCount, state.addedInWorkspaces.size)} ðŸš€`);
    }
  } else {
    logger.logger?.log('Congratulations! Already Socket.dev optimized ðŸŽ‰');
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$l
} = constants;
const config$l = {
  commandName: 'optimize',
  description: 'Optimize dependencies with @socketregistry overrides',
  hidden: false,
  flags: {
    ...commonFlags,
    pin: {
      type: 'boolean',
      default: false,
      description: 'Pin overrides to their latest version'
    },
    prod: {
      type: 'boolean',
      default: false,
      description: 'Only add overrides for production dependencies'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}
      $ ${command} --pin
  `
};
const cmdOptimize = {
  description: config$l.description,
  hidden: config$l.hidden,
  run: run$l
};
async function run$l(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$l,
    importMeta,
    parentName
  });
  const cwd = process$1.cwd();
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$l);
    return;
  }
  await applyOptimization(cwd, Boolean(cli.flags['pin']), Boolean(cli.flags['prod']));
}

async function fetchOrganization() {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchOrganizationWithToken(apiToken);
}
async function fetchOrganizationWithToken(apiToken) {
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);

  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Fetching organization list...');
  const result = await handleApiCall(socketSdk.getOrganizations(), 'looking up organizations');
  spinner.successAndStop('Received organization list response.');
  if (!result.success) {
    handleUnsuccessfulApiResponse('getOrganizations', result);
    return;
  }
  return result.data;
}

async function outputOrganizationList(data, outputKind = 'text') {
  const organizations = Object.values(data.organizations);
  const apiToken = shadowNpmInject.getDefaultToken();
  const lastFiveOfApiToken = getLastFiveOfApiToken(apiToken ?? '?????');
  switch (outputKind) {
    case 'json':
      {
        logger.logger.log(JSON.stringify(organizations.map(o => ({
          name: o.name,
          id: o.id,
          plan: o.plan
        })), null, 2));
        return;
      }
    case 'markdown':
      {
        // | Syntax      | Description |
        // | ----------- | ----------- |
        // | Header      | Title       |
        // | Paragraph   | Text        |
        let mw1 = 4;
        let mw2 = 2;
        let mw3 = 4;
        for (const o of organizations) {
          mw1 = Math.max(mw1, o.name.length);
          mw2 = Math.max(mw2, o.id.length);
          mw3 = Math.max(mw3, o.plan.length);
        }
        logger.logger.log('# Organizations\n');
        logger.logger.log(`List of organizations associated with your API key, ending with: ${colors.italic(lastFiveOfApiToken)}\n`);
        logger.logger.log(`| Name${' '.repeat(mw1 - 4)} | ID${' '.repeat(mw2 - 2)} | Plan${' '.repeat(mw3 - 4)} |`);
        logger.logger.log(`| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} | ${'-'.repeat(mw3)} |`);
        for (const o of organizations) {
          logger.logger.log(`| ${(o.name || '').padEnd(mw1, ' ')} | ${(o.id || '').padEnd(mw2, ' ')} | ${(o.plan || '').padEnd(mw3, ' ')} |`);
        }
        logger.logger.log(`| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} | ${'-'.repeat(mw3)} |`);
        return;
      }
    default:
      {
        logger.logger.log(`List of organizations associated with your API key, ending with: ${colors.italic(lastFiveOfApiToken)}\n`);
        // Just dump
        for (const o of organizations) {
          logger.logger.log(`- Name: ${colors.bold(o.name)}, ID: ${colors.bold(o.id)}, Plan: ${colors.bold(o.plan)}`);
        }
      }
  }
}

async function handleOrganizationList(outputKind = 'text') {
  const data = await fetchOrganization();
  if (!data) return;
  await outputOrganizationList(data, outputKind);
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$k
} = constants;
const config$k = {
  commandName: 'list',
  description: 'List organizations associated with the API key used',
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}

    Options
      ${getFlagListOutput(config$k.flags, 6)}
  `
};
const cmdOrganizationList = {
  description: config$k.description,
  hidden: config$k.hidden,
  run: run$k
};
async function run$k(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$k,
    importMeta,
    parentName
  });
  const json = Boolean(cli.flags['json']);
  const markdown = Boolean(cli.flags['markdown']);
  if (json && markdown) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

  - The json and markdown flags cannot be both set, pick one
    `);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$k);
    return;
  }
  await handleOrganizationList(json ? 'json' : markdown ? 'markdown' : 'text');
}

async function fetchSecurityPolicy(orgSlug) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchSecurityPolicyWithToken(apiToken, orgSlug);
}
async function fetchSecurityPolicyWithToken(apiToken, orgSlug) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  spinner.start('Fetching organization quota...');
  const result = await handleApiCall(socketSdk.getOrgSecurityPolicy(orgSlug), 'looking up organization quota');
  spinner?.successAndStop('Received organization quota response.');
  if (!result.success) {
    handleUnsuccessfulApiResponse('getOrgSecurityPolicy', result);
    return;
  }
  return result.data;
}

async function getSecurityPolicy(data, outputKind) {
  if (outputKind === 'json') {
    let json;
    try {
      json = JSON.stringify(data, null, 2);
    } catch {
      console.error('Failed to convert the server response to json, try running the same command without --json');
      return;
    }
    logger.logger.log(json);
    logger.logger.log('');
    return;
  }
  logger.logger.log('# Security policy');
  logger.logger.log('');
  logger.logger.log(`The default security policy setting is: "${data.securityPolicyDefault}"`);
  logger.logger.log('');
  logger.logger.log('These are the security policies per setting for your organization:');
  logger.logger.log('');
  const rules = data.securityPolicyRules;
  const entries = Object.entries(rules);
  const mapped = entries.map(([key, value]) => [key, value.action]);
  mapped.sort(([a], [b]) => a < b ? -1 : a > b ? 1 : 0);
  logger.logger.log(mdTableOfPairs(mapped, ['name', 'action']));
  logger.logger.log('');
}

async function handleSecurityPolicy(orgSlug, outputKind) {
  const data = await fetchSecurityPolicy(orgSlug);
  if (!data) return;
  await getSecurityPolicy(data, outputKind);
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$j
} = constants;

// TODO: secret toplevel alias `socket security policy`?
const config$j = {
  commandName: 'security',
  description: 'Retrieve the security policy of an organization.',
  hidden: true,
  flags: {
    ...commonFlags,
    ...outputFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${getFlagListOutput(config$j.flags, 6)}

    Your API token will need the \`security-policy:read\` permission otherwise
    the request will fail with an authentication error.

    Examples
      $ ${command} mycorp
      $ ${command} mycorp --json
  `
};
const cmdOrganizationPolicyPolicy = {
  description: config$j.description,
  hidden: config$j.hidden,
  run: run$j
};
async function run$j(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$j,
    importMeta,
    parentName
  });
  const json = Boolean(cli.flags['json']);
  const markdown = Boolean(cli.flags['markdown']);
  const [orgSlug = ''] = cli.input;
  if (!orgSlug || json && markdown) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

  - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}
  - The json and markdown flags cannot be both set ${json && markdown ? colors.red('(pick one!)') : colors.green('(ok)')}
    `);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$j);
    return;
  }
  await handleSecurityPolicy(orgSlug, json ? 'json' : markdown ? 'markdown' : 'text');
}

const description$5 = 'Organization policy details';
const cmdOrganizationPolicy = {
  description: description$5,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: true,
  async run(argv, importMeta, {
    parentName
  }) {
    await meowWithSubcommands({
      security: cmdOrganizationPolicyPolicy
    }, {
      argv,
      description: description$5,
      defaultSub: 'list',
      // Backwards compat
      importMeta,
      name: parentName + ' policy'
    });
  }
};

async function fetchQuota() {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchQuotaWithToken(apiToken);
}
async function fetchQuotaWithToken(apiToken) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  spinner.start('Fetching organization quota...');
  const result = await handleApiCall(socketSdk.getQuota(), 'looking up organization quota');
  spinner?.successAndStop('Recieved organization quota response.');
  if (!result.success) {
    handleUnsuccessfulApiResponse('getQuota', result);
    return;
  }
  return result.data;
}

async function outputQuota(data, outputKind = 'text') {
  if (outputKind === 'json') {
    let json;
    try {
      json = JSON.stringify(data, null, 2);
    } catch {
      console.error('Failed to convert the server response to json, try running the same command without --json');
      return;
    }
    logger.logger.log(json);
    logger.logger.log('');
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Quota');
    logger.logger.log('');
    logger.logger.log(`Quota left on the current API token: ${data.quota}`);
    logger.logger.log('');
    return;
  }
  logger.logger.log(`Quota left on the current API token: ${data.quota}`);
  logger.logger.log('');
}

async function handleQuota(outputKind = 'text') {
  const data = await fetchQuota();
  if (!data) return;
  await outputQuota(data, outputKind);
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$i
} = constants;
const config$i = {
  commandName: 'quota',
  description: 'List organizations associated with the API key used',
  hidden: true,
  flags: {
    ...commonFlags,
    ...outputFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}

    Options
      ${getFlagListOutput(config$i.flags, 6)}
  `
};
const cmdOrganizationQuota = {
  description: config$i.description,
  hidden: config$i.hidden,
  run: run$i
};
async function run$i(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$i,
    importMeta,
    parentName
  });
  const json = Boolean(cli.flags['json']);
  const markdown = Boolean(cli.flags['markdown']);
  if (json && markdown) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

  - The json and markdown flags cannot be both set, pick one
    `);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$i);
    return;
  }
  await handleQuota(json ? 'json' : markdown ? 'markdown' : 'text');
}

const description$4 = 'Account details';
const cmdOrganization = {
  description: description$4,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: true,
  async run(argv, importMeta, {
    parentName
  }) {
    await meowWithSubcommands({
      list: cmdOrganizationList,
      quota: cmdOrganizationQuota,
      policy: cmdOrganizationPolicy
    }, {
      argv,
      description: description$4,
      defaultSub: 'list',
      // Backwards compat
      importMeta,
      name: parentName + ' organization'
    });
  }
};

async function fetchPurlsShallowScore(purls) {
  logger.logger.error(`Requesting shallow score data for ${purls.length} package urls (purl): ${purls.join(', ')}`);

  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start(`Requesting data ...`);
  const socketSdk = await shadowNpmInject.setupSdk(shadowNpmInject.getPublicToken());
  const result = await handleApiCall(socketSdk.batchPackageFetch({
    alerts: 'true'
    // compact: false,
    // fixable: false,
    // licenseattrib: false,
    // licensedetails: false
  }, {
    components: purls.map(purl => ({
      purl
    }))
  }), 'looking up package');
  spinner.successAndStop('Request completed');
  if (result.success) {
    return result;
  }
  handleUnsuccessfulApiResponse('batchPackageFetch', result);
}

function outputPurlsShallowScore(purls, packageData, outputKind) {
  if (outputKind === 'json') {
    // In JSON simply return what the server responds with. Don't bother trying
    // to match the response with the requested packages/purls.
    logger.logger.log(JSON.stringify(packageData, undefined, 2));
    return;
  }

  // Make some effort to match the requested data with the response

  const set = new Set();
  packageData.forEach(data => {
    set.add('pkg:' + data.type + '/' + data.name + '@' + data.version);
    set.add('pkg:' + data.type + '/' + data.name);
  });
  const missing = purls.filter(purl => {
    if (set.has(purl)) return false;
    if (purl.endsWith('@latest') && set.has(purl.slice(0, -'@latest'.length))) return false;
    return true; // not found
  });
  if (outputKind === 'markdown') {
    logger.logger.log(commonTags.stripIndents`
      # Shallow Package Report

      This report contains the response for requesting data on some package url(s).

      Please note: The listed scores are ONLY for the package itself. It does NOT
                   reflect the scores of any dependencies, transitive or otherwise.

      ${missing.length ? `\n## Missing response\n\nAt least one package had no response or the purl was not canonical:\n\n${missing.map(purl => '- ' + purl + '\n').join('')}` : ''}

      ${packageData.map(data => '## ' + formatReportCard(data, false)).join('\n\n\n')}
    `);
    return;
  }
  logger.logger.log('\n' + colors.bold('Shallow Package Score') + '\n');
  logger.logger.log('Please note: The listed scores are ONLY for the package itself. It does NOT\n' + '             reflect the scores of any dependencies, transitive or otherwise.');
  if (missing.length) {
    logger.logger.log(`\nAt least one package had no response or the purl was not canonical:\n${missing.map(purl => '\n- ' + colors.bold(purl)).join('')}`);
  }
  packageData.forEach(data => {
    logger.logger.log('\n');
    logger.logger.log(formatReportCard(data, true));
  });
  logger.logger.log('');
}
function formatReportCard(data, color) {
  const scoreResult = {
    'Supply Chain Risk': Math.floor((data.score?.supplyChain ?? 0) * 100),
    Maintenance: Math.floor((data.score?.maintenance ?? 0) * 100),
    Quality: Math.floor((data.score?.quality ?? 0) * 100),
    Vulnerabilities: Math.floor((data.score?.vulnerability ?? 0) * 100),
    License: Math.floor((data.score?.license ?? 0) * 100)
  };
  const alertString = getAlertString(data.alerts, !color);
  const purl = 'pkg:' + data.type + '/' + data.name + '@' + data.version;
  return ['Package: ' + (color ? colors.bold(purl) : purl), '', ...Object.entries(scoreResult).map(score => `- ${score[0]}:`.padEnd(20, ' ') + `  ${formatScore(score[1], !color, true)}`), alertString].join('\n');
}
function formatScore(score, noColor = false, pad = false) {
  const padded = String(score).padStart(pad ? 3 : 0, ' ');
  if (noColor) return padded;else if (score >= 80) return colors.green(padded);else if (score >= 60) return colors.yellow(padded);else return colors.red(padded);
}
function getAlertString(alerts, noColor = false) {
  if (!alerts?.length) {
    return noColor ? `- Alerts: none!` : `- Alerts: ${colors.green('none')}!`;
  } else {
    const bad = alerts.filter(alert => alert.severity !== 'low' && alert.severity !== 'middle').sort((a, b) => a.type < b.type ? -1 : a.type > b.type ? 1 : 0);
    const mid = alerts.filter(alert => alert.severity === 'middle').sort((a, b) => a.type < b.type ? -1 : a.type > b.type ? 1 : 0);
    const low = alerts.filter(alert => alert.severity === 'low').sort((a, b) => a.type < b.type ? -1 : a.type > b.type ? 1 : 0);

    // We need to create the no-color string regardless because the actual string
    // contains a bunch of invisible ANSI chars which would screw up length checks.
    const colorless = `- Alerts (${bad.length}/${mid.length.toString()}/${low.length}):`;
    if (noColor) {
      return colorless + ' '.repeat(Math.max(0, 20 - colorless.length)) + '  ' + [bad.map(alert => `[${alert.severity}] ` + alert.type).join(', '), mid.map(alert => `[${alert.severity}] ` + alert.type).join(', '), low.map(alert => `[${alert.severity}] ` + alert.type).join(', ')].filter(Boolean).join(', ');
    }
    return `- Alerts (${colors.red(bad.length.toString())}/${colors.yellow(mid.length.toString())}/${low.length}):` + ' '.repeat(Math.max(0, 20 - colorless.length)) + '  ' + [bad.map(alert => colors.red(colors.dim(`[${alert.severity}] `) + alert.type)).join(', '), mid.map(alert => colors.yellow(colors.dim(`[${alert.severity}] `) + alert.type)).join(', '), low.map(alert => colors.dim(`[${alert.severity}] `) + alert.type).join(', ')].filter(Boolean).join(', ');
  }
}

async function handlePurlsShallowScore({
  outputKind,
  purls
}) {
  const packageData = await fetchPurlsShallowScore(purls);
  if (packageData) {
    outputPurlsShallowScore(purls, packageData.data, outputKind);
  }
}

// Either an ecosystem was given or all args must be (namespaced) purls
// The `pkg:` part is optional here. We'll scan for `eco/name@version`.
// Not hardcoding the namespace since we don't know what the server accepts.
// The ecosystem is considered as the first package if it is not an a-z string.
function parsePackageSpecifiers(ecosystem, pkgs) {
  let valid = true;
  const purls = [];
  if (!ecosystem) {
    valid = false;
  } else if (/^[a-zA-Z]+$/.test(ecosystem)) {
    for (let i = 0; i < pkgs.length; ++i) {
      const pkg = pkgs[i] ?? '';
      if (!pkg) {
        valid = false;
        break;
      } else if (pkg.startsWith('pkg:')) {
        // keep
        purls.push(pkg);
      } else if (pkg.includes('/')) {
        // Looks like this arg was already namespaced
        purls.push('pkg:' + pkg);
      } else {
        purls.push('pkg:' + ecosystem + '/' + pkg);
      }
    }
    if (!purls.length) {
      valid = false;
    }
  } else {
    // Assume ecosystem is a purl, too
    pkgs.unshift(ecosystem);
    for (let i = 0; i < pkgs.length; ++i) {
      const pkg = pkgs[i] ?? '';
      if (!/^(?:pkg:)?[a-zA-Z]+\/./.test(pkg)) {
        // At least one purl did not start with `pkg:eco/x` or `eco/x`
        valid = false;
        break;
      } else if (pkg.startsWith('pkg:')) {
        purls.push(pkg);
      } else {
        purls.push('pkg:' + pkg);
      }
    }
    if (!purls.length) {
      valid = false;
    }
  }
  return {
    purls,
    valid
  };
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$h
} = constants;
const config$h = {
  commandName: 'shallow',
  description: 'Look up info regarding one or more packages but not their transitives',
  hidden: true,
  flags: {
    ...commonFlags,
    ...outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <<ecosystem> <name> [<name> ...] | <purl> [<purl> ...]>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Requirements
      - quota: 100
      - scope: \`packages:list\`

    Show scoring details for one or more packages purely based on their own package.
    This means that any dependency scores are not reflected by the score. You can
    use the \`socket package score <pkg>\` command to get its full transitive score.

    Only a few ecosystems are supported like npm, golang, and maven.

    A "purl" is a standard package name formatting: \`pkg:eco/name@version\`
    This command will automatically prepend "pkg:" when not present.

    If the first arg is an ecosystem, remaining args that are not a purl are
    assumed to be scoped to that ecosystem.

    Examples
      $ ${command} npm webtorrent
      $ ${command} npm webtorrent@1.9.1
      $ ${command} npm/webtorrent@1.9.1
      $ ${command} pkg:npm/webtorrent@1.9.1
      $ ${command} maven webtorrent babel
      $ ${command} npm/webtorrent golang/babel
      $ ${command} npm npm/webtorrent@1.0.1 babel
  `
};
const cmdPackageShallow = {
  description: config$h.description,
  hidden: config$h.hidden,
  alias: {
    shallowScore: {
      description: config$h.description,
      hidden: true,
      argv: []
    }
  },
  run: run$h
};
async function run$h(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$h,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const [ecosystem = '', ...pkgs] = cli.input;
  const {
    purls,
    valid
  } = parsePackageSpecifiers(ecosystem, pkgs);
  if (!valid || !purls.length) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:\n
      - First parameter should be an ecosystem or all args must be purls ${!valid ? colors.red('(bad!)') : colors.green('(ok)')}\n
      - Expecting at least one package ${!purls.length ? colors.red('(missing!)') : colors.green('(ok)')}\n
    `);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$h);
    return;
  }
  await handlePurlsShallowScore({
    outputKind: json ? 'json' : markdown ? 'markdown' : 'text',
    purls
  });
}

const description$3 = 'Commands relating to looking up published packages';
const cmdPackage = {
  description: description$3,
  hidden: true,
  // [beta]
  async run(argv, importMeta, {
    parentName
  }) {
    await meowWithSubcommands({
      shallow: cmdPackageShallow
    }, {
      aliases: {
        pkg: {
          description: description$3,
          hidden: true,
          argv: []
        }
      },
      argv,
      description: description$3,
      importMeta,
      name: parentName + ' package'
    });
  }
};

async function runRawNpm(argv) {
  const spawnPromise = spawn.spawn(shadowNpmPaths.getNpmBinPath(), argv, {
    stdio: 'inherit'
  });
  // See https://nodejs.org/api/all.html#all_child_process_event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process$1.kill(process$1.pid, signalName);
    } else if (code !== null) {
      process$1.exit(code);
    }
  });
  await spawnPromise;
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$g,
  NPM
} = constants;
const config$g = {
  commandName: 'raw-npm',
  description: `Temporarily disable the Socket ${NPM} wrapper`,
  hidden: false,
  flags: {},
  help: command => `
    Usage
      $ ${command} <command>

    Examples
      $ ${command} install
  `
};
const cmdRawNpm = {
  description: config$g.description,
  hidden: config$g.hidden,
  run: run$g
};
async function run$g(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$g,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$g);
    return;
  }
  await runRawNpm(argv);
}

async function runRawNpx(argv) {
  const spawnPromise = spawn.spawn(shadowNpmPaths.getNpxBinPath(), argv, {
    stdio: 'inherit'
  });
  // See https://nodejs.org/api/all.html#all_child_process_event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process$1.kill(process$1.pid, signalName);
    } else if (code !== null) {
      process$1.exit(code);
    }
  });
  await spawnPromise;
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$f,
  NPX
} = constants;
const config$f = {
  commandName: 'raw-npx',
  description: `Temporarily disable the Socket ${NPX} wrapper`,
  hidden: false,
  flags: {},
  help: command => `
    Usage
      $ ${command} <command>

    Examples
      $ ${command} install
  `
};
const cmdRawNpx = {
  description: config$f.description,
  hidden: config$f.hidden,
  run: run$f
};
async function run$f(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$f,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$f);
    return;
  }
  await runRawNpx(argv);
}

const {
  DRY_RUN_LABEL
} = constants;
async function createReport(socketConfig, inputPaths, {
  cwd,
  dryRun
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const socketSdk = await shadowNpmInject.setupSdk();
  const supportedFiles = await socketSdk.getReportSupportedFiles().then(res => {
    if (!res.success) handleUnsuccessfulApiResponse('getReportSupportedFiles', res);
    return res.data;
  }).catch(cause => {
    throw new Error('Failed getting supported files for report', {
      cause
    });
  });
  const packagePaths = await shadowNpmPaths.getPackageFilesFullScans(cwd, inputPaths, supportedFiles, socketConfig);
  const packagePathsCount = packagePaths.length;
  if (packagePathsCount && debug.isDebug()) {
    for (const pkgPath of packagePaths) {
      debug.debugLog(`Uploading: ${pkgPath}`);
    }
  }
  if (dryRun) {
    debug.debugLog(`${DRY_RUN_LABEL}: Skipped actual upload`);
    return undefined;
  }
  spinner.start(`Creating report with ${packagePathsCount} package ${words.pluralize('file', packagePathsCount)}`);
  const apiCall = socketSdk.createReportFromFilePaths(packagePaths, cwd, socketConfig?.issueRules);
  const result = await handleApiCall(apiCall, 'creating report');
  if (!result.success) {
    handleUnsuccessfulApiResponse('createReport', result);
    return undefined;
  }
  spinner.successAndStop();
  return result;
}

async function getSocketConfig(absoluteConfigPath) {
  const socketConfig = await config$D.readSocketConfig(absoluteConfigPath).catch(cause => {
    if (cause && typeof cause === 'object' && cause instanceof config$D.SocketValidationError) {
      // Inspired by workbox-build:
      // https://github.com/GoogleChrome/workbox/blob/95f97a207fd51efb3f8a653f6e3e58224183a778/packages/workbox-build/src/lib/validate-options.ts#L68-L71
      const betterErrors = betterAjvErrors.betterAjvErrors({
        basePath: 'config',
        data: cause.data,
        errors: cause.validationErrors,
        schema: cause.schema
      });
      throw new shadowNpmInject.InputError('The socket.yml config is not valid', betterErrors.map(err => `[${err.path}] ${err.message}.${err.suggestion ? err.suggestion : ''}`).join('\n'));
    } else {
      throw new Error('Failed to read socket.yml config', {
        cause
      });
    }
  });
  return socketConfig;
}

const MAX_TIMEOUT_RETRY = 5;
const HTTP_CODE_TIMEOUT = 524;
async function fetchReportData$1(reportId, includeAllIssues, strict) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.log('Fetching report with ID ${reportId} (this could take a while)');
  spinner.start(`Fetch started... (this could take a while)`);
  const socketSdk = await shadowNpmInject.setupSdk();
  let result;
  for (let retry = 1; !result; ++retry) {
    try {
      // eslint-disable-next-line no-await-in-loop
      result = await handleApiCall(socketSdk.getReport(reportId), 'fetching report');
    } catch (err) {
      if (retry >= MAX_TIMEOUT_RETRY || !(err instanceof Error) || err.cause?.cause?.response?.statusCode !== HTTP_CODE_TIMEOUT) {
        spinner.stop(`Failed to fetch report`);
        throw err;
      }
      spinner?.fail(`Retrying report fetch ${retry} / ${MAX_TIMEOUT_RETRY}`);
    }
  }
  if (!result.success) {
    return handleUnsuccessfulApiResponse('getReport', result);
  }

  // Conclude the status of the API call.
  if (strict) {
    if (result.data.healthy) {
      spinner.success('Report result is healthy and great!');
    } else {
      spinner.error('Report result deemed unhealthy for project');
    }
  } else if (!result.data.healthy) {
    const severityCount = shadowNpmInject.getSeverityCount(result.data.issues, includeAllIssues ? undefined : 'high');
    const issueSummary = shadowNpmInject.formatSeverityCount(severityCount);
    spinner.success(`Report has these issues: ${issueSummary}`);
  } else {
    spinner.success('Report has no issues');
  }
  spinner.stop();
  return result.data;
}

function formatReportDataOutput(reportId, data, commandName, outputKind, strict, artifacts) {
  if (outputKind === 'json') {
    logger.logger.log(JSON.stringify(data, undefined, 2));
  } else {
    const format = new shadowNpmInject.ColorOrMarkdown(outputKind === 'markdown');
    logger.logger.log(commonTags.stripIndents`
      Detailed info on socket.dev: ${format.hyperlink(reportId, data.url, {
      fallbackToUrl: true
    })}`);
    if (outputKind === 'print') {
      logger.logger.log(data);
      logger.logger.log(colors.dim(`Or rerun ${colors.italic(commandName)} using the ${colors.italic('--json')} flag to get full JSON output`));
      logger.logger.log('The scan:');
      logger.logger.log(artifacts);
    }
  }
  if (strict && !data.healthy) {
    process$1.exit(1);
  }
}

async function getFullScan(orgSlug, fullScanId) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  spinner.start('Fetching full-scan...');
  const response = await queryAPI(`orgs/${orgSlug}/full-scans/${encodeURIComponent(fullScanId)}`, apiToken);
  spinner.stop('Fetch complete.');
  if (!response.ok) {
    const err = await handleAPIError(response.status);
    logger.logger.fail(`${colors.bgRed(colors.white(response.statusText))}: Fetch error: ${err}`);
    return;
  }

  // This is nd-json; each line is a json object
  const jsons = await response.text();
  const lines = jsons.split('\n').filter(Boolean);
  const data = lines.map(line => {
    try {
      return JSON.parse(line);
    } catch {
      console.error('At least one line item was returned that could not be parsed as JSON...');
      return {};
    }
  });
  return data;
}

async function viewReport(reportId, {
  all,
  commandName,
  outputKind,
  strict
}) {
  const result = await fetchReportData$1(reportId, all, strict);
  const artifacts = await getFullScan('socketdev', reportId);
  if (result) {
    formatReportDataOutput(reportId, result, commandName, outputKind, strict, artifacts);
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$e
} = constants;
const config$e = {
  commandName: 'create',
  description: '[Deprecated] Create a project report',
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags,
    ...validationFlags,
    dryRun: {
      type: 'boolean',
      default: false,
      description: 'Only output what will be done without actually doing it'
    },
    view: {
      type: 'boolean',
      shortFlag: 'v',
      default: false,
      description: 'Will wait for and return the created report'
    }
  },
  help: () => `
    This command is deprecated in favor of \`socket scan view\`.
    It will be removed in the next major release of the CLI.
  `
};
const cmdReportCreate = {
  description: config$e.description,
  hidden: config$e.hidden,
  run: run$e
};
async function run$e(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$e,
    importMeta,
    parentName
  });

  // TODO: Allow setting a custom cwd and/or configFile path?
  const cwd = process$1.cwd();
  const absoluteConfigPath = path$1.join(cwd, 'socket.yml');
  const dryRun = Boolean(cli.flags['dryRun']);
  const json = Boolean(cli.flags['json']);
  const markdown = Boolean(cli.flags['markdown']);
  const strict = Boolean(cli.flags['strict']);
  const includeAllIssues = Boolean(cli.flags['all']);
  const view = Boolean(cli.flags['view']);

  // Note exiting earlier to skirt a hidden auth requirement
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$e);
    return;
  }
  const socketConfig = await getSocketConfig(absoluteConfigPath);
  const result = await createReport(socketConfig, cli.input, {
    cwd,
    dryRun
  });
  const commandName = `${parentName} ${config$e.commandName}`;
  if (result?.success) {
    if (view) {
      const reportId = result.data.id;
      await viewReport(reportId, {
        all: includeAllIssues,
        commandName,
        outputKind: json ? 'json' : markdown ? 'markdown' : 'print',
        strict
      });
    } else if (json) {
      logger.logger.log(JSON.stringify(result.data, undefined, 2));
    } else {
      const format = new shadowNpmInject.ColorOrMarkdown(markdown);
      logger.logger.log(`New report: ${format.hyperlink(result.data.id, result.data.url, {
        fallbackToUrl: true
      })}`);
    }
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$d
} = constants;
const config$d = {
  commandName: 'view',
  description: '[Deprecated] View a project report',
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags,
    ...validationFlags
  },
  help: () => `
    This command is deprecated in favor of \`socket scan view\`.
    It will be removed in the next major release of the CLI.
  `
};
const cmdReportView = {
  description: config$d.description,
  hidden: config$d.hidden,
  run: run$d
};
async function run$d(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$d,
    importMeta,
    parentName
  });
  const [reportId, ...extraInput] = cli.input;

  // Validate the input.
  if (extraInput.length || !reportId) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Need at least one report ID ${!reportId ? colors.red('(missing!)') : colors.green('(ok)')}

      - Can only handle a single report ID ${extraInput.length < 2 ? colors.red(`(received ${extraInput.length}!)`) : colors.green('(ok)')}`);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$d);
    return;
  }
  await viewReport(reportId, {
    all: Boolean(cli.flags['all']),
    commandName: `${parentName} ${config$d.commandName}`,
    outputKind: cli.flags['json'] ? 'json' : cli.flags['markdown'] ? 'markdown' : 'print',
    strict: Boolean(cli.flags['strict'])
  });
}

const description$2 = '[Deprecated] Project report related commands';
const cmdReport = {
  description: description$2,
  hidden: true,
  // Deprecated in favor of `scan`
  async run(argv, importMeta, {
    parentName
  }) {
    await meowWithSubcommands({
      create: cmdReportCreate,
      view: cmdReportView
    }, {
      argv,
      description: description$2,
      importMeta,
      name: parentName + ' report'
    });
  }
};

async function fetchCreateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchCreateRepoWithToken(apiToken, {
    default_branch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  });
}
async function fetchCreateRepoWithToken(apiToken, {
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  spinner.start('Sending request ot create a repository...');
  const result = await handleApiCall(socketSdk.createOrgRepo(orgSlug, {
    name: repoName,
    description,
    homepage,
    default_branch,
    visibility
  }), 'creating repository');
  spinner.successAndStop('Received response requesting to create a repository.');
  if (!result.success) {
    handleUnsuccessfulApiResponse('createOrgRepo', result);
    return;
  }
  return result.data;
}

async function outputCreateRepo(_data) {
  logger.logger.success('Repository created successfully');
}

async function handleCreateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  const data = await fetchCreateRepo({
    default_branch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  });
  if (!data) return;
  await outputCreateRepo();
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$c
} = constants;
const config$c = {
  commandName: 'create',
  description: 'Create a repository in an organization',
  hidden: false,
  flags: {
    ...commonFlags,
    repoName: {
      type: 'string',
      shortFlag: 'n',
      default: '',
      description: 'Repository name'
    },
    repoDescription: {
      type: 'string',
      shortFlag: 'd',
      default: '',
      description: 'Repository description'
    },
    homepage: {
      type: 'string',
      shortFlag: 'h',
      default: '',
      description: 'Repository url'
    },
    defaultBranch: {
      type: 'string',
      shortFlag: 'b',
      default: 'main',
      description: 'Repository default branch'
    },
    visibility: {
      type: 'string',
      shortFlag: 'v',
      default: 'private',
      description: 'Repository visibility (Default Private)'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg --repoName=test-repo
  `
};
const cmdReposCreate = {
  description: config$c.description,
  hidden: config$c.hidden,
  run: run$c
};
async function run$c(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$c,
    importMeta,
    parentName
  });
  const repoName = cli.flags['repoName'];
  const [orgSlug = ''] = cli.input;
  if (!repoName || typeof repoName !== 'string' || !orgSlug) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Repository name using --repoName ${!repoName ? colors.red('(missing!)') : typeof repoName !== 'string' ? colors.red('(invalid!)') : colors.green('(ok)')}`);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$c);
    return;
  }
  await handleCreateRepo({
    orgSlug,
    repoName,
    description: String(cli.flags['repoDescription'] || ''),
    homepage: String(cli.flags['homepage'] || ''),
    default_branch: String(cli.flags['defaultBranch'] || ''),
    visibility: String(cli.flags['visibility'] || 'private')
  });
}

async function handleDeleteRepo(orgSlug, repoName) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  await deleteRepoWithToken(orgSlug, repoName, apiToken);
}
async function deleteRepoWithToken(orgSlug, repoName, apiToken) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Deleting repository...');
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const result = await handleApiCall(socketSdk.deleteOrgRepo(orgSlug, repoName), 'deleting repository');
  if (!result.success) {
    handleUnsuccessfulApiResponse('deleteOrgRepo', result);
    return;
  }
  spinner.successAndStop('Repository deleted successfully');
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$b
} = constants;
const config$b = {
  commandName: 'del',
  description: 'Delete a repository in an organization',
  hidden: false,
  flags: {
    ...commonFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug> <repo slug>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg test-repo
  `
};
const cmdReposDel = {
  description: config$b.description,
  hidden: config$b.hidden,
  run: run$b
};
async function run$b(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$b,
    importMeta,
    parentName
  });
  const [orgSlug = '', repoName = ''] = cli.input;
  if (!orgSlug || !repoName) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Repository name as the second argument ${!repoName ? colors.red('(missing!)') : typeof repoName !== 'string' ? colors.red('(invalid!)') : colors.green('(ok)')}

      - At least one TARGET (e.g. \`.\` or \`./package.json\``);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$b);
    return;
  }
  await handleDeleteRepo(orgSlug, repoName);
}

async function fetchListRepos({
  direction,
  orgSlug,
  page,
  per_page,
  sort
}) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchListReposWithToken(apiToken, {
    direction,
    orgSlug,
    page,
    per_page,
    sort
  });
}
async function fetchListReposWithToken(apiToken, {
  direction,
  orgSlug,
  page,
  per_page,
  sort
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  spinner.start('Fetching list of repositories...');
  const result = await handleApiCall(socketSdk.getOrgRepoList(orgSlug, {
    sort,
    direction,
    per_page: String(per_page),
    page: String(page)
  }), 'listing repositories');
  spinner.successAndStop('Received response for repository list.');
  if (!result.success) {
    handleUnsuccessfulApiResponse('getOrgRepoList', result);
    return;
  }
  return result.data;
}

// @ts-ignore
async function outputListRepos(data, outputKind) {
  if (outputKind === 'json') {
    const json = data.results.map(o => ({
      id: o.id,
      name: o.name,
      visibility: o.visibility,
      defaultBranch: o.default_branch,
      archived: o.archived
    }));
    logger.logger.log(JSON.stringify(json, null, 2));
    return;
  }
  const options = {
    columns: [{
      field: 'id',
      name: colors.magenta('ID')
    }, {
      field: 'name',
      name: colors.magenta('Name')
    }, {
      field: 'visibility',
      name: colors.magenta('Visibility')
    }, {
      field: 'default_branch',
      name: colors.magenta('Default branch')
    }, {
      field: 'archived',
      name: colors.magenta('Archived')
    }]
  };
  logger.logger.log(chalkTable(options, data.results));
}

async function handleListRepos({
  direction,
  orgSlug,
  outputKind,
  page,
  per_page,
  sort
}) {
  const data = await fetchListRepos({
    direction,
    orgSlug,
    page,
    per_page,
    sort
  });
  if (!data) return;
  await outputListRepos(data, outputKind);
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$a
} = constants;
const config$a = {
  commandName: 'list',
  description: 'List repositories in an organization',
  hidden: false,
  flags: {
    ...commonFlags,
    sort: {
      type: 'string',
      shortFlag: 's',
      default: 'created_at',
      description: 'Sorting option'
    },
    direction: {
      type: 'string',
      default: 'desc',
      description: 'Direction option'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Number of results per page'
    },
    page: {
      type: 'number',
      shortFlag: 'p',
      default: 1,
      description: 'Page number'
    },
    ...outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg
  `
};
const cmdReposList = {
  description: config$a.description,
  hidden: config$a.hidden,
  run: run$a
};
async function run$a(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$a,
    importMeta,
    parentName
  });
  const [orgSlug = ''] = cli.input;
  if (!orgSlug) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - At least one TARGET (e.g. \`.\` or \`./package.json\``);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$a);
    return;
  }
  await handleListRepos({
    direction: cli.flags['direction'] === 'asc' ? 'asc' : 'desc',
    orgSlug,
    outputKind: cli.flags['json'] ? 'json' : cli.flags['markdown'] ? 'markdown' : 'print',
    page: Number(cli.flags['page']) || 1,
    per_page: Number(cli.flags['perPage']) || 30,
    sort: String(cli.flags['sort'] || 'created_at')
  });
}

async function fetchUpdateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchUpdateRepoWithToken(apiToken, {
    default_branch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  });
}
async function fetchUpdateRepoWithToken(apiToken, {
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Sending request to update a repository...');
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const result = await handleApiCall(socketSdk.updateOrgRepo(orgSlug, repoName, {
    orgSlug,
    name: repoName,
    description,
    homepage,
    default_branch,
    visibility
  }), 'updating repository');
  spinner.successAndStop('Received response trying to update a repository');
  if (!result.success) {
    handleUnsuccessfulApiResponse('updateOrgRepo', result);
    return;
  }
  return result.data;
}

async function outputUpdateRepo(_data) {
  logger.logger.success('Repository updated successfully');
}

async function handleUpdateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  const data = await fetchUpdateRepo({
    default_branch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  });
  if (!data) return;
  await outputUpdateRepo();
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$9
} = constants;
const config$9 = {
  commandName: 'update',
  description: 'Update a repository in an organization',
  hidden: false,
  flags: {
    ...commonFlags,
    repoName: {
      type: 'string',
      shortFlag: 'n',
      default: '',
      description: 'Repository name'
    },
    repoDescription: {
      type: 'string',
      shortFlag: 'd',
      default: '',
      description: 'Repository description'
    },
    homepage: {
      type: 'string',
      shortFlag: 'h',
      default: '',
      description: 'Repository url'
    },
    defaultBranch: {
      type: 'string',
      shortFlag: 'b',
      default: 'main',
      description: 'Repository default branch'
    },
    visibility: {
      type: 'string',
      shortFlag: 'v',
      default: 'private',
      description: 'Repository visibility (Default Private)'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg
  `
};
const cmdReposUpdate = {
  description: config$9.description,
  hidden: config$9.hidden,
  run: run$9
};
async function run$9(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$9,
    importMeta,
    parentName
  });
  const repoName = cli.flags['repoName'];
  const [orgSlug = ''] = cli.input;
  if (!repoName || typeof repoName !== 'string' || !orgSlug) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Repository name using --repoName ${!repoName ? colors.red('(missing!)') : typeof repoName !== 'string' ? colors.red('(invalid!)') : colors.green('(ok)')}

      - At least one TARGET (e.g. \`.\` or \`./package.json\``);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$9);
    return;
  }
  await handleUpdateRepo({
    orgSlug,
    repoName,
    description: String(cli.flags['repoDescription'] || ''),
    homepage: String(cli.flags['homepage'] || ''),
    default_branch: String(cli.flags['defaultBranch'] || ''),
    visibility: String(cli.flags['visibility'] || 'private')
  });
}

async function fetchViewRepo(orgSlug, repoName) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  return await fetchViewRepoWithToken(orgSlug, repoName, apiToken);
}
async function fetchViewRepoWithToken(orgSlug, repoName, apiToken) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  spinner.start('Fetching repository data...');
  const result = await handleApiCall(socketSdk.getOrgRepo(orgSlug, repoName), 'fetching repository');
  spinner.successAndStop('Received response while fetched repository data.');
  if (!result.success) {
    handleUnsuccessfulApiResponse('getOrgRepo', result);
    return;
  }
  return result.data;
}

// @ts-ignore
async function outputViewRepo(data, outputKind) {
  if (outputKind === 'json') {
    const {
      archived,
      created_at,
      default_branch,
      homepage,
      id,
      name,
      visibility
    } = data;
    logger.logger.log(JSON.stringify({
      id,
      name,
      visibility,
      default_branch,
      homepage,
      archived,
      created_at
    }, null, 2));
    return;
  }
  const options = {
    columns: [{
      field: 'id',
      name: colors.magenta('ID')
    }, {
      field: 'name',
      name: colors.magenta('Name')
    }, {
      field: 'visibility',
      name: colors.magenta('Visibility')
    }, {
      field: 'default_branch',
      name: colors.magenta('Default branch')
    }, {
      field: 'homepage',
      name: colors.magenta('Homepage')
    }, {
      field: 'archived',
      name: colors.magenta('Archived')
    }, {
      field: 'created_at',
      name: colors.magenta('Created at')
    }]
  };
  logger.logger.log(chalkTable(options, [data]));
}

async function handleViewRepo(orgSlug, repoName, outputKind) {
  const data = await fetchViewRepo(orgSlug, repoName);
  if (!data) return;
  await outputViewRepo(data, outputKind);
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$8
} = constants;
const config$8 = {
  commandName: 'view',
  description: 'View repositories in an organization',
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags,
    repoName: {
      description: 'The repository to check',
      default: '',
      type: 'string'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg
  `
};
const cmdReposView = {
  description: config$8.description,
  hidden: config$8.hidden,
  run: run$8
};
async function run$8(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$8,
    importMeta,
    parentName
  });
  const {
    json,
    markdown,
    repoName
  } = cli.flags;
  const [orgSlug = ''] = cli.input;
  if (!repoName || typeof repoName !== 'string' || !orgSlug) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
      ${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Repository name using --repoName ${!repoName ? colors.red('(missing!)') : typeof repoName !== 'string' ? colors.red('(invalid!)') : colors.green('(ok)')}
    `);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$8);
    return;
  }
  await handleViewRepo(orgSlug, repoName, json ? 'json' : markdown ? 'markdown' : 'text');
}

const description$1 = 'Repositories related commands';
const cmdRepos = {
  description: description$1,
  async run(argv, importMeta, {
    parentName
  }) {
    await meowWithSubcommands({
      create: cmdReposCreate,
      view: cmdReposView,
      list: cmdReposList,
      del: cmdReposDel,
      update: cmdReposUpdate
    }, {
      argv,
      description: description$1,
      importMeta,
      name: `${parentName} repos`
    });
  }
};

async function suggestOrgSlug(socketSdk) {
  const result = await handleApiCall(socketSdk.getOrganizations(), 'looking up organizations');
  // Ignore a failed request here. It was not the primary goal of
  // running this command and reporting it only leads to end-user confusion.
  if (result.success) {
    const proceed = await prompts.select({
      message: 'Missing org name; do you want to use any of these orgs for this scan?',
      choices: Array.from(Object.values(result.data.organizations)).map(({
        name: slug
      }) => ({
        name: 'Yes [' + slug + ']',
        value: slug,
        description: `Use "${slug}" as the organization`
      })).concat({
        name: 'No',
        value: '',
        description: 'Do not use any of these organizations (will end in a no-op)'
      })
    });
    if (proceed) {
      return proceed;
    }
  }
}

async function suggestRepoSlug(socketSdk, orgSlug) {
  // Same as above, but if there's a repo with the same name as cwd then
  // default the selection to that name.
  const result = await handleApiCall(socketSdk.getOrgRepoList(orgSlug, {
    orgSlug,
    sort: 'name',
    direction: 'asc',
    // There's no guarantee that the cwd is part of this page. If it's not
    // then do an additional request and specific search for it instead.
    // This way we can offer the tip of "do you want to create [cwd]?".
    perPage: '10',
    page: '0'
  }), 'looking up known repos');
  // Ignore a failed request here. It was not the primary goal of
  // running this command and reporting it only leads to end-user confusion.
  if (result.success) {
    const currentDirName = dirNameToSlug(path$1.basename(process$1.cwd()));
    let cwdIsKnown = !!currentDirName && result.data.results.some(obj => obj.slug === currentDirName);
    if (!cwdIsKnown && currentDirName) {
      // Do an explicit request so we can assert that the cwd exists or not
      const result = await handleApiCall(socketSdk.getOrgRepo(orgSlug, currentDirName), 'checking if current cwd is a known repo');
      if (result.success) {
        cwdIsKnown = true;
      }
    }
    const proceed = await prompts.select({
      message: 'Missing repo name; do you want to use any of these known repo names for this scan?',
      choices:
      // Put the CWD suggestion at the top, whether it exists or not
      (currentDirName ? [{
        name: `Yes, current dir [${cwdIsKnown ? currentDirName : `create repo for ${currentDirName}`}]`,
        value: currentDirName,
        description: cwdIsKnown ? 'Register a new repo name under the given org and use it' : 'Use current dir as repo'
      }] : []).concat(result.data.results.filter(({
        slug
      }) => !!slug && slug !== currentDirName).map(({
        slug
      }) => ({
        name: 'Yes [' + slug + ']',
        value: slug || '',
        // Filtered above but TS is like nah.
        description: `Use "${slug}" as the repo name`
      })), {
        name: 'No',
        value: '',
        description: 'Do not use any of these repos (will end in a no-op)'
      })
    });
    if (proceed) {
      const repoName = proceed;
      let repoDefaultBranch = '';
      // Store the default branch to help with the branch name question next
      result.data.results.some(obj => {
        if (obj.slug === proceed && obj.default_branch) {
          repoDefaultBranch = obj.default_branch;
          return;
        }
      });
      return {
        slug: repoName,
        defaultBranch: repoDefaultBranch
      };
    }
  }
}
function dirNameToSlug(name) {
  // Uses slug specs asserted by our servers
  // Note: this can lead to collisions; eg. slug for `x--y` and `x---y` is `x-y`
  return name.toLowerCase().replace(/[^[a-zA-Z0-9_.-]/g, '_').replace(/--+/g, '-').replace(/__+/g, '_').replace(/\.\.+/g, '.').replace(/[._-]+$/, '');
}

async function suggestBranchSlug(repoDefaultBranch) {
  const spawnResult = spawn.spawnSync('git', ['branch', '--show-current']);
  const currentBranch = spawnResult.stdout.toString('utf8').trim();
  if (currentBranch && spawnResult.status === 0) {
    const proceed = await prompts.select({
      message: 'Use the current git branch as target branch name?',
      choices: [{
        name: `Yes [${currentBranch}]`,
        value: currentBranch,
        description: 'Use the current git branch for branch name'
      }, ...(repoDefaultBranch && repoDefaultBranch !== currentBranch ? [{
        name: `No, use the default branch [${repoDefaultBranch}]`,
        value: repoDefaultBranch,
        description: 'Use the default branch for target repo as the target branch name'
      }] : []), {
        name: 'No',
        value: '',
        description: 'Do not use the current git branch as name (will end in a no-op)'
      }].filter(Boolean)
    });
    if (proceed) {
      return proceed;
    }
  }
}

async function suggestTarget() {
  // We could prefill this with sub-dirs of the current
  // dir ... but is that going to be useful?
  const proceed = await prompts.select({
    message: 'No TARGET given. Do you want to use the current directory?',
    choices: [{
      name: 'Yes',
      value: true,
      description: 'Target the current directory'
    }, {
      name: 'No',
      value: false,
      description: 'Do not use the current directory (this will end in a no-op)'
    }]
  });
  if (proceed) {
    return ['.'];
  }
}

async function createFullScan({
  branchName,
  commitHash: _commitHash,
  commitMessage,
  committers: _committers,
  cwd,
  defaultBranch,
  orgSlug,
  pendingHead,
  pullRequest: _pullRequest,
  readOnly,
  repoName,
  targets,
  tmp
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const socketSdk = await shadowNpmInject.setupSdk();
  const supportedFiles = await socketSdk.getReportSupportedFiles().then(res => {
    if (!res.success) {
      handleUnsuccessfulApiResponse('getReportSupportedFiles', res);
      assert(false, 'handleUnsuccessfulApiResponse should unconditionally throw');
    }
    return res.data;
  }).catch(cause => {
    throw new Error('Failed getting supported files for report', {
      cause
    });
  });

  // If we updated any inputs then we should print the command line to repeat
  // the command without requiring user input, as a suggestion.
  let updatedInput = false;
  if (!targets.length) {
    const received = await suggestTarget();
    targets = received ?? [];
    updatedInput = true;
  }

  // // TODO: we'll probably use socket.json or something else soon...
  // const absoluteConfigPath = path.join(cwd, 'socket.yml')
  // const socketConfig = await getSocketConfig(absoluteConfigPath)

  const packagePaths = await shadowNpmPaths.getPackageFilesFullScans(cwd, targets, supportedFiles
  // socketConfig
  );

  // We're going to need an api token to suggest data because those suggestions
  // must come from data we already know. Don't error on missing api token yet.
  // If the api-token is not set, ignore it for the sake of suggestions.
  const apiToken = shadowNpmInject.getDefaultToken();

  // If the current cwd is unknown and is used as a repo slug anyways, we will
  // first need to register the slug before we can use it.
  let repoDefaultBranch = '';
  if (apiToken) {
    if (!orgSlug) {
      const suggestion = await suggestOrgSlug(socketSdk);
      if (suggestion) orgSlug = suggestion;
      updatedInput = true;
    }

    // (Don't bother asking for the rest if we didn't get an org slug above)
    if (orgSlug && !repoName) {
      const suggestion = await suggestRepoSlug(socketSdk, orgSlug);
      if (suggestion) {
        repoDefaultBranch = suggestion.defaultBranch;
        repoName = suggestion.slug;
      }
      updatedInput = true;
    }

    // (Don't bother asking for the rest if we didn't get an org/repo above)
    if (orgSlug && repoName && !branchName) {
      const suggestion = await suggestBranchSlug(repoDefaultBranch);
      if (suggestion) branchName = suggestion;
      updatedInput = true;
    }
  }
  if (!orgSlug || !repoName || !branchName || !packagePaths.length) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process$1.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
      ${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Repository name using --repo ${!repoName ? colors.red('(missing!)') : colors.green('(ok)')}

      - Branch name using --branch ${!branchName ? colors.red('(missing!)') : colors.green('(ok)')}

      - At least one TARGET (e.g. \`.\` or \`./package.json\`) ${!packagePaths.length ? colors.red(targets.length > 0 ? '(TARGET' + (targets.length ? 's' : '') + ' contained no matching/supported files!)' : '(missing)') : colors.green('(ok)')}

      ${!apiToken ? 'Note: was unable to make suggestions because no API Token was found; this would make command fail regardless' : ''}
      `);
    return;
  }
  if (updatedInput) {
    logger.logger.log('Note: You can invoke this command next time to skip the interactive questions:');
    logger.logger.log('```');
    logger.logger.log(`    socket scan create [other flags...] --repo ${repoName} --branch ${branchName} ${orgSlug} ${targets.join(' ')}`);
    logger.logger.log('```');
  }
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  if (readOnly) {
    logger.logger.log('[ReadOnly] Bailing now');
    return;
  }
  spinner.start(`Creating a scan with ${packagePaths.length} packages...`);
  const result = await handleApiCall(socketSdk.createOrgFullScan(orgSlug, {
    repo: repoName,
    branch: branchName,
    commit_message: commitMessage,
    make_default_branch: String(defaultBranch),
    set_as_pending_head: String(pendingHead),
    tmp: String(tmp)
  }, packagePaths, cwd), 'Creating scan');
  if (!result.success) {
    handleUnsuccessfulApiResponse('CreateOrgFullScan', result);
    return;
  }
  spinner.successAndStop('Scan created successfully');
  const link = colors.underline(colors.cyan(`${result.data.html_report_url}`));
  logger.logger.log(`Available at: ${link}`);
  const rl = readline.createInterface({
    input: process$1.stdin,
    output: process$1.stdout
  });
  const answer = await rl.question('Would you like to open it in your browser? (y/n)');
  if (answer.toLowerCase() === 'y') {
    await open(`${result.data.html_report_url}`);
  }
  rl.close();
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$7
} = constants;
const config$7 = {
  commandName: 'create',
  description: 'Create a scan',
  hidden: false,
  flags: {
    repo: {
      type: 'string',
      shortFlag: 'r',
      default: '',
      description: 'Repository name'
    },
    branch: {
      type: 'string',
      shortFlag: 'b',
      default: '',
      description: 'Branch name'
    },
    commitMessage: {
      type: 'string',
      shortFlag: 'm',
      default: '',
      description: 'Commit message'
    },
    commitHash: {
      type: 'string',
      shortFlag: 'ch',
      default: '',
      description: 'Commit hash'
    },
    cwd: {
      type: 'string',
      description: 'working directory, defaults to process.cwd()'
    },
    dryRun: {
      type: 'boolean',
      description: 'run input validation part of command without any concrete side effects'
    },
    pullRequest: {
      type: 'number',
      shortFlag: 'pr',
      description: 'Commit hash'
    },
    committers: {
      type: 'string',
      shortFlag: 'c',
      default: '',
      description: 'Committers'
    },
    defaultBranch: {
      type: 'boolean',
      shortFlag: 'db',
      default: false,
      description: 'Make default branch'
    },
    pendingHead: {
      type: 'boolean',
      shortFlag: 'ph',
      default: false,
      description: 'Set as pending head'
    },
    readOnly: {
      type: 'boolean',
      default: false,
      description: 'Similar to --dry-run except it can read from remote, stops before it would create an actual report'
    },
    tmp: {
      type: 'boolean',
      shortFlag: 't',
      default: false,
      description: 'Set the visibility (true/false) of the scan in your dashboard'
    },
    view: {
      type: 'boolean',
      shortFlag: 'v',
      default: true,
      description: 'Will wait for and return the created report. Use --no-view to disable.'
    }
  },
  // TODO: your project's "socket.yml" file's "projectIgnorePaths"
  help: (command, config) => `
    Usage
      $ ${command} [...options] <org> <TARGET> [TARGET...]

    Uploads the specified "package.json" and lock files for JavaScript, Python,
    Go, Scala, Gradle, and Kotlin dependency manifests.
    If any folder is specified, the ones found in there recursively are uploaded.

    Supports globbing such as "**/package.json", "**/requirements.txt", etc.

    Ignores any file specified in your project's ".gitignore" and also has a
    sensible set of default ignores from the "ignore-by-default" module.

    TARGET should be a FILE or DIR that _must_ be inside the CWD.

    When a FILE is given only that FILE is targeted. Otherwise any eligible
    files in the given DIR will be considered.

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} --repo=test-repo --branch=main FakeOrg ./package.json
  `
};
const cmdScanCreate = {
  description: config$7.description,
  hidden: config$7.hidden,
  run: run$7
};
async function run$7(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$7,
    importMeta,
    parentName
  });
  const [orgSlug = '', ...targets] = cli.input;
  const cwd = cli.flags['cwd'] && cli.flags['cwd'] !== 'process.cwd()' ? String(cli.flags['cwd']) : process$1.cwd();
  const {
    branch: branchName,
    repo: repoName
  } = cli.flags;
  const apiToken = shadowNpmInject.getDefaultToken(); // This checks if we _can_ suggest anything

  if (!apiToken && (!orgSlug || !repoName || !branchName || !targets.length)) {
    // Without api token we cannot recover because we can't request more info
    // from the server, to match and help with the current cwd/git status.
    //
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process$1.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
      ${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Repository name using --repo ${!repoName ? colors.red('(missing!)') : colors.green('(ok)')}

      - Branch name using --branch ${!branchName ? colors.red('(missing!)') : colors.green('(ok)')}

      - At least one TARGET (e.g. \`.\` or \`./package.json\`) ${!targets.length ? '(missing)' : colors.green('(ok)')}

      (Additionally, no API Token was set so we cannot auto-discover these details)
    `);
    return;
  }

  // Note exiting earlier to skirt a hidden auth requirement
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$7);
    return;
  }
  await createFullScan({
    branchName: branchName,
    commitHash: cli.flags['commitHash'] ?? '',
    commitMessage: cli.flags['commitMessage'] ?? '',
    committers: cli.flags['committers'] ?? '',
    cwd,
    defaultBranch: Boolean(cli.flags['defaultBranch']),
    orgSlug,
    pendingHead: Boolean(cli.flags['pendingHead']),
    pullRequest: cli.flags['pullRequest'] ?? undefined,
    readOnly: Boolean(cli.flags['readOnly']),
    repoName: repoName,
    targets,
    tmp: Boolean(cli.flags['tmp'])
  });
}

async function deleteOrgFullScan(orgSlug, fullScanId) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  await deleteOrgFullScanWithToken(orgSlug, fullScanId, apiToken);
}
async function deleteOrgFullScanWithToken(orgSlug, fullScanId, apiToken) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Deleting scan...');
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const result = await handleApiCall(socketSdk.deleteOrgFullScan(orgSlug, fullScanId), 'Deleting scan');
  if (!result.success) {
    handleUnsuccessfulApiResponse('deleteOrgFullScan', result);
    return;
  }
  spinner.successAndStop('Scan deleted successfully');
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$6
} = constants;
const config$6 = {
  commandName: 'del',
  description: 'Delete a scan',
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug> <scan ID>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg 000aaaa1-0000-0a0a-00a0-00a0000000a0
  `
};
const cmdScanDel = {
  description: config$6.description,
  hidden: config$6.hidden,
  run: run$6
};
async function run$6(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$6,
    importMeta,
    parentName
  });
  const [orgSlug = '', fullScanId = ''] = cli.input;
  if (!orgSlug || !fullScanId) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Full Scan ID to delete as second argument ${!fullScanId ? colors.red('(missing!)') : colors.green('(ok)')}`);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$6);
    return;
  }
  await deleteOrgFullScan(orgSlug, fullScanId);
}

// @ts-ignore
async function listFullScans({
  direction,
  from_time,
  orgSlug,
  outputKind,
  page,
  per_page,
  sort
}) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  await listFullScansWithToken({
    apiToken,
    direction,
    from_time,
    orgSlug,
    outputKind,
    page,
    per_page,
    sort
  });
}
async function listFullScansWithToken({
  apiToken,
  direction,
  from_time,
  orgSlug,
  outputKind,
  page,
  per_page,
  sort
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Fetching list of scans...');
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const result = await handleApiCall(socketSdk.getOrgFullScanList(orgSlug, {
    sort,
    direction,
    per_page: String(per_page),
    page: String(page),
    from: from_time
  }), 'Listing scans');
  if (!result.success) {
    handleUnsuccessfulApiResponse('getOrgFullScanList', result);
    return;
  }
  spinner.stop(`Fetch complete`);
  if (outputKind === 'json') {
    logger.logger.log(result.data);
    return;
  }
  const options = {
    columns: [{
      field: 'id',
      name: colors.magenta('ID')
    }, {
      field: 'report_url',
      name: colors.magenta('Scan URL')
    }, {
      field: 'branch',
      name: colors.magenta('Branch')
    }, {
      field: 'created_at',
      name: colors.magenta('Created at')
    }]
  };
  const formattedResults = result.data.results.map(d => {
    return {
      id: d.id,
      report_url: colors.underline(`${d.html_report_url}`),
      created_at: d.created_at ? new Date(d.created_at).toLocaleDateString('en-us', {
        year: 'numeric',
        month: 'numeric',
        day: 'numeric'
      }) : '',
      branch: d.branch
    };
  });
  logger.logger.log(chalkTable(options, formattedResults));
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$5
} = constants;
const config$5 = {
  commandName: 'list',
  description: 'List the scans for an organization',
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags,
    sort: {
      type: 'string',
      shortFlag: 's',
      default: 'created_at',
      description: 'Sorting option (`name` or `created_at`) - default is `created_at`'
    },
    direction: {
      type: 'string',
      shortFlag: 'd',
      default: 'desc',
      description: 'Direction option (`desc` or `asc`) - Default is `desc`'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Results per page - Default is 30'
    },
    page: {
      type: 'number',
      shortFlag: 'p',
      default: 1,
      description: 'Page number - Default is 1'
    },
    fromTime: {
      type: 'string',
      shortFlag: 'f',
      default: '',
      description: 'From time - as a unix timestamp'
    },
    untilTime: {
      type: 'string',
      shortFlag: 'u',
      default: '',
      description: 'Until time - as a unix timestamp'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg
  `
};
const cmdScanList = {
  description: config$5.description,
  hidden: config$5.hidden,
  run: run$5
};
async function run$5(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$5,
    importMeta,
    parentName
  });
  const orgSlug = cli.input[0];
  if (!orgSlug) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

    - Org name as the argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}`);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$5);
    return;
  }
  await listFullScans({
    direction: String(cli.flags['direction'] || ''),
    from_time: String(cli.flags['fromTime'] || ''),
    orgSlug,
    outputKind: cli.flags['json'] ? 'json' : cli.flags['markdown'] ? 'markdown' : 'print',
    page: Number(cli.flags['page'] || 1),
    per_page: Number(cli.flags['perPage'] || 30),
    sort: String(cli.flags['sort'] || '')
  });
}

async function getOrgScanMetadata(orgSlug, scanId, outputKind) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  await getOrgScanMetadataWithToken(orgSlug, scanId, apiToken, outputKind);
}
async function getOrgScanMetadataWithToken(orgSlug, scanId, apiToken, outputKind) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Fetching meta data for a full scan...');
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const result = await handleApiCall(socketSdk.getOrgFullScanMetadata(orgSlug, scanId), 'Listing scans');
  if (!result.success) {
    handleUnsuccessfulApiResponse('getOrgFullScanMetadata', result);
    return;
  }
  spinner?.successAndStop('Fetched the meta data\n');
  if (outputKind === 'json') {
    logger.logger.log(result.data);
  } else {
    // Markdown = print
    if (outputKind === 'markdown') {
      logger.logger.log('# Scan meta data\n');
    }
    logger.logger.log(`Scan ID: ${scanId}\n`);
    for (const [key, value] of Object.entries(result.data)) {
      if (['id', 'updated_at', 'organization_id', 'repository_id', 'commit_hash', 'html_report_url'].includes(key)) continue;
      logger.logger.log(`- ${key}:`, value);
    }
    if (outputKind === 'markdown') {
      logger.logger.log(`\nYou can view this report at: [${result.data.html_report_url}](${result.data.html_report_url})\n`);
    } else {
      logger.logger.log(`\nYou can view this report at: ${result.data.html_report_url}]\n`);
    }
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$4
} = constants;
const config$4 = {
  commandName: 'metadata',
  description: "Get a scan's metadata",
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug> <scan id>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg 000aaaa1-0000-0a0a-00a0-00a0000000a0
  `
};
const cmdScanMetadata = {
  description: config$4.description,
  hidden: config$4.hidden,
  run: run$4
};
async function run$4(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$4,
    importMeta,
    parentName
  });
  const [orgSlug = '', fullScanId = ''] = cli.input;
  if (!orgSlug || !fullScanId) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Full Scan ID to inspect as second argument ${!fullScanId ? colors.red('(missing!)') : colors.green('(ok)')}`);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$4);
    return;
  }
  await getOrgScanMetadata(orgSlug, fullScanId, cli.flags['json'] ? 'json' : cli.flags['markdown'] ? 'markdown' : 'print');
}

/**
 * This fetches all the relevant pieces of data to generate a report, given a
 * full scan ID.
 * It can optionally only fetch the security or license side of things.
 */
async function fetchReportData(orgSlug, fullScanId,
// includeLicensePolicy: boolean,
includeSecurityPolicy) {
  let haveScan = false;
  // let haveLicensePolicy = false
  let haveSecurityPolicy = false;

  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  function updateProgress() {
    const needs = [!haveScan ? 'scan' : undefined,
    // includeLicensePolicy && !haveLicensePolicy ? 'license policy' : undefined,
    includeSecurityPolicy && !haveSecurityPolicy ? 'security policy' : undefined].filter(Boolean);
    if (needs.length > 2) {
      // .toOxford()
      needs[needs.length - 1] = `and ${needs[needs.length - 1]}`;
    }
    const haves = [haveScan ? 'scan' : undefined,
    // includeLicensePolicy && haveLicensePolicy ? 'license policy' : undefined,
    includeSecurityPolicy && haveSecurityPolicy ? 'security policy' : undefined].filter(Boolean);
    if (haves.length > 2) {
      // .toOxford()
      haves[haves.length - 1] = `and ${haves[haves.length - 1]}`;
    }
    if (needs.length) {
      spinner.start(`Fetching ${needs.join(needs.length > 2 ? ', ' : ' and ')}...${haves.length ? ` Completed fetching ${haves.join(haves.length > 2 ? ', ' : ' and ')}.` : ''}`);
    } else {
      spinner?.successAndStop(`Completed fetching ${haves.join(haves.length > 2 ? ', ' : ' and ')}.`);
    }
  }
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  updateProgress();
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);

  // @ts-ignore
  const [scan,
  // licensePolicyMaybe,
  securityPolicyMaybe] = await Promise.all([(async () => {
    try {
      const response = await queryAPI(`orgs/${orgSlug}/full-scans/${encodeURIComponent(fullScanId)}`, apiToken);
      haveScan = true;
      updateProgress();
      if (!response.ok) {
        const err = await handleAPIError(response.status);
        logger.logger.fail(`${colors.bgRed(colors.white(response.statusText))}: Fetch error: ${err}`);
        return undefined;
      }
      const jsons = await response.text();
      const lines = jsons.split('\n').filter(Boolean);
      const data = lines.map(line => {
        try {
          return JSON.parse(line);
        } catch {
          console.error('At least one line item was returned that could not be parsed as JSON...');
          return;
        }
      });
      return data;
    } catch (e) {
      spinner.errorAndStop('There was an issue while fetching full scan data.');
      throw e;
    }
  })(),
  // includeLicensePolicy &&
  //   (async () => {
  //     const r = await socketSdk.getOrgSecurityPolicy(orgSlug)
  //     haveLicensePolicy = true
  //     updateProgress()
  //     return await handleApiCall(
  //       r,
  //       "looking up organization's license policy"
  //     )
  //   })(),
  includeSecurityPolicy && (async () => {
    const r = await socketSdk.getOrgSecurityPolicy(orgSlug);
    haveSecurityPolicy = true;
    updateProgress();
    return await handleApiCall(r, "looking up organization's security policy");
  })()]).finally(() => spinner.stop());
  if (!Array.isArray(scan)) {
    logger.logger.error('Was unable to fetch scan, bailing');
    process.exitCode = 1;
    return {
      ok: false,
      scan: undefined,
      // licensePolicy: undefined,
      securityPolicy: undefined
    };
  }

  // // Note: security->license once the api ships in the sdk
  // let licensePolicy: undefined | SocketSdkReturnType<'getOrgSecurityPolicy'> =
  //   undefined
  // if (includeLicensePolicy) {
  //   if (licensePolicyMaybe && licensePolicyMaybe.success) {
  //     licensePolicy = licensePolicyMaybe
  //   } else {
  //     logger.error('Was unable to fetch license policy, bailing')
  //     process.exitCode = 1
  //     return {
  //       ok: false,
  //       scan: undefined,
  //       licensePolicy: undefined,
  //       securityPolicy: undefined
  //     }
  //   }
  // }

  let securityPolicy = undefined;
  if (includeSecurityPolicy) {
    if (securityPolicyMaybe && securityPolicyMaybe.success) {
      securityPolicy = securityPolicyMaybe;
    } else {
      logger.logger.error('Was unable to fetch security policy, bailing');
      process.exitCode = 1;
      return {
        ok: false,
        scan: undefined,
        // licensePolicy: undefined,
        securityPolicy: undefined
      };
    }
  }
  return {
    ok: true,
    scan,
    // licensePolicy,
    securityPolicy
  };
}

function generateReport(scan, _licensePolicy, securityPolicy, {
  fold,
  orgSlug,
  reportLevel,
  scanId,
  short
}) {
  const now = Date.now();

  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Generating report...');

  // Create an object that includes:
  //   healthy: boolean
  //   worst violation level;
  //   per eco
  //     per package
  //       per version
  //         per offending file
  //           reported issue -> policy action

  // In the context of a report;
  // - the alert.severity is irrelevant
  // - the securityPolicyDefault is irrelevant
  // - the report defaults to healthy:true with no alerts
  // - the appearance of an alert will trigger the policy action;
  //   - error: healthy will end up as false, add alerts to report
  //   - warn: healthy unchanged, add alerts to report
  //   - monitor/ignore: no action
  //   - defer: unknown (no action)

  const violations = new Map();
  let healthy = true;
  const securityRules = securityPolicy?.data.securityPolicyRules;
  if (securityPolicy && securityRules) {
    // Note: reportLevel: error > warn > monitor > ignore > defer
    scan.forEach(artifact => {
      const {
        alerts,
        name: pkgName = '<unknown>',
        type: ecosystem,
        version = '<unknown>'
      } = artifact;
      alerts?.forEach(alert => {
        const alertName = alert.type; // => policy[type]
        const action = securityRules[alertName]?.action || '';
        switch (action) {
          case 'error':
            {
              healthy = false;
              if (!short) {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case 'warn':
            {
              if (!short && reportLevel !== 'error') {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case 'monitor':
            {
              if (!short && reportLevel !== 'warn' && reportLevel !== 'error') {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case 'ignore':
            {
              if (!short && reportLevel !== 'warn' && reportLevel !== 'error' && reportLevel !== 'monitor') {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case 'defer':
            {
              // Not sure but ignore for now. Defer to later ;)
              if (!short && reportLevel === 'defer') {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
        }
      });
    });
  }
  spinner.successAndStop(`Generated reported in ${Date.now() - now} ms`);
  const report = short ? {
    healthy
  } : {
    healthy,
    orgSlug,
    scanId,
    options: {
      fold,
      reportLevel
    },
    alerts: violations
  };
  return report;
}
function createLeaf(art, alert, policyAction) {
  const leaf = {
    type: alert.type,
    policy: policyAction,
    url: `https://socket.dev/${art.type}/package/${art.name}/${art.version}`,
    manifest: art.manifestFiles?.map(obj => obj.file) ?? []
  };
  return leaf;
}
function addAlert(art, violations, foldSetting, ecosystem, pkgName, version, alert, policyAction) {
  if (!violations.has(ecosystem)) violations.set(ecosystem, new Map());
  const ecomap = violations.get(ecosystem);
  if (foldSetting === 'pkg') {
    const existing = ecomap.get(pkgName);
    if (!existing || isStricterPolicy(existing.policy, policyAction)) {
      ecomap.set(pkgName, createLeaf(art, alert, policyAction));
    }
  } else {
    if (!ecomap.has(pkgName)) ecomap.set(pkgName, new Map());
    const pkgmap = ecomap.get(pkgName);
    if (foldSetting === 'version') {
      const existing = pkgmap.get(version);
      if (!existing || isStricterPolicy(existing.policy, policyAction)) {
        pkgmap.set(version, createLeaf(art, alert, policyAction));
      }
    } else {
      if (!pkgmap.has(version)) pkgmap.set(version, new Map());
      const file = alert.file || '<unknown>';
      const vermap = pkgmap.get(version);
      if (foldSetting === 'file') {
        const existing = vermap.get(file);
        if (!existing || isStricterPolicy(existing.policy, policyAction)) {
          vermap.set(file, createLeaf(art, alert, policyAction));
        }
      } else {
        if (!vermap.has(file)) vermap.set(file, new Map());
        const key = `${alert.type} at ${alert.start}:${alert.end}`;
        const filemap = vermap.get(file);
        const existing = filemap.get(key);
        if (!existing || isStricterPolicy(existing.policy, policyAction)) {
          filemap.set(key, createLeaf(art, alert, policyAction));
        }
      }
    }
  }
}
function isStricterPolicy(was, is) {
  // error > warn > monitor > ignore > defer > {unknown}
  if (was === 'error') return false;
  if (is === 'error') return true;
  if (was === 'warn') return false;
  if (is === 'warn') return false;
  if (was === 'monitor') return false;
  if (is === 'monitor') return false;
  if (was === 'ignore') return false;
  if (is === 'ignore') return false;
  if (was === 'defer') return false;
  if (is === 'defer') return false;
  // unreachable?
  return false;
}

/**
 * Convert a Map<string, Map|string> to a nested object of similar shape.
 * The goal is to serialize it with JSON.stringify, which Map can't do.
 */
function mapToObject(map) {
  return Object.fromEntries(Array.from(map.entries()).map(([k, v]) => [k, v instanceof Map ? mapToObject(v) : v]));
}

function* walkNestedMap(map, keys = []) {
  for (const [key, value] of map.entries()) {
    if (value instanceof Map) {
      yield* walkNestedMap(value, keys.concat(key));
    } else {
      yield {
        keys: keys.concat(key),
        value: value
      };
    }
  }
}

async function reportFullScan({
  filePath,
  fold,
  fullScanId,
  includeLicensePolicy,
  includeSecurityPolicy,
  orgSlug,
  outputKind,
  reportLevel,
  short
}) {
  logger.logger.error('output:', outputKind, ', file:', filePath, ', fold:', fold, ', reportLevel:', reportLevel);
  if (!includeSecurityPolicy) {
    return; // caller should assert
  }
  const {
    // licensePolicy,
    ok,
    scan,
    securityPolicy
  } = await fetchReportData(orgSlug, fullScanId,
  // includeLicensePolicy
  includeSecurityPolicy);
  if (!ok) {
    return;
  }
  const scanReport = generateReport(scan, undefined,
  // licensePolicy,
  securityPolicy, {
    orgSlug,
    scanId: fullScanId,
    fold,
    short,
    reportLevel
  });
  if (!scanReport.healthy) {
    process.exitCode = 1;
  }
  if (outputKind === 'json' || outputKind === 'text' && filePath && filePath.endsWith('.json')) {
    const json = short ? JSON.stringify(scanReport) : toJsonReport(scanReport);
    if (filePath && filePath !== '-') {
      logger.logger.log('Writing json report to', filePath);
      return await fs.writeFile(filePath, json);
    }
    logger.logger.log(json);
    return;
  }
  if (outputKind === 'markdown' || filePath && filePath.endsWith('.md')) {
    const md = short ? `healthy = ${scanReport.healthy}` : toMarkdownReport(scanReport);
    if (filePath && filePath !== '-') {
      logger.logger.log('Writing markdown report to', filePath);
      return await fs.writeFile(filePath, md);
    }
    logger.logger.log(md);
    return;
  }
  if (short) {
    logger.logger.log(scanReport.healthy ? 'OK' : 'ERR');
  } else {
    logger.logger.dir(scanReport, {
      depth: null
    });
  }
}
function toJsonReport(report) {
  const obj = mapToObject(report.alerts);
  const json = JSON.stringify({
    ...report,
    alerts: obj
  }, null, 2);
  return json;
}
function toMarkdownReport(report) {
  const flatData = Array.from(walkNestedMap(report.alerts)).map(({
    keys,
    value
  }) => {
    const {
      manifest,
      policy,
      type,
      url
    } = value;
    return {
      'Alert Type': type,
      Package: keys[1] || '<unknown>',
      'Introduced by': keys[2] || '<unknown>',
      url,
      'Manifest file': manifest.join(', '),
      Policy: policy
    };
  });
  const md = `
# Scan Policy Report

This report tells you whether the results of a Socket scan results violate the
security or license policy set by your organization.

## Health status

${report.healthy ? 'The scan *PASSES* all requirements set by your security and license policy.' : 'The scan *VIOLATES* one or more policies set to the "error" level.'}

## Settings

Configuration used to generate this report:

- Organization: ${report.orgSlug}
- Scan ID: ${report.scanId}
- Alert folding: ${report.options.fold === 'none' ? 'none' : `up to ${report.options.fold}`}
- Minimal policy level for alert to be included in report: ${report.options.reportLevel === 'defer' ? 'everything' : report.options.reportLevel}

## Alerts

${report.alerts.size ? `All the alerts from the scan with a policy set to at least "${report.options.reportLevel}"}.` : `The scan contained no alerts for with a policy set to at least "${report.options.reportLevel}".`}

${!report.alerts.size ? '' : mdTable(flatData, ['Policy', 'Alert Type', 'Package', 'Introduced by', 'url', 'Manifest file'])}
  `.trim() + '\n';
  return md;
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$3
} = constants;
const config$3 = {
  commandName: 'report',
  description: 'Check whether a scan result passes the organizational policies (security, license)',
  hidden: true,
  // [beta]
  flags: {
    ...commonFlags,
    ...outputFlags,
    fold: {
      type: 'string',
      default: 'none',
      description: 'Fold reported alerts to some degree'
    },
    reportLevel: {
      type: 'string',
      default: 'warn',
      description: 'Which policy level alerts should be reported'
    },
    short: {
      type: 'boolean',
      default: false,
      description: 'Report only the healthy status'
    },
    // license: {
    //   type: 'boolean',
    //   default: true,
    //   description: 'Report the license policy status. Default: true'
    // },
    security: {
      type: 'boolean',
      default: true,
      description: 'Report the security policy status. Default: true'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug> <scan ID> [path to output file]

    Options
      ${getFlagListOutput(config.flags, 6)}

    This consumes 1 quota unit plus 1 for each of the requested policy types.

    Note: By default it reports both so by default it consumes 3 quota units.

    Your API token will need the \`full-scans:list\` scope regardless. Additionally
    it needs \`security-policy:read\` to report on the security policy.

    By default the result is a nested object that looks like this:
      \`{[ecosystem]: {[pkgName]: {[version]: {[file]: {[type:loc]: policy}}}}\`
    You can fold this up to given level: 'pkg', 'version', 'file', and 'none'.

    By default only the warn and error policy level alerts are reported. You can
    override this and request more ('defer' < 'ignore' < 'monitor' < 'warn' < 'error')

    Short responses: JSON: \`{healthy:bool}\`, markdown: \`healthy = bool\`, text: \`OK/ERR\`

    Examples
      $ ${command} FakeOrg 000aaaa1-0000-0a0a-00a0-00a0000000a0 --json --fold=version
  `
};
const cmdScanReport = {
  description: config$3.description,
  hidden: config$3.hidden,
  run: run$3
};
async function run$3(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$3,
    importMeta,
    parentName
  });
  const {
    fold = 'none',
    json,
    // license,
    markdown,
    reportLevel = 'warn',
    security
  } = cli.flags;
  const [orgSlug = '', fullScanId = '', file = '-'] = cli.input;
  if (!orgSlug || !fullScanId ||
  // (!license && !security) ||
  json && markdown) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
      ${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Full Scan ID to fetch as second argument ${!fullScanId ? colors.red('(missing!)') : colors.green('(ok)')}

      - Not both the --json and --markdown flags ${json && markdown ? colors.red('(pick one!)') : colors.green('(ok)')}
    `
    // - At least one policy to report ${!license && !security ? colors.red('(do not omit both!)') : colors.green('(ok)')}
    );
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$3);
    return;
  }
  await reportFullScan({
    orgSlug,
    fullScanId,
    includeLicensePolicy: false,
    // !!license,
    includeSecurityPolicy: typeof security === 'boolean' ? security : true,
    outputKind: json ? 'json' : markdown ? 'markdown' : 'text',
    filePath: file,
    fold: fold,
    short: !!cli.flags['short'],
    reportLevel: reportLevel
  });
}

async function streamFullScan(orgSlug, fullScanId, file) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  spinner.start('Fetching scan...');
  const socketSdk = await shadowNpmInject.setupSdk(apiToken);
  const data = await handleApiCall(socketSdk.getOrgFullScan(orgSlug, fullScanId, file === '-' ? undefined : file), 'Fetching a scan');
  if (!data?.success) {
    handleUnsuccessfulApiResponse('getOrgFullScan', data);
    return;
  }
  spinner?.successAndStop(file ? `Full scan details written to ${file}` : 'stdout');
  return data;
}

async function viewFullScan(orgSlug, fullScanId, filePath) {
  const artifacts = await getFullScan(orgSlug, fullScanId);
  if (!artifacts) return;
  const display = artifacts.map(art => {
    const author = Array.isArray(art.author) ? `${art.author[0]}${art.author.length > 1 ? ' et.al.' : ''}` : art.author;
    return {
      type: art.type,
      name: art.name,
      version: art.version,
      author,
      score: JSON.stringify(art.score)
    };
  });
  const md = mdTable(display, ['type', 'version', 'name', 'author', 'score']);
  const report = `
# Scan Details

These are the artifacts and their scores found.

Sscan ID: ${fullScanId}

${md}

View this report at: https://socket.dev/dashboard/org/${orgSlug}/sbom/${fullScanId}
  `.trim() + '\n';
  if (filePath && filePath !== '-') {
    try {
      await fs.writeFile(filePath, report, 'utf8');
      logger.logger.log(`Data successfully written to ${filePath}`);
    } catch (e) {
      process.exitCode = 1;
      logger.logger.fail('There was an error trying to write the json to disk');
      logger.logger.error(e);
    }
  } else {
    logger.logger.log(report);
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$2
} = constants;
const config$2 = {
  commandName: 'view',
  description: 'View the raw results of a scan',
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug> <scan ID> [path to output file]

    When no output path is given the contents is sent to stdout.

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeOrg 000aaaa1-0000-0a0a-00a0-00a0000000a0 ./stream.txt
  `
};
const cmdScanView = {
  description: config$2.description,
  hidden: config$2.hidden,
  run: run$2
};
async function run$2(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$2,
    importMeta,
    parentName
  });
  const [orgSlug = '', fullScanId = '', file = '-'] = cli.input;
  if (!orgSlug || !fullScanId) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
      ${colors.bgRed(colors.white('Input error'))}: Please provide the required fields:

      - Org name as the first argument ${!orgSlug ? colors.red('(missing!)') : colors.green('(ok)')}

      - Full Scan ID to fetch as second argument ${!fullScanId ? colors.red('(missing!)') : colors.green('(ok)')}
    `);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$2);
    return;
  }
  if (cli.flags['json']) {
    await streamFullScan(orgSlug, fullScanId, file);
  } else {
    await viewFullScan(orgSlug, fullScanId, file);
  }
}

const description = 'Full Scan related commands';
const cmdScan = {
  description,
  async run(argv, importMeta, {
    parentName
  }) {
    await meowWithSubcommands({
      create: cmdScanCreate,
      list: cmdScanList,
      del: cmdScanDel,
      metadata: cmdScanMetadata,
      report: cmdScanReport,
      view: cmdScanView
    }, {
      aliases: {
        // Backwards compat. TODO: Drop next major bump
        stream: {
          description: cmdScanView.description,
          hidden: true,
          argv: ['view'] // Original args will be appended (!)
        }
      },
      argv,
      description,
      importMeta,
      name: parentName + ' scan'
    });
  }
};

// Note: Widgets does not seem to actually work as code :'(

async function getThreatFeed({
  direction,
  ecosystem,
  filter,
  outputKind,
  page,
  perPage
}) {
  const apiToken = shadowNpmInject.getDefaultToken();
  if (!apiToken) {
    throw new shadowNpmInject.AuthError('User must be authenticated to run this command. To log in, run the command `socket login` and enter your API key.');
  }
  await getThreatFeedWithToken({
    apiToken,
    direction,
    ecosystem,
    filter,
    outputKind,
    page,
    perPage
  });
}
async function getThreatFeedWithToken({
  apiToken,
  direction,
  ecosystem,
  filter,
  outputKind,
  page,
  perPage
}) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const queryParams = new URLSearchParams([['direction', direction], ['ecosystem', ecosystem], ['filter', filter], ['page', page], ['per_page', String(perPage)]]);
  spinner.start('Fetching Threat Feed data...');
  const response = await queryAPI(`threat-feed?${queryParams}`, apiToken);
  const data = await response.json();
  spinner.stop('Threat feed data fetched');
  if (outputKind === 'json') {
    logger.logger.log(data);
    return;
  }
  const screen = new ScreenWidget();
  const table = new TableWidget({
    keys: 'true',
    fg: 'white',
    selectedFg: 'white',
    selectedBg: 'magenta',
    interactive: 'true',
    label: 'Threat feed',
    width: '100%',
    height: '70%',
    // Changed from 100% to 70%
    border: {
      type: 'line',
      fg: 'cyan'
    },
    columnWidth: [10, 30, 20, 18, 15, 200],
    // TODO: the truncation doesn't seem to work too well yet but when we add
    //       `pad` alignment fails, when we extend columnSpacing alignment fails
    columnSpacing: 1,
    truncate: '_'
  });

  // Create details box at the bottom
  const detailsBox = new BoxWidget({
    bottom: 0,
    height: '30%',
    width: '100%',
    border: {
      type: 'line',
      fg: 'cyan'
    },
    label: 'Details',
    content: 'Use arrow keys to navigate. Press Enter to select a threat. Press q to exit.',
    style: {
      fg: 'white'
    }
  });

  // allow control the table with the keyboard
  table.focus();
  screen.append(table);
  screen.append(detailsBox);
  const formattedOutput = formatResults(data.results);
  const descriptions = data.results.map(d => d.description);
  table.setData({
    headers: [' Ecosystem', ' Name', '  Version', '  Threat type', '  Detected at', ' Details'],
    data: formattedOutput
  });

  // Update details box when selection changes
  table.rows.on('select item', () => {
    const selectedIndex = table.rows.selected;
    if (selectedIndex !== undefined && selectedIndex >= 0) {
      const selectedRow = formattedOutput[selectedIndex];
      if (selectedRow) {
        // Note: the spacing works around issues with the table; it refuses to pad!
        detailsBox.setContent(`Ecosystem: ${selectedRow[0]}\n` + `Name: ${selectedRow[1]}\n` + `Version:${selectedRow[2]}\n` + `Threat type:${selectedRow[3]}\n` + `Detected at:${selectedRow[4]}\n` + `Details: ${selectedRow[5]}\n` + `Description: ${descriptions[selectedIndex]}`);
        screen.render();
      }
    }
  });
  screen.render();
  screen.key(['escape', 'q', 'C-c'], () => process$1.exit(0));
  screen.key(['return'], () => {
    const selectedIndex = table.rows.selected;
    screen.destroy();
    const selectedRow = formattedOutput[selectedIndex];
    console.log(selectedRow);
  });
}
function formatResults(data) {
  return data.map(d => {
    const ecosystem = d.purl.split('pkg:')[1].split('/')[0];
    const name = d.purl.split('/')[1].split('@')[0];
    const version = d.purl.split('@')[1];
    const timeDiff = msAtHome(d.createdAt);

    // Note: the spacing works around issues with the table; it refuses to pad!
    return [ecosystem, decodeURIComponent(name), ` ${version}`, ` ${d.threatType}`, ` ${timeDiff}`, d.locationHtmlUrl];
  });
}
function msAtHome(isoTimeStamp) {
  const timeStart = Date.parse(isoTimeStamp);
  const timeEnd = Date.now();
  const rtf = new Intl.RelativeTimeFormat('en', {
    numeric: 'always',
    style: 'short'
  });
  const delta = timeEnd - timeStart;
  if (delta < 60 * 60 * 1000) {
    return rtf.format(-Math.round(delta / (60 * 1000)), 'minute');
    // return Math.round(delta / (60 * 1000)) + ' min ago'
  } else if (delta < 24 * 60 * 60 * 1000) {
    return rtf.format(-(delta / (60 * 60 * 1000)).toFixed(1), 'hour');
    // return (delta / (60 * 60 * 1000)).toFixed(1) + ' hr ago'
  } else if (delta < 7 * 24 * 60 * 60 * 1000) {
    return rtf.format(-(delta / (24 * 60 * 60 * 1000)).toFixed(1), 'day');
    // return (delta / (24 * 60 * 60 * 1000)).toFixed(1) + ' day ago'
  } else {
    return isoTimeStamp.slice(0, 10);
  }
}

const {
  DRY_RUN_BAIL_TEXT: DRY_RUN_BAIL_TEXT$1
} = constants;
const config$1 = {
  commandName: 'threat-feed',
  description: '[beta] View the threat feed',
  hidden: false,
  flags: {
    ...commonFlags,
    ...outputFlags,
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Number of items per page'
    },
    page: {
      type: 'string',
      shortFlag: 'p',
      default: '1',
      description: 'Page token'
    },
    direction: {
      type: 'string',
      shortFlag: 'd',
      default: 'desc',
      description: 'Order asc or desc by the createdAt attribute.'
    },
    eco: {
      type: 'string',
      shortFlag: 'e',
      default: '',
      description: 'Only show threats for a particular ecosystem'
    },
    filter: {
      type: 'string',
      shortFlag: 'f',
      default: 'mal',
      description: 'Filter what type of threats to return'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    This feature requires a Threat Feed license. Please contact
    sales@socket.dev if you are interested in purchasing this access.

    Options
      ${getFlagListOutput(config.flags, 6)}

    Valid filters:

      - anom    Anomaly
      - c       Do not filter
      - fp      False Positives
      - joke    Joke / Fake
      - mal     Malware and Possible Malware [default]
      - secret  Secrets
      - spy     Telemetry
      - tp      False Positives and Unreviewed
      - typo    Typo-squat
      - u       Unreviewed
      - vuln    Vulnerability

    Valid ecosystems:

      - gem
      - golang
      - maven
      - npm
      - nuget
      - pypi

    Examples
      $ ${command}
      $ ${command} --perPage=5 --page=2 --direction=asc --filter=joke
  `
};
const cmdThreatFeed = {
  description: config$1.description,
  hidden: config$1.hidden,
  run: run$1
};
async function run$1(argv, importMeta, {
  parentName
}) {
  const cli = meowOrExit({
    argv,
    config: config$1,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT$1);
    return;
  }
  await getThreatFeed({
    direction: String(cli.flags['direction'] || 'desc'),
    ecosystem: String(cli.flags['eco'] || ''),
    filter: String(cli.flags['filter'] || 'mal'),
    outputKind: cli.flags['json'] ? 'json' : cli.flags['markdown'] ? 'markdown' : 'print',
    page: String(cli.flags['page'] || '1'),
    perPage: Number(cli.flags['perPage']) || 30
  });
}

function addSocketWrapper(file) {
  return fs$1.appendFile(file, 'alias npm="socket npm"\nalias npx="socket npx"\n', err => {
    if (err) {
      return new Error(`There was an error setting up the alias: ${err}`);
    }
    // TODO: pretty sure you need to source the file or restart
    //       any terminal session before changes are reflected.
    logger.logger.log(commonTags.stripIndents`
The alias was added to ${file}. Running 'npm install' will now be wrapped in Socket's "safe npm" ðŸŽ‰
If you want to disable it at any time, run \`socket wrapper --disable\`
`);
  });
}

function checkSocketWrapperSetup(file) {
  const fileContent = fs$1.readFileSync(file, 'utf8');
  const linesWithSocketAlias = fileContent.split('\n').filter(l => l === 'alias npm="socket npm"' || l === 'alias npx="socket npx"');
  if (linesWithSocketAlias.length) {
    logger.logger.log(`The Socket npm/npx wrapper is set up in your bash profile (${file}).`);
    return true;
  }
  return false;
}

function postinstallWrapper() {
  // Lazily access constants.bashRcPath and constants.zshRcPath.
  const {
    bashRcPath,
    zshRcPath
  } = constants;
  const socketWrapperEnabled = fs$1.existsSync(bashRcPath) && checkSocketWrapperSetup(bashRcPath) || fs$1.existsSync(zshRcPath) && checkSocketWrapperSetup(zshRcPath);
  if (!socketWrapperEnabled) {
    installSafeNpm(`The Socket CLI is now successfully installed! ðŸŽ‰

      To better protect yourself against supply-chain attacks, our "safe npm" wrapper can warn you about malicious packages whenever you run 'npm install'.

      Do you want to install "safe npm" (this will create an alias to the socket-npm command)? (y/n)`);
  }
}
function installSafeNpm(query) {
  logger.logger.log(`
 _____         _       _
|   __|___ ___| |_ ___| |_
|__   | . |  _| '_| -_|  _|
|_____|___|___|_,_|___|_|

`);
  const rl = readline$1.createInterface({
    input: process$1.stdin,
    output: process$1.stdout
  });
  return askQuestion(rl, query);
}
function askQuestion(rl, query) {
  rl.question(query, ans => {
    if (ans.toLowerCase() === 'y') {
      // Lazily access constants.bashRcPath and constants.zshRcPath.
      const {
        bashRcPath,
        zshRcPath
      } = constants;
      try {
        if (fs$1.existsSync(bashRcPath)) {
          addSocketWrapper(bashRcPath);
        }
        if (fs$1.existsSync(zshRcPath)) {
          addSocketWrapper(zshRcPath);
        }
      } catch (e) {
        throw new Error(`There was an issue setting up the alias: ${e}`);
      }
      rl.close();
    } else if (ans.toLowerCase() !== 'n') {
      askQuestion(rl, 'Incorrect input: please enter either y (yes) or n (no): ');
    } else {
      rl.close();
    }
  });
}

function removeSocketWrapper(file) {
  return fs$1.readFile(file, 'utf8', function (err, data) {
    if (err) {
      logger.logger.fail('There was an error removing the alias:');
      logger.logger.error(err);
      return;
    }
    const linesWithoutSocketAlias = data.split('\n').filter(l => l !== 'alias npm="socket npm"' && l !== 'alias npx="socket npx"');
    const updatedFileContent = linesWithoutSocketAlias.join('\n');
    fs$1.writeFile(file, updatedFileContent, function (err) {
      if (err) {
        logger.logger.error(err);
        return;
      }
      // TODO: pretty sure you need to source the file or restart
      //       any terminal session before changes are reflected.
      logger.logger.log(`The alias was removed from ${file}. Running 'npm install' will now run the standard npm command.`);
    });
  });
}

const {
  DRY_RUN_BAIL_TEXT
} = constants;
const config = {
  commandName: 'wrapper',
  description: 'Enable or disable the Socket npm/npx wrapper',
  hidden: false,
  flags: {
    ...commonFlags,
    enable: {
      type: 'boolean',
      default: false,
      description: 'Enables the Socket npm/npx wrapper'
    },
    disable: {
      type: 'boolean',
      default: false,
      description: 'Disables the Socket npm/npx wrapper'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <flag>

    Options
      ${getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} --enable
      $ ${command} --disable
  `
};
const cmdWrapper = {
  description: config.description,
  hidden: config.hidden,
  run
};
async function run(argv, importMeta, {
  parentName
}) {
  // I don't think meow would mess with this but ...
  if (argv[0] === '--postinstall') {
    postinstallWrapper();
    return;
  }
  const cli = meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    enable
  } = cli.flags;
  if (!enable && !cli.flags['disable']) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(commonTags.stripIndents`
      ${colors.bgRed(colors.white('Input error'))}: Please provide the required flags:

      - Must use --enabled or --disabled
    `);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAIL_TEXT);
    return;
  }

  // Lazily access constants.bashRcPath and constants.zshRcPath.
  const {
    bashRcPath,
    zshRcPath
  } = constants;
  if (enable) {
    if (fs$1.existsSync(bashRcPath) && !checkSocketWrapperSetup(bashRcPath)) {
      addSocketWrapper(bashRcPath);
    }
    if (fs$1.existsSync(zshRcPath) && !checkSocketWrapperSetup(zshRcPath)) {
      addSocketWrapper(zshRcPath);
    }
  } else {
    if (fs$1.existsSync(bashRcPath)) {
      removeSocketWrapper(bashRcPath);
    }
    if (fs$1.existsSync(zshRcPath)) {
      removeSocketWrapper(zshRcPath);
    }
  }
  if (!fs$1.existsSync(bashRcPath) && !fs$1.existsSync(zshRcPath)) {
    logger.logger.fail('There was an issue setting up the alias in your bash profile');
  }
}

const {
  SOCKET_CLI_BIN_NAME
} = constants;

// TODO: Add autocompletion using https://socket.dev/npm/package/omelette
void (async () => {
  await updateNotifier({
    name: SOCKET_CLI_BIN_NAME,
    // The '@rollup/plugin-replace' will replace "process.env['INLINED_SOCKET_CLI_VERSION']".
    version: "0.14.65",
    ttl: 86_400_000 /* 24 hours in milliseconds */
  });
  try {
    await meowWithSubcommands({
      cdxgen: cmdCdxgen,
      fix: cmdFix,
      info: cmdInfo,
      login: cmdLogin,
      logout: cmdLogout,
      npm: cmdNpm,
      npx: cmdNpx,
      oops: cmdOops,
      optimize: cmdOptimize,
      organization: cmdOrganization,
      package: cmdPackage,
      'raw-npm': cmdRawNpm,
      'raw-npx': cmdRawNpx,
      report: cmdReport,
      wrapper: cmdWrapper,
      scan: cmdScan,
      'audit-log': cmdAuditLog,
      repos: cmdRepos,
      dependencies: cmdScanCreate$1,
      analytics: cmdAnalytics,
      'diff-scan': cmdDiffScan,
      'threat-feed': cmdThreatFeed,
      manifest: cmdManifest
    }, {
      aliases: {
        ci: {
          description: 'Alias for "report create --view --strict"',
          argv: ['report', 'create', '--view', '--strict']
        }
      },
      argv: process$1.argv.slice(2),
      name: SOCKET_CLI_BIN_NAME,
      importMeta: {
        url: `${node_url.pathToFileURL(__filename)}`
      }
    });
  } catch (e) {
    process$1.exitCode = 1;
    let errorBody;
    let errorTitle;
    let errorMessage = '';
    if (e instanceof shadowNpmInject.AuthError) {
      errorTitle = 'Authentication error';
      errorMessage = e.message;
    } else if (e instanceof shadowNpmInject.InputError) {
      errorTitle = 'Invalid input';
      errorMessage = e.message;
      errorBody = e.body;
    } else if (e instanceof Error) {
      errorTitle = 'Unexpected error';
      errorMessage = ponyCause.messageWithCauses(e);
      errorBody = ponyCause.stackWithCauses(e);
    } else {
      errorTitle = 'Unexpected error with no details';
    }
    logger.logger.fail(`${colors.bgRed(colors.white(`${errorTitle}:`))} ${errorMessage}`);
    if (errorBody) {
      logger.logger.error(`\n${errorBody}`);
    }
    await shadowNpmInject.captureException(e);
  }
})();
//# debugId=a3546933-7fe3-404c-ac5f-dae11e0b6833
//# sourceMappingURL=cli.js.map
